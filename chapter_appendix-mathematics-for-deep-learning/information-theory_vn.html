<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>18.11. Lý thuyết Thông tin &#8212; Đắm mình vào Học Sâu 0.14.4 documentation</title>

    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="19. Phụ lục: Công cụ cho Học Sâu" href="../chapter_appendix-tools-for-deep-learning/index_vn.html" />
    <link rel="prev" title="18.10. Thống kê" href="statistics_vn.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index_vn.html"><span class="section-number">18. </span>Phụ lục: Toán học cho Học Sâu</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">18.11. </span>Lý thuyết Thông tin</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_appendix-mathematics-for-deep-learning/information-theory_vn.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/aivivn/d2l-vn">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://forum.machinelearningcoban.com/">
                  <i class="fab fa-discourse"></i>
                  Forum
              </a>
          
              <a  class="mdl-navigation__link" href="https://www.d2l.ai/">
                  <i class="fas fa-external-link-alt"></i>
                  English
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text-vi.png" alt="Đắm mình vào Học Sâu"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro_vn.html">Giới thiệu từ nhóm dịch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index_vn.html">Lời nói đầu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_install/index_vn.html">Cài đặt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index_vn.html">Ký hiệu</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index_vn.html">1. Giới thiệu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index_vn.html">2. Sơ bộ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray_vn.html">2.1. Thao tác với Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas_vn.html">2.2. Tiền xử lý dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra_vn.html">2.3. Đại số tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus_vn.html">2.4. Giải tích</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd_vn.html">2.5. Tính vi phân Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability_vn.html">2.6. Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api_vn.html">2.7. Tài liệu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-networks/index_vn.html">3. Mạng nơ-ron Tuyến tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression_vn.html">3.1. Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-scratch_vn.html">3.2. Lập trình Hồi quy Tuyến tính từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-gluon_vn.html">3.3. Cách lập trình súc tích Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression_vn.html">3.4. Hồi quy Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/fashion-mnist_vn.html">3.5. Bộ dữ liệu Phân loại Ảnh (Fashion-MNIST)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-scratch_vn.html">3.6. Lập trình Hồi quy Sofmax từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-gluon_vn.html">3.7. Cách lập trình súc tích Hồi quy Softmax</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index_vn.html">4. Perceptron Đa tầng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp_vn.html">4.1. Perceptron đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-scratch_vn.html">4.2. Lập trình Perceptron Đa tầng từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-gluon_vn.html">4.3. Cách lập trình súc tích Perceptron Đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/underfit-overfit_vn.html">4.4. Lựa Chọn Mô Hình, Dưới Khớp và Quá Khớp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/weight-decay_vn.html">4.5. Suy giảm trọng số</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout_vn.html">4.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop_vn.html">4.7. Lan truyền xuôi, Lan truyền ngược và Đồ thị tính toán</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init_vn.html">4.8. Ổn định Số học và Khởi tạo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/environment_vn.html">4.9. Cân nhắc tới Môi trường</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price_vn.html">4.10. Dự đoán Giá Nhà trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_deep-learning-computation/index_vn.html">5. Tính toán Học sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/model-construction_vn.html">5.1. Tầng và Khối</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/parameters_vn.html">5.2. Quản lý Tham số</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/deferred-init_vn.html">5.3. Khởi tạo trễ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/custom-layer_vn.html">5.4. Các tầng Tuỳ chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/read-write_vn.html">5.5. Đọc/Ghi tệp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/use-gpu_vn.html">5.6. GPU</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index_vn.html">6. Mạng Nơ-ron Tích chập</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv_vn.html">6.1. Từ Tầng Kết nối Dày đặc đến phép Tích chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer_vn.html">6.2. Phép Tích chập cho Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides_vn.html">6.3. Đệm và Sải Bước</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels_vn.html">6.4. Đa kênh Đầu vào và Đầu ra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling_vn.html">6.5. Gộp (<em>Pooling</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet_vn.html">6.6. Mạng Nơ-ron Tích chập (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index_vn.html">7. Mạng Nơ-ron Tích chập Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet_vn.html">7.1. Mạng Nơ-ron Tích chập Sâu (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/vgg_vn.html">7.2. Mạng sử dụng Khối (VGG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/nin_vn.html">7.3. Mạng trong Mạng (<em>Network in Network - NiN</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet_vn.html">7.4. Mạng nối song song (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm_vn.html">7.5. Chuẩn hoá theo batch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet_vn.html">7.6. Mạng phần dư (ResNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet_vn.html">7.7. Mạng Tích chập Kết nối Dày đặc (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index_vn.html">8. Mạng Nơ-ron Hồi tiếp</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence_vn.html">8.1. Mô hình chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-preprocessing_vn.html">8.2. Tiền Xử lý Dữ liệu Văn bản</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-models-and-dataset_vn.html">8.3. Mô hình Ngôn ngữ và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn_vn.html">8.4. Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch_vn.html">8.5. Lập trình Mạng nơ-ron Hồi tiếp từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-gluon_vn.html">8.6. Lập trình súc tích Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt_vn.html">8.7. Lan truyền Ngược qua Thời gian</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index_vn.html">9. Mạng Nơ-ron Hồi tiếp Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru_vn.html">9.1. Nút Hồi tiếp có Cổng (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm_vn.html">9.2. Bộ nhớ Ngắn hạn Dài (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn_vn.html">9.3. Mạng Nơ-ron Hồi tiếp Sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/bi-rnn_vn.html">9.4. Mạng Nơ-ron Hồi tiếp Hai chiều</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset_vn.html">9.5. Dịch Máy và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder_vn.html">9.6. Kiến trúc Mã hoá - Giải mã</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq_vn.html">9.7. Chuỗi sang Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search_vn.html">9.8. Tìm kiếm Chùm</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms/index_vn.html">10. Cơ chế Tập trung</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/attention_vn.html">10.1. Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/seq2seq-attention_vn.html">10.2. Chuỗi sang Chuỗi áp dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/transformer_vn.html">10.3. Kiến trúc Transformer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index_vn.html">11. Thuật toán Tối ưu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html">11.1. Tối ưu và Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-thach-thuc-cua-toi-uu-trong-hoc-sau">11.2. Các Thách thức của Tối ưu trong Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-vung-cuc-tieu">11.3. Các vùng Cực tiểu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-diem-yen-ngua">11.4. Các điểm Yên ngựa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#tieu-bien-gradient">11.5. Tiêu biến Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity_vn.html">11.6. Tính lồi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd_vn.html">11.7. Hạ Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd_vn.html">11.8. Hạ Gradient Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd_vn.html">11.9. Hạ Gradient Ngẫu nhiên theo Minibatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum_vn.html">11.10. Động lượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad_vn.html">11.11. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop_vn.html">11.12. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta_vn.html">11.13. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam_vn.html">11.14. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler_vn.html">11.15. Định thời Tốc độ Học</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational-performance/index_vn.html">12. Hiệu năng Tính toán</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hybridize_vn.html">12.1. Trình biên dịch và Trình thông dịch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/async-computation_vn.html">12.2. Tính toán Bất đồng bộ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/auto-parallelism_vn.html">12.3. Song song hóa Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hardware_vn.html">12.4. Phần cứng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus_vn.html">12.5. Huấn luyện đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus-concise_vn.html">12.6. Cách lập trình Súc tích đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/parameterserver_vn.html">12.7. Máy chủ Tham số</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index_vn.html">13. Thị giác Máy tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation_vn.html">13.1. Tăng cường Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning_vn.html">13.2. Tinh Chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box_vn.html">13.3. Phát hiện Vật thể và Khoanh vùng Đối tượng (Khung chứa)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor_vn.html">13.4. Khung neo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection_vn.html">13.5. Phát hiện Vật thể Đa tỷ lệ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset_vn.html">13.6. Tập dữ liệu Phát hiện Đối tượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd_vn.html">13.7. Phát hiện Nhiều khung Một lượt (SSD)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn_vn.html">13.8. CNN theo Vùng (R-CNN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset_vn.html">13.9. Phân vùng theo Ngữ nghĩa và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv_vn.html">13.10. Tích chập Chuyển vị</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn_vn.html">13.11. Mạng Tích chập Đầy đủ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style_vn.html">13.12. Truyền tải Phong cách Nơ-ron</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10_vn.html">13.13. Phân loại ảnh (CIFAR-10) trên Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog_vn.html">13.14. Nhận diện Giống Chó (ImageNet Dogs) trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index_vn.html">14. Xử lý Ngôn ngữ Tự nhiên: Tiền Huấn luyện</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec_vn.html">14.1. Embedding Từ (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training_vn.html">14.2. Huấn luyện Gần đúng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset_vn.html">14.3. Tập dữ liệu để Tiền Huấn luyện Embedding Từ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining_vn.html">14.4. Tiền huấn luyện word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove_vn.html">14.5. Embedding từ với Vector Toàn cục (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding_vn.html">14.6. Embedding từ con</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy_vn.html">14.7. Tìm kiếm từ Đồng nghĩa và Loại suy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert_vn.html">14.8. Biểu diễn Mã hóa hai chiều từ Transformer (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset_vn.html">14.9. Tập dữ liệu để Tiền huấn luyện BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining_vn.html">14.10. Tiền Huấn luyện BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index_vn.html">15. Xử lý Ngôn ngữ Tự nhiên: Ứng dụng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset_vn.html">15.1. Tác vụ Phân tích Cảm xúc và Bộ Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn_vn.html">15.2. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn_vn.html">15.3. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Tích Chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset_vn.html">15.4. Suy luận ngôn ngữ tự nhiên và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention_vn.html">15.5. Suy luận Ngôn ngữ Tự nhiên: Sử dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert_vn.html">15.6. Tinh chỉnh BERT cho các Ứng dụng Cấp Chuỗi và Cấp Token</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-bert_vn.html">15.7. Suy luận Ngôn ngữ Tự nhiên: Tinh chỉnh BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender-systems/index_vn.html">16. Hệ thống Đề xuất</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/recsys-intro_vn.html">16.1. Tổng quan về Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/movielens_vn.html">16.2. Tập dữ liệu MovieLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/mf_vn.html">16.3. Phân rã Ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/autorec_vn.html">16.4. AutoRec: Dự đoán Đánh giá với Bộ tự Mã hóa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ranking_vn.html">16.5. Cá nhân hóa Xếp hạng trong Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/neumf_vn.html">16.6. Lọc Cộng tác Nơ-ron cho Cá nhân hóa Xếp hạng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/seqrec_vn.html">16.7. Hệ thống Đề xuất có Nhận thức về Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ctr_vn.html">16.8. Hệ thống Đề xuất Giàu Đặc trưng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/fm_vn.html">16.9. Máy Phân rã ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/deepfm_vn.html">16.10. Máy Phân rã Ma trận Sâu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_generative-adversarial-networks/index_vn.html">17. Mạng Đối sinh</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/gan_vn.html">17.1. Mạng Đối sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/dcgan_vn.html">17.2. Mạng Đối sinh Tích chập Sâu</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index_vn.html">18. Phụ lục: Toán học cho Học Sâu</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="geometry-linear-algebraic-ops_vn.html">18.1. Các phép toán Hình học và Đại số Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="eigendecomposition_vn.html">18.2. Phân rã trị riêng</a></li>
<li class="toctree-l2"><a class="reference internal" href="single-variable-calculus_vn.html">18.3. Giải tích một biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="multivariable-calculus_vn.html">18.4. Giải tích Nhiều biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="integral-calculus_vn.html">18.5. Giải tích Tích phân</a></li>
<li class="toctree-l2"><a class="reference internal" href="random-variables_vn.html">18.6. Biến Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="maximum-likelihood_vn.html">18.7. Hợp lý Cực đại</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributions_vn.html">18.8. Các Phân phối Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="naive-bayes_vn.html">18.9. Bộ phân loại Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="statistics_vn.html">18.10. Thống kê</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">18.11. Lý thuyết Thông tin</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index_vn.html">19. Phụ lục: Công cụ cho Học Sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/jupyter_vn.html">19.1. Sử dụng Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/sagemaker_vn.html">19.2. Sử dụng Amazon SageMaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/aws_vn.html">19.3. Sử dụng Máy ảo AWS EC2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/colab_vn.html">19.4. Sử dụng Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus_vn.html">19.5. Lựa chọn Máy chủ &amp; GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/contributing_vn.html">19.6. Đóng góp cho Quyển sách</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/d2l_vn.html">19.7. Tài liệu API của <code class="docutils literal notranslate"><span class="pre">d2l</span></code></a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/zreferences.html">Tài liệu tham khảo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Bảng thuật ngữ</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text-vi.png" alt="Đắm mình vào Học Sâu"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro_vn.html">Giới thiệu từ nhóm dịch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index_vn.html">Lời nói đầu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_install/index_vn.html">Cài đặt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index_vn.html">Ký hiệu</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index_vn.html">1. Giới thiệu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index_vn.html">2. Sơ bộ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray_vn.html">2.1. Thao tác với Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas_vn.html">2.2. Tiền xử lý dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra_vn.html">2.3. Đại số tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus_vn.html">2.4. Giải tích</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd_vn.html">2.5. Tính vi phân Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability_vn.html">2.6. Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api_vn.html">2.7. Tài liệu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-networks/index_vn.html">3. Mạng nơ-ron Tuyến tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression_vn.html">3.1. Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-scratch_vn.html">3.2. Lập trình Hồi quy Tuyến tính từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-gluon_vn.html">3.3. Cách lập trình súc tích Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression_vn.html">3.4. Hồi quy Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/fashion-mnist_vn.html">3.5. Bộ dữ liệu Phân loại Ảnh (Fashion-MNIST)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-scratch_vn.html">3.6. Lập trình Hồi quy Sofmax từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-gluon_vn.html">3.7. Cách lập trình súc tích Hồi quy Softmax</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index_vn.html">4. Perceptron Đa tầng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp_vn.html">4.1. Perceptron đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-scratch_vn.html">4.2. Lập trình Perceptron Đa tầng từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-gluon_vn.html">4.3. Cách lập trình súc tích Perceptron Đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/underfit-overfit_vn.html">4.4. Lựa Chọn Mô Hình, Dưới Khớp và Quá Khớp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/weight-decay_vn.html">4.5. Suy giảm trọng số</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout_vn.html">4.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop_vn.html">4.7. Lan truyền xuôi, Lan truyền ngược và Đồ thị tính toán</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init_vn.html">4.8. Ổn định Số học và Khởi tạo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/environment_vn.html">4.9. Cân nhắc tới Môi trường</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price_vn.html">4.10. Dự đoán Giá Nhà trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_deep-learning-computation/index_vn.html">5. Tính toán Học sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/model-construction_vn.html">5.1. Tầng và Khối</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/parameters_vn.html">5.2. Quản lý Tham số</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/deferred-init_vn.html">5.3. Khởi tạo trễ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/custom-layer_vn.html">5.4. Các tầng Tuỳ chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/read-write_vn.html">5.5. Đọc/Ghi tệp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/use-gpu_vn.html">5.6. GPU</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index_vn.html">6. Mạng Nơ-ron Tích chập</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv_vn.html">6.1. Từ Tầng Kết nối Dày đặc đến phép Tích chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer_vn.html">6.2. Phép Tích chập cho Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides_vn.html">6.3. Đệm và Sải Bước</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels_vn.html">6.4. Đa kênh Đầu vào và Đầu ra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling_vn.html">6.5. Gộp (<em>Pooling</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet_vn.html">6.6. Mạng Nơ-ron Tích chập (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index_vn.html">7. Mạng Nơ-ron Tích chập Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet_vn.html">7.1. Mạng Nơ-ron Tích chập Sâu (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/vgg_vn.html">7.2. Mạng sử dụng Khối (VGG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/nin_vn.html">7.3. Mạng trong Mạng (<em>Network in Network - NiN</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet_vn.html">7.4. Mạng nối song song (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm_vn.html">7.5. Chuẩn hoá theo batch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet_vn.html">7.6. Mạng phần dư (ResNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet_vn.html">7.7. Mạng Tích chập Kết nối Dày đặc (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index_vn.html">8. Mạng Nơ-ron Hồi tiếp</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence_vn.html">8.1. Mô hình chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-preprocessing_vn.html">8.2. Tiền Xử lý Dữ liệu Văn bản</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-models-and-dataset_vn.html">8.3. Mô hình Ngôn ngữ và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn_vn.html">8.4. Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch_vn.html">8.5. Lập trình Mạng nơ-ron Hồi tiếp từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-gluon_vn.html">8.6. Lập trình súc tích Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt_vn.html">8.7. Lan truyền Ngược qua Thời gian</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index_vn.html">9. Mạng Nơ-ron Hồi tiếp Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru_vn.html">9.1. Nút Hồi tiếp có Cổng (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm_vn.html">9.2. Bộ nhớ Ngắn hạn Dài (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn_vn.html">9.3. Mạng Nơ-ron Hồi tiếp Sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/bi-rnn_vn.html">9.4. Mạng Nơ-ron Hồi tiếp Hai chiều</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset_vn.html">9.5. Dịch Máy và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder_vn.html">9.6. Kiến trúc Mã hoá - Giải mã</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq_vn.html">9.7. Chuỗi sang Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search_vn.html">9.8. Tìm kiếm Chùm</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms/index_vn.html">10. Cơ chế Tập trung</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/attention_vn.html">10.1. Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/seq2seq-attention_vn.html">10.2. Chuỗi sang Chuỗi áp dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/transformer_vn.html">10.3. Kiến trúc Transformer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index_vn.html">11. Thuật toán Tối ưu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html">11.1. Tối ưu và Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-thach-thuc-cua-toi-uu-trong-hoc-sau">11.2. Các Thách thức của Tối ưu trong Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-vung-cuc-tieu">11.3. Các vùng Cực tiểu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-diem-yen-ngua">11.4. Các điểm Yên ngựa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#tieu-bien-gradient">11.5. Tiêu biến Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity_vn.html">11.6. Tính lồi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd_vn.html">11.7. Hạ Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd_vn.html">11.8. Hạ Gradient Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd_vn.html">11.9. Hạ Gradient Ngẫu nhiên theo Minibatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum_vn.html">11.10. Động lượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad_vn.html">11.11. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop_vn.html">11.12. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta_vn.html">11.13. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam_vn.html">11.14. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler_vn.html">11.15. Định thời Tốc độ Học</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational-performance/index_vn.html">12. Hiệu năng Tính toán</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hybridize_vn.html">12.1. Trình biên dịch và Trình thông dịch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/async-computation_vn.html">12.2. Tính toán Bất đồng bộ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/auto-parallelism_vn.html">12.3. Song song hóa Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hardware_vn.html">12.4. Phần cứng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus_vn.html">12.5. Huấn luyện đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus-concise_vn.html">12.6. Cách lập trình Súc tích đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/parameterserver_vn.html">12.7. Máy chủ Tham số</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index_vn.html">13. Thị giác Máy tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation_vn.html">13.1. Tăng cường Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning_vn.html">13.2. Tinh Chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box_vn.html">13.3. Phát hiện Vật thể và Khoanh vùng Đối tượng (Khung chứa)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor_vn.html">13.4. Khung neo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection_vn.html">13.5. Phát hiện Vật thể Đa tỷ lệ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset_vn.html">13.6. Tập dữ liệu Phát hiện Đối tượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd_vn.html">13.7. Phát hiện Nhiều khung Một lượt (SSD)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn_vn.html">13.8. CNN theo Vùng (R-CNN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset_vn.html">13.9. Phân vùng theo Ngữ nghĩa và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv_vn.html">13.10. Tích chập Chuyển vị</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn_vn.html">13.11. Mạng Tích chập Đầy đủ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style_vn.html">13.12. Truyền tải Phong cách Nơ-ron</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10_vn.html">13.13. Phân loại ảnh (CIFAR-10) trên Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog_vn.html">13.14. Nhận diện Giống Chó (ImageNet Dogs) trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index_vn.html">14. Xử lý Ngôn ngữ Tự nhiên: Tiền Huấn luyện</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec_vn.html">14.1. Embedding Từ (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training_vn.html">14.2. Huấn luyện Gần đúng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset_vn.html">14.3. Tập dữ liệu để Tiền Huấn luyện Embedding Từ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining_vn.html">14.4. Tiền huấn luyện word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove_vn.html">14.5. Embedding từ với Vector Toàn cục (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding_vn.html">14.6. Embedding từ con</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy_vn.html">14.7. Tìm kiếm từ Đồng nghĩa và Loại suy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert_vn.html">14.8. Biểu diễn Mã hóa hai chiều từ Transformer (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset_vn.html">14.9. Tập dữ liệu để Tiền huấn luyện BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining_vn.html">14.10. Tiền Huấn luyện BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index_vn.html">15. Xử lý Ngôn ngữ Tự nhiên: Ứng dụng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset_vn.html">15.1. Tác vụ Phân tích Cảm xúc và Bộ Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn_vn.html">15.2. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn_vn.html">15.3. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Tích Chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset_vn.html">15.4. Suy luận ngôn ngữ tự nhiên và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention_vn.html">15.5. Suy luận Ngôn ngữ Tự nhiên: Sử dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert_vn.html">15.6. Tinh chỉnh BERT cho các Ứng dụng Cấp Chuỗi và Cấp Token</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-bert_vn.html">15.7. Suy luận Ngôn ngữ Tự nhiên: Tinh chỉnh BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender-systems/index_vn.html">16. Hệ thống Đề xuất</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/recsys-intro_vn.html">16.1. Tổng quan về Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/movielens_vn.html">16.2. Tập dữ liệu MovieLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/mf_vn.html">16.3. Phân rã Ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/autorec_vn.html">16.4. AutoRec: Dự đoán Đánh giá với Bộ tự Mã hóa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ranking_vn.html">16.5. Cá nhân hóa Xếp hạng trong Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/neumf_vn.html">16.6. Lọc Cộng tác Nơ-ron cho Cá nhân hóa Xếp hạng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/seqrec_vn.html">16.7. Hệ thống Đề xuất có Nhận thức về Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ctr_vn.html">16.8. Hệ thống Đề xuất Giàu Đặc trưng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/fm_vn.html">16.9. Máy Phân rã ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/deepfm_vn.html">16.10. Máy Phân rã Ma trận Sâu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_generative-adversarial-networks/index_vn.html">17. Mạng Đối sinh</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/gan_vn.html">17.1. Mạng Đối sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/dcgan_vn.html">17.2. Mạng Đối sinh Tích chập Sâu</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index_vn.html">18. Phụ lục: Toán học cho Học Sâu</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="geometry-linear-algebraic-ops_vn.html">18.1. Các phép toán Hình học và Đại số Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="eigendecomposition_vn.html">18.2. Phân rã trị riêng</a></li>
<li class="toctree-l2"><a class="reference internal" href="single-variable-calculus_vn.html">18.3. Giải tích một biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="multivariable-calculus_vn.html">18.4. Giải tích Nhiều biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="integral-calculus_vn.html">18.5. Giải tích Tích phân</a></li>
<li class="toctree-l2"><a class="reference internal" href="random-variables_vn.html">18.6. Biến Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="maximum-likelihood_vn.html">18.7. Hợp lý Cực đại</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributions_vn.html">18.8. Các Phân phối Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="naive-bayes_vn.html">18.9. Bộ phân loại Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="statistics_vn.html">18.10. Thống kê</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">18.11. Lý thuyết Thông tin</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index_vn.html">19. Phụ lục: Công cụ cho Học Sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/jupyter_vn.html">19.1. Sử dụng Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/sagemaker_vn.html">19.2. Sử dụng Amazon SageMaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/aws_vn.html">19.3. Sử dụng Máy ảo AWS EC2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/colab_vn.html">19.4. Sử dụng Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus_vn.html">19.5. Lựa chọn Máy chủ &amp; GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/contributing_vn.html">19.6. Đóng góp cho Quyển sách</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/d2l_vn.html">19.7. Tài liệu API của <code class="docutils literal notranslate"><span class="pre">d2l</span></code></a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/zreferences.html">Tài liệu tham khảo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Bảng thuật ngữ</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <!--
# Information Theory
--><div class="section" id="ly-thuyet-thong-tin">
<span id="sec-information-theory"></span><h1><span class="section-number">18.11. </span>Lý thuyết Thông tin<a class="headerlink" href="#ly-thuyet-thong-tin" title="Permalink to this headline">¶</a></h1>
<!--
The universe is overflowing with information.
Information provides a common language across disciplinary rifts: from Shakespeare's Sonnet to researchers' paper on Cornell ArXiv,
from Van Gogh's printing Starry Night to Beethoven's music Symphony No. 5,
from the first programming language Plankalkül to the state-of-the-art machine learning algorithms.
Everything must follow the rules of information theory, no matter the format.
With information theory, we can measure and compare how much information is present in different signals.
In this section, we will investigate the fundamental concepts of information theory and applications of information theory in machine learning.
--><p>Vũ trụ mà chúng ta đang sống thì tràn ngập với thông tin. Thông tin cung
cấp một ngôn ngữ chung giúp vượt qua rào cản ngăn cách nhiều lĩnh vực
riêng biệt: từ thơ của Shakespeare đến các bài báo khoa học của các nhà
nghiên cứu trên Cornell ArXiv, từ bản in Đêm Đầy Sao của Van Gogh đến
Bản Giao Hưởng Số 5 của Beethoven, từ ngôn ngữ lập trình đầu tiên
Plankalkül đến các thuật toán học máy hiện đại nhất. Mọi thứ phải tuân
theo các quy tắc của lý thuyết thông tin, bất kể chúng ở định dạng nào.
Với lý thuyết thông tin, chúng ta có thể đo lường và so sánh lượng thông
tin có trong các tín hiệu khác nhau. Trong phần này, chúng ta sẽ nghiên
cứu các khái niệm cơ bản của lý thuyết thông tin và các ứng dụng của lý
thuyết thông tin trong học máy.</p>
<!--
Before we get started, let us outline the relationship between machine learning and information theory.
Machine learning aims to extract interesting signals from data and make critical predictions.
On the other hand, information theory studies encoding, decoding, transmitting, and manipulating information.
As a result, information theory provides fundamental language for discussing the information processing in machine learned systems.
For example, many machine learning applications use the cross entropy loss as described in :numref:`sec_softmax`.
This loss can be directly derived from information theoretic considerations.
--><p>Trước khi bắt đầu, chúng ta hãy phác thảo mối quan hệ giữa học máy và lý
thuyết thông tin. Mục tiêu của học máy là trích xuất các đặc trưng đáng
chú ý từ dữ liệu và đưa ra các dự đoán quan trọng. Mặt khác, lý thuyết
thông tin nghiên cứu vấn đề mã hóa, giải mã, truyền và thao tác với
thông tin. Do vậy, lý thuyết thông tin cung cấp ngôn ngữ cơ bản để thảo
luận về việc xử lý thông tin trong các hệ thống học máy. Ví dụ: nhiều
ứng dụng học máy sử dụng mất mát entropy chéo như được mô tả trong
<a class="reference internal" href="../chapter_linear-networks/softmax-regression_vn.html#sec-softmax"><span class="std std-numref">Section 3.4</span></a>. Mất mát này có thể được trực tiếp rút ra từ các
quan điểm từ góc nhìn lý thuyết thông tin.</p>
<!--
## Information
--><div class="section" id="thong-tin">
<h2><span class="section-number">18.11.1. </span>Thông tin<a class="headerlink" href="#thong-tin" title="Permalink to this headline">¶</a></h2>
<!--
Let us start with the "soul" of information theory: information.
*Information* can be encoded in anything with a particular sequence of one or more encoding formats.
Suppose that we task ourselves with trying to define a notion of information.
What could be our starting point?
--><p>Ta hãy bắt đầu với “linh hồn” của lý thuyết thông tin: thông tin. <em>Thông
tin</em> có thể được mã hóa trong bất kỳ thứ gì với một hoặc nhiều chuỗi
định dạng mã hóa. Ta giả sử thử chính mình đưa ra một định nghĩa cho
khái niệm thông tin. Ta có thể bắt đầu từ đâu?</p>
<!--
Consider the following thought experiment.
We have a friend with a deck of cards.
They will shuffle the deck, flip over some cards, and tell us statements about the cards.
We will try to assess the information content of each statement.
--><p>Hãy xem thí nghiệm tưởng tượng sau đây. Ta có một người bạn với một bộ
bài. Họ sẽ xáo trộn bộ bài, lật qua một số lá bài và cho chúng ta biết
vài điều về các quân bài. Chúng ta sẽ thử đánh giá nội dung thông tin
của từng phát biểu sau đây.</p>
<!--
First, they flip over a card and tell us, "I see a card."
This provides us with no information at all.
We were already certain that this was the case so we hope the information should be zero.
--><p>Đầu tiên, họ lật một lá và nói, “Tôi thấy một lá bài.” Điều này không
cung cấp cho ta thông tin nào. Rõ ràng là trong trường hợp này chúng ta
đã biết chắc chắn mệnh đề trên là đúng nên lượng thông tin mà nó chứa sẽ
là 0.</p>
<!--
Next, they flip over a card and say, "I see a heart."
This provides us some information, but in reality there are only $4$ different suits that were possible, each equally likely, so we are not surprised by this outcome.
We hope that whatever the measure of information, this event should have low information content.
--><p>Tiếp theo, họ lật một lá khác và nói, “Tôi thấy một lá cơ.” Điều này
cung cấp cho ta một chút thông tin, mà trên thực tế chỉ có thể có
<span class="math notranslate nohighlight">\(4\)</span> loại chất khác nhau, mỗi chất đều có khả năng như nhau, vì vậy
ta không ngạc nhiên trước kết quả này. Ta hy vọng rằng dù thông tin được
đo đạc dưới bất kể hình thức nào, sự kiện này nên có hàm lượng thông tin
thấp.</p>
<!--
Next, they flip over a card and say, "This is the $3$ of spades." This is more information.
Indeed there were $52$ equally likely possible outcomes, and our friend told us which one it was. This should be a medium amount of information.
--><p>Tiếp theo, họ lật một lá và nói, “Đây là quân <span class="math notranslate nohighlight">\(3\)</span> bích.”. Câu trên
chứa nhiều thông tin hơn. Quả thực có <span class="math notranslate nohighlight">\(52\)</span> kết quả tương đương có
thể xảy ra, và ta đã được cho biết đó là lá bài nào. Đây là một lượng
thông tin trung bình.</p>
<!--
Let us take this to the logical extreme.
Suppose that finally they flip over every card from the deck and read off the entire sequence of the shuffled deck.
There are $52!$ different orders to the deck, again all equally likely, so we need a lot of information to know which one it is.
--><p>Hãy đi đến cực hạn. Giả sử rằng cuối cùng họ lật từng lá bài từ bộ bài
và đọc ra toàn bộ trình tự của bộ bài đã bị xáo trộn đó. Có <span class="math notranslate nohighlight">\(52!\)</span>
các thứ tự khác nhau cho bộ bài với khả năng như nhau, vì vậy chúng ta
cần rất nhiều thông tin để biết được chính xác trình tự rút bài.</p>
<!--
Any notion of information we develop must conform to this intuition.
Indeed, in the next sections we will learn how to compute that these events have $0\text{ bits}$,
$2\text{ bits}$, $~5.7\text{ bits}$, and $~225.6\text{ bits}$ of information respectively.
--><p>Bất kỳ khái niệm thông tin nào chúng ta phát triển phải phù hợp với trực
giác này. Thật vậy, trong phần tiếp theo, chúng ta sẽ học cách tính toán
rằng các sự kiện trên có tương ứng <span class="math notranslate nohighlight">\(0\text{ bit}\)</span>,
<span class="math notranslate nohighlight">\(2\text{ bit}\)</span>, <span class="math notranslate nohighlight">\(~5.7\text{ bit}\)</span>, và
<span class="math notranslate nohighlight">\(~225.6\text{ bit}\)</span> thông tin.</p>
<!--
If we read through these thought experiments, we see a natural idea.
As a starting point, rather than caring about the knowledge,
we may build off the idea that information represents the degree of surprise or the abstract possibility of the event.
For example, if we want to describe an unusual event, we need a lot information.
For a common event, we may not need much information.
--><p>Nếu đọc hết những thí nghiệm tưởng tượng này, chúng ta thấy một ý tưởng
tự nhiên. Để khởi đầu, thay vì quan tâm đến kiến thức đã biết, chúng ta
có thể xây dựng ý tưởng là thông tin đại diện cho mức độ bất ngờ hoặc
xác suất trừu tượng của sự kiện. Ví dụ, nếu chúng ta muốn mô tả một sự
kiện hiếm gặp, chúng ta cần rất nhiều thông tin. Đối với một sự kiện phổ
biến, chúng ta có thể không cần nhiều thông tin.</p>
<!--
In 1948, Claude E. Shannon published *A Mathematical Theory of Communication* :cite:`Shannon.1948` establishing the theory of information.
In his article, Shannon introduced the concept of information entropy for the first time. We will begin our journey here.
--><p>Năm 1948, Claude E. Shannon thiết lập lĩnh vực lý thuyết thông tin qua
bài báo khoa học <em>Lý thuyết Toán cho Truyền tải Thông tin - A
Mathematical Theory of Communication</em> <a class="bibtex reference internal" href="../chapter_references/zreferences.html#shannon-1948" id="id1">[Shannon, 1948]</a>. Trong bài
báo của mình, Shannon đưa ra khái niệm entropy thông tin. Chúng ta sẽ
bắt đầu từ đây.</p>
<!--
### Self-information
--><div class="section" id="luong-tin">
<h3><span class="section-number">18.11.1.1. </span>Lượng tin<a class="headerlink" href="#luong-tin" title="Permalink to this headline">¶</a></h3>
<!--
Since information embodies the abstract possibility of an event, how do we map the possibility to the number of bits?
Shannon introduced the terminology *bit* as the unit of information, which was originally created by John Tukey.
So what is a "bit" and why do we use it to measure information? Historically, an antique transmitter can only send or receive two types of code: $0$ and $1$.
Indeed, binary encoding is still in common use on all modern digital computers.
In this way, any information is encoded by a series of $0$ and $1$.
And hence, a series of binary digits of length $n$ contains $n$ bits of information.
--><p>Vì thông tin biểu diễn xác suất trừu tượng của một sự kiện, làm thế nào
để chúng ta ánh xạ xác suất đó thành số lượng bit? Shannon đã giới thiệu
thuật ngữ <em>bit</em> làm đơn vị thông tin, mà ban đầu được đề xuất bởi John
Tukey. Vậy “bit” là gì và tại sao ta sử dụng nó để đo lường thông tin?
Trong quá khứ, một máy phát tín hiệu chỉ có thể gửi hoặc nhận hai loại
mã: <span class="math notranslate nohighlight">\(0\)</span> và <span class="math notranslate nohighlight">\(1\)</span>. Mà thật ra mã hóa nhị phân vẫn được sử dụng
phổ biến trên tất cả các máy tính kỹ thuật số hiện đại. Bằng cách này,
bất kỳ thông tin nào cũng được mã hóa bởi một chuỗi <span class="math notranslate nohighlight">\(0\)</span> và
<span class="math notranslate nohighlight">\(1\)</span>. Và do đó, một chuỗi các chữ số nhị phân (<em>binary</em>) có độ dài
<span class="math notranslate nohighlight">\(n\)</span> chứa <span class="math notranslate nohighlight">\(n\)</span> bit thông tin.</p>
<!--
Now, suppose that for any series of codes, each $0$ or $1$ occurs with a probability of $\frac{1}{2}$.
Hence, an event $X$ with a series of codes of length $n$, occurs with a probability of $\frac{1}{2^n}$.
At the same time, as we mentioned before, this series contains $n$ bits of information.
So, can we generalize to a math function which can transfer the probability $p$ to the number of bits?
Shannon gave the answer by defining *self-information*
--><p>Bây giờ, giả sử rằng đối với bất kỳ chuỗi mã nào, mỗi giá trị <span class="math notranslate nohighlight">\(0\)</span>
hoặc <span class="math notranslate nohighlight">\(1\)</span> xuất hiện với xác suất là <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>. Do đó, sự
kiện <span class="math notranslate nohighlight">\(X\)</span> với một chuỗi mã có độ dài <span class="math notranslate nohighlight">\(n\)</span>, xảy ra với xác suất
<span class="math notranslate nohighlight">\(\frac{1}{2^n}\)</span>. Đồng thời, như chúng tôi đã đề cập trước đây,
chuỗi số này chứa <span class="math notranslate nohighlight">\(n\)</span> bit thông tin. Vì vậy, liệu có thể tổng quát
hóa thành một hàm toán học chuyển xác suất <span class="math notranslate nohighlight">\(p\)</span> thành số lượng bit
không? Shannon đưa ra câu trả lời bằng cách định nghĩa <em>lượng tin</em></p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-0">
<span class="eqno">(18.11.1)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-0" title="Permalink to this equation">¶</a></span>\[I(X) = - \log_2 (p),\]</div>
<!--
as the *bits* of information we have received for this event $X$.
Note that we will always use base-2 logarithms in this section.
For the sake of simplicity, the rest of this section will omit the subscript 2 in the logarithm notation, i.e., $\log(.)$ always refers to $\log_2(.)$.
For example, the code "0010" has a self-information
--><p>là số <em>bit</em> thông tin ta đã nhận cho sự kiện <span class="math notranslate nohighlight">\(X\)</span> này. Lưu ý rằng
ta sẽ luôn sử dụng logarit cơ số 2 trong phần này. Để đơn giản, phần còn
lại của phần này sẽ bỏ qua cơ số 2 trong ký hiệu logarit, tức là
<span class="math notranslate nohighlight">\(\log(.)\)</span> luôn có nghĩa là <span class="math notranslate nohighlight">\(\log_2(.)\)</span>. Ví dụ: mã “0010” có
lượng tin là</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-1">
<span class="eqno">(18.11.2)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-1" title="Permalink to this equation">¶</a></span>\[I(\text{&quot;0010&quot;}) = - \log (p(\text{&quot;0010&quot;})) = - \log \left( \frac{1}{2^4} \right) = 4 \text{ bits}.\]</div>
<!--
We can calculate self information as shown below.
Before that, let us first import all the necessary packages in this section.
--><p>Chúng ta có thể tính toán lượng tin như phần dưới đây. Trước đó, hãy
nhập tất cả các gói cần thiết trong phần này.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">mxnet.metric</span> <span class="kn">import</span> <span class="n">NegativeLogLikelihood</span>
<span class="kn">from</span> <span class="nn">mxnet.ndarray</span> <span class="kn">import</span> <span class="n">nansum</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">self_information</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="n">self_information</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">6.0</span>
</pre></div>
</div>
<!--
## Entropy
--></div>
</div>
<div class="section" id="entropy">
<h2><span class="section-number">18.11.2. </span>Entropy<a class="headerlink" href="#entropy" title="Permalink to this headline">¶</a></h2>
<!--
As self-information only measures the information of a single discrete event,
we need a more generalized measure for any random variable of either discrete or continuous distribution.
--><p>Do lượng tin chỉ đo lường thông tin từ một biến cố rời rạc đơn lẻ, chúng
ta cần một thước đo khái quát hơn cho cả biến ngẫu nhiên có phân bố rời
rạc và liên tục.</p>
<!--
### Motivating Entropy
--><div class="section" id="phat-trien-ly-thuyet-entropy">
<h3><span class="section-number">18.11.2.1. </span>Phát triển Lý thuyết Entropy<a class="headerlink" href="#phat-trien-ly-thuyet-entropy" title="Permalink to this headline">¶</a></h3>
<!--
Let us try to get specific about what we want.  This will be an informal statement of what are known as the *axioms of Shannon entropy*.
It will turn out that the following collection of common-sense statements force us to a unique definition of information.
A formal version of these axioms, along with several others may be found in :cite:`Csiszar.2008`.
--><p>Hãy phân tích cụ thể hơn. Dưới đây là các phát biểu không chính thức của
<em>các tiên đề Shannon về entropy</em>. Chúng buộc ta đi tới một định nghĩa
độc nhất về thông tin. Một phiên bản chính quy của những tiên đề này
cùng với một số tiên đề khác có thể được tìm thấy trong
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#csiszar-2008" id="id2">[Csiszar, 2008]</a>.</p>
<!--
1.  The information we gain by observing a random variable does not depend on what we call the elements, or the presence of additional elements which have probability zero.
2.  The information we gain by observing two random variables is no more than the sum of the information we gain by observing them separately.
If they are independent, then it is exactly the sum.
3.  The information gained when observing (nearly) certain events is (nearly) zero.
--><ol class="arabic simple">
<li>Thông tin thu được bằng cách quan sát một biến ngẫu nhiên không phụ
thuộc vào các yếu tố, hay sự xuất hiện của các yếu tố bổ sung mà có
xác suất bằng 0.</li>
<li>Thông tin thu được bằng cách quan sát hai biến ngẫu nhiên không lớn
hơn tổng thông tin thu được khi quan sát chúng một cách riêng rẽ. Nếu
hai biến ngẫu nhiên là độc lập thì thông tin thu được từ hai cách
bằng nhau.</li>
<li>Thông tin thu được khi quan sát những biến cố (gần như) chắc chắn thì
(gần như) bằng 0.</li>
</ol>
<!--
While proving this fact is beyond the scope of our text, it is important to know that this uniquely determines the form that entropy must take.
The only ambiguity that these allow is in the choice of fundamental units, which is most often normalized by making the choice
we saw before that the information provided by a single fair coin flip is one bit.
--><p>Việc chứng minh các tiên đề trên nằm ngoài phạm vi của cuốn sách, điều
quan trọng cần nhớ là chúng xác định một cách độc nhất hình thái mà
entropy phải có. Chỉ có duy nhất một điều chưa xác định từ những phát
biểu trên là về việc chọn đơn vị cho entropy, mà điều này thường được
chuẩn hóa bằng cách đặt thông tin cung cấp bởi một lần lật đồng xu cân
đối đồng chất là một bit, như đã thấy trước đó.</p>
<!--
### Definition
--></div>
<div class="section" id="dinh-nghia">
<h3><span class="section-number">18.11.2.2. </span>Định nghĩa<a class="headerlink" href="#dinh-nghia" title="Permalink to this headline">¶</a></h3>
<!--
For any random variable $X$ that follows a probability distribution $P$ with a probability density function (p.d.f.) or
a probability mass function (p.m.f.) $p(x)$, we measure the expected amount of information through *entropy* (or *Shannon entropy*)
--><p>Cho một biến ngẫu nhiên <span class="math notranslate nohighlight">\(X\)</span> bất kỳ tuân theo phân phối xác suất
<span class="math notranslate nohighlight">\(P\)</span> với hàm mật độ xác suất (p.d.f) hoặc hàm khối xác suất (p.m.f)
<span class="math notranslate nohighlight">\(p(x)\)</span>, ta đo lượng thông tin kỳ vọng thu được thông qua <em>entropy</em>
(hoặc <em>entropy Shannon</em>):</p>
<div class="math notranslate nohighlight" id="equation-eq-ent-def">
<span class="eqno">(18.11.3)<a class="headerlink" href="#equation-eq-ent-def" title="Permalink to this equation">¶</a></span>\[H(X) = - E_{x \sim P} [\log p(x)].\]</div>
<!--
To be specific, if $X$ is discrete,
--><p>Cụ thể hơn, nếu <span class="math notranslate nohighlight">\(X\)</span> rời rạc:</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-2">
<span class="eqno">(18.11.4)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-2" title="Permalink to this equation">¶</a></span>\[H(X) = - \sum_i p_i \log p_i \text{, where } p_i = P(X_i).\]</div>
<!--
Otherwise, if $X$ is continuous, we also refer entropy as *differential entropy*
--><p>Ngược lại, nếu <span class="math notranslate nohighlight">\(X\)</span> liên tục, ta gọi là <em>entropy vi phân</em>
(<em>differential entropy</em>):</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-3">
<span class="eqno">(18.11.5)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-3" title="Permalink to this equation">¶</a></span>\[H(X) = - \int_x p(x) \log p(x) \; dx.\]</div>
<!--
We can define entropy as below.
--><p>Chúng ta có thể định nghĩa entropy như sau.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span> <span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="c1"># Operator nansum will sum up the non-nan number</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">nansum</span><span class="p">(</span><span class="n">entropy</span><span class="o">.</span><span class="n">as_nd_ndarray</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="n">entropy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]))</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">1.6854753</span><span class="p">]</span>
<span class="o">&lt;</span><span class="n">NDArray</span> <span class="mi">1</span> <span class="nd">@cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">&gt;</span>
</pre></div>
</div>
<!--
### Interpretations
--></div>
<div class="section" id="dien-giai">
<h3><span class="section-number">18.11.2.3. </span>Diễn giải<a class="headerlink" href="#dien-giai" title="Permalink to this headline">¶</a></h3>
<!--
You may be curious: in the entropy definition :eqref:`eq_ent_def`, why do we use an expectation of a negative logarithm? Here are some intuitions.
--><p>Bạn có thể thắc mắc: trong định nghĩa entropy <a class="reference internal" href="#equation-eq-ent-def">(18.11.3)</a>, tại
sao chúng ta sử dụng kỳ vọng của logarit âm? Dưới đây là một số cách
giải thích trực quan.</p>
<!--
First, why do we use a *logarithm* function $\log$?
Suppose that $p(x) = f_1(x) f_2(x) \ldots, f_n(x)$, where each component function $f_i(x)$ is independent from each other.
This means that each $f_i(x)$ contributes independently to the total information obtained from $p(x)$.
As discussed above, we want the entropy formula to be additive over independent random variables.
Luckily, $\log$ can naturally turn a product of probability distributions to a summation of the individual terms.
--><p>Đầu tiên, tại sao chúng ta sử dụng hàm <em>logarit</em> <span class="math notranslate nohighlight">\(\log\)</span>? Giả sử
<span class="math notranslate nohighlight">\(p(x) = f_1(x) f_2(x) \ldots, f_n(x)\)</span>, khi mỗi hàm thành tố
<span class="math notranslate nohighlight">\(f_i(x)\)</span> độc lập lẫn nhau. Điều này nghĩa là mỗi <span class="math notranslate nohighlight">\(f_i(x)\)</span>
đóng góp một cách độc lập vào tổng thông tin thu được từ <span class="math notranslate nohighlight">\(p(x)\)</span>.
Như đã thảo luận ở trên, ta muốn công thức entropy là phép cộng trên các
biến ngẫu nhiên độc lập. May mắn thay, hàm <span class="math notranslate nohighlight">\(\log\)</span> có thể chuyển
tích thành tổng.</p>
<!--
Next, why do we use a *negative* $\log$? Intuitively, more frequent events should contain less information than less common events,
since we often gain more information from an unusual case than from an ordinary one.
However, $\log$ is monotonically increasing with the probabilities, and indeed negative for all values in $[0, 1]$.
We need to construct a monotonically decreasing relationship between the probability of events and their entropy,
which will ideally be always positive (for nothing we observe should force us to forget what we have known).
Hence, we add a negative sign in front of $\log$ function.
--><p>Tiếp theo, tại sao chúng ta sử dụng <span class="math notranslate nohighlight">\(\log\)</span> <em>âm</em>? Một cách trực
quan, những biến cố xảy ra thường xuyên sẽ chứa ít thông tin hơn những
biến cố hiếm vì ta thường thu được nhiều thông tin hơn từ những trường
hợp bất thường. Do đó, ta cần thiết lập mối quan hệ đơn điệu giảm giữa
xác suất của biến cố và entropy của chúng, và muốn entropy luôn dương
(vì các quan sát mới không nên buộc ta quên đi những gì đã biết). Tuy
nhiên, hàm <span class="math notranslate nohighlight">\(\log\)</span> lại là đơn điệu tăng, và có giá trị âm với xác
suất trong đoạn <span class="math notranslate nohighlight">\([0, 1]\)</span>. Vậy nên ta thêm dấu âm vào trước hàm
<span class="math notranslate nohighlight">\(\log\)</span>.</p>
<!--
Last, where does the *expectation* function come from? Consider a random variable $X$.
We can interpret the self-information ($-\log(p)$) as the amount of *surprise* we have at seeing a particular outcome.
Indeed, as the probability approaches zero, the surprise becomes infinite.
Similarly, we can interpret the entropy as the average amount of surprise from observing $X$.
For example, imagine that a slot machine system emits statistical independently symbols ${s_1, \ldots, s_k}$ with probabilities ${p_1, \ldots, p_k}$ respectively.
Then the entropy of this system equals to the average self-information from observing each output, i.e.,
--><p>Cuối cùng, hàm <em>kỳ vọng</em> đến từ đâu? Xét một biến ngẫu nhiên <span class="math notranslate nohighlight">\(X\)</span>.
Ta có thể diễn giải lượng tin (<em>self-information</em>) (<span class="math notranslate nohighlight">\(-\log(p)\)</span>)
như mức độ <em>bất ngờ</em> khi quan sát được một kết quả cụ thể nào đó. Thật
vậy, khi xác suất xấp xỉ bằng 0, mức độ bất ngờ tiến tới vô cùng. Tương
tự, chúng ta có thể diễn giải entropy như mức độ bất ngờ trung bình từ
việc quan sát <span class="math notranslate nohighlight">\(X\)</span>. Ví dụ, tưởng tượng một hệ thống máy đánh bạc
đưa ra các ký hiệu độc lập <span class="math notranslate nohighlight">\({s_1, \ldots, s_k}\)</span> với xác suất lần
lượt là <span class="math notranslate nohighlight">\({p_1, \ldots, p_k}\)</span>. Khi đó, entropy của hệ thống này
bằng với lượng tin trung bình thu được từ việc quan sát mỗi kết quả,
tức:</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-4">
<span class="eqno">(18.11.6)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-4" title="Permalink to this equation">¶</a></span>\[H(S) = \sum_i {p_i \cdot I(s_i)} = - \sum_i {p_i \cdot \log p_i}.\]</div>
<!--
### Properties of Entropy
--></div>
<div class="section" id="tinh-chat-cua-entropy">
<h3><span class="section-number">18.11.2.4. </span>Tính chất của Entropy<a class="headerlink" href="#tinh-chat-cua-entropy" title="Permalink to this headline">¶</a></h3>
<!--
By the above examples and interpretations, we can derive the following properties of entropy :eqref:`eq_ent_def`.
Here, we refer to $X$ as an event and $P$ as the probability distribution of $X$.
--><p>Bằng các ví dụ và diễn giải phía trên, ta có thể rút ra các tính chất
sau của entropy <a class="reference internal" href="#equation-eq-ent-def">(18.11.3)</a>. Ở đây, ta xem <span class="math notranslate nohighlight">\(X\)</span> là một
biến cố và <span class="math notranslate nohighlight">\(P\)</span> là phân phối xác suất của <span class="math notranslate nohighlight">\(X\)</span>.</p>
<!--
* Entropy is non-negative, i.e., $H(X) \geq 0, \forall X$.
* If $X \sim P$ with a p.d.f. or a p.m.f. $p(x)$, and we try to estimate $P$ by a new probability distribution $Q$ with a p.d.f. or a p.m.f. $q(x)$, then
$$H(X) = - E_{x \sim P} [\log p(x)] \leq  - E_{x \sim P} [\log q(x)], \text{ with equality if and only if } P = Q.$$
Alternatively, $H(X)$ gives a lower bound of the average number of bits needed to encode symbols drawn from $P$.
* If $X \sim P$, then $x$ conveys the maximum amount of information if it spreads evenly among all possible outcomes.
Specifically, if the probability distribution $P$ is discrete with $k$-class $\{p_1, \ldots, p_k \}$, then
$$H(X) \leq \log(k), \text{ with equality if and only if } p_i = \frac{1}{k}, \forall i.$$
If $P$ is a continuous random variable, then the story becomes much more complicated.
However, if we additionally impose that $P$ is supported on a finite interval (with all values between $0$ and $1$),
then $P$ has the highest entropy if it is the uniform distribution on that interval.
--><ul>
<li><p class="first">Entropy có giá trị không âm, tức <span class="math notranslate nohighlight">\(H(X) \geq 0, \forall X\)</span>.</p>
</li>
<li><p class="first">Nếu <span class="math notranslate nohighlight">\(X \sim P\)</span> có hàm mật độ xác suất hoặc hàm khối xác suất
<span class="math notranslate nohighlight">\(p(x)\)</span>, và ta muốn ước lượng <span class="math notranslate nohighlight">\(P\)</span> bằng một phân phối xác
suất mới <span class="math notranslate nohighlight">\(Q\)</span> với hàm mật độ xác suất hoặc hàm khối xác suất
<span class="math notranslate nohighlight">\(q(x)\)</span>, ta có:</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-5">
<span class="eqno">(18.11.7)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-5" title="Permalink to this equation">¶</a></span>\[ \begin{align}\begin{aligned}H(X) = - E_{x \sim P} [\log p(x)] \leq  - E_{x \sim P} [\log q(x)], \text{ dấu bằng xảy ra khi và chỉ khi } P = Q.\\Ngoài ra, :math:`H(X)` cho biết cận dưới của số bit trung bình cần\end{aligned}\end{align} \]</div>
<p>dùng để mã hóa các giá trị lấy từ <span class="math notranslate nohighlight">\(P\)</span>.</p>
</li>
<li><p class="first">Nếu <span class="math notranslate nohighlight">\(X \sim P\)</span>, <span class="math notranslate nohighlight">\(x\)</span> sẽ chứa lượng thông tin cực đại nếu
mọi biến cố khả dĩ chứa lượng thông tin như nhau. Cụ thể, nếu
<span class="math notranslate nohighlight">\(P\)</span> là phân phối rời rạc với <span class="math notranslate nohighlight">\(k\)</span> lớp
<span class="math notranslate nohighlight">\(\{p_1, \ldots, p_k \}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-6">
<span class="eqno">(18.11.8)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-6" title="Permalink to this equation">¶</a></span>\[ \begin{align}\begin{aligned}H(X) \leq \log(k), \text{ dấu bằng xảy ra khi và chỉ khi } p_i = \frac{1}{k}, \forall i.\\Nếu :math:`P` là phân phối liên tục thì sẽ phức tạp hơn. Tuy nhiên,\end{aligned}\end{align} \]</div>
<p>nếu ta giả sử thêm rằng <span class="math notranslate nohighlight">\(P\)</span> có miền giá trị nằm trong một
khoảng hữu hạn (với tất cả giá trị nằm trong khoảng <span class="math notranslate nohighlight">\(0\)</span> và
<span class="math notranslate nohighlight">\(1\)</span>), <span class="math notranslate nohighlight">\(P\)</span> sẽ có entropy cực đại nếu nó là phân phối đều
trong khoảng đó.</p>
</li>
</ul>
<!--
## Mutual Information
--></div>
</div>
<div class="section" id="thong-tin-tuong-ho">
<h2><span class="section-number">18.11.3. </span>Thông tin Tương hỗ<a class="headerlink" href="#thong-tin-tuong-ho" title="Permalink to this headline">¶</a></h2>
<!--
Previously we defined entropy of a single random variable $X$, how about the entropy of a pair random variables $(X, Y)$?
We can think of these techniques as trying to answer the following type of question,
"What information is contained in $X$ and $Y$ together compared to each separately?
Is there redundant information, or is it all unique?"
--><p>Ta đã định nghĩa entropy của một biễn ngẫu nhiên <span class="math notranslate nohighlight">\(X\)</span> duy nhất, vậy
còn entropy của một cặp biến ngẫu nhiên <span class="math notranslate nohighlight">\((X,Y)\)</span> thì sao? Ta xem
xét khái niệm này để trả lời các câu hỏi: “Thông tin chứa trong cả
<span class="math notranslate nohighlight">\(X\)</span> và <span class="math notranslate nohighlight">\(Y\)</span> sẽ trông như thế nào so với thông tin trong từng
biến? Có thông tin thừa không, hay chúng đều độc nhất?”</p>
<!--
For the following discussion, we always use $(X, Y)$ as a pair of random variables that follows
a joint probability distribution $P$ with a p.d.f. or a p.m.f. $p_{X, Y}(x, y)$, while $X$ and $Y$ follow probability distribution $p_X(x)$ and $p_Y(y)$, respectively.
--><p>Trong phần thảo luận dưới đây, chúng tôi sẽ luôn dùng <span class="math notranslate nohighlight">\((X,Y)\)</span> để
ký hiệu một cặp biễn ngẫu nhiên tuân theo phân phối xác suất kết hợp
<span class="math notranslate nohighlight">\(P\)</span> với hàm mật độ xác suất hoặc hàm khối xác suất
<span class="math notranslate nohighlight">\(p_{X,Y}(x,y)\)</span>, còn <span class="math notranslate nohighlight">\(X\)</span> và <span class="math notranslate nohighlight">\(Y\)</span> lần lượt tuân theo phân
phối xác suất <span class="math notranslate nohighlight">\(p_X(x)\)</span> và <span class="math notranslate nohighlight">\(p_Y(y)\)</span>.</p>
<!--
### Joint Entropy
--><div class="section" id="entropy-ket-hop">
<h3><span class="section-number">18.11.3.1. </span>Entropy Kết hợp<a class="headerlink" href="#entropy-ket-hop" title="Permalink to this headline">¶</a></h3>
<!--
Similar to entropy of a single random variable :eqref:`eq_ent_def`, we define the *joint entropy* $H(X, Y)$ of a pair random variables $(X, Y)$ as
--><p>Tương tự như entropy của một biến ngẫu nhiên <a class="reference internal" href="#equation-eq-ent-def">(18.11.3)</a>, ta
định nghĩa <em>entropy kết hợp</em> (<em>joint entropy</em>) <span class="math notranslate nohighlight">\(H(X,Y)\)</span> của cặp
biến ngẫu nhiên <span class="math notranslate nohighlight">\((X,Y)\)</span> như sau</p>
<div class="math notranslate nohighlight" id="equation-eq-joint-ent-def">
<span class="eqno">(18.11.9)<a class="headerlink" href="#equation-eq-joint-ent-def" title="Permalink to this equation">¶</a></span>\[H(X, Y) = −E_{(x, y) \sim P} [\log p_{X, Y}(x, y)].\]</div>
<!--
Precisely, on the one hand, if $(X, Y)$ is a pair of discrete random variables, then
--><p>Nếu <span class="math notranslate nohighlight">\((X,Y)\)</span> là rời rạc:</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-7">
<span class="eqno">(18.11.10)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-7" title="Permalink to this equation">¶</a></span>\[H(X, Y) = - \sum_{x} \sum_{y} p_{X, Y}(x, y) \log p_{X, Y}(x, y).\]</div>
<!--
On the other hand, if $(X, Y)$ is a pair of continuous random variables, then we define the *differential joint entropy* as
--><p>Mặt khác, nếu <span class="math notranslate nohighlight">\((X,Y)\)</span> là liên tục, ta định nghĩa <em>entropy kết hợp
vi phân (differential joint entropy)</em> như sau:</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-8">
<span class="eqno">(18.11.11)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-8" title="Permalink to this equation">¶</a></span>\[H(X, Y) = - \int_{x, y} p_{X, Y}(x, y) \ \log p_{X, Y}(x, y) \;dx \;dy.\]</div>
<!--
We can think of :eqref:`eq_joint_ent_def` as telling us the total randomness in the pair of random variables.
As a pair of extremes, if $X = Y$ are two identical random variables, then the information in the pair is exactly the information in one and we have $H(X, Y) = H(X) = H(Y)$.
On the other extreme, if $X$ and $Y$ are independent then $H(X, Y) = H(X) + H(Y)$.
Indeed we will always have that the information contained in a pair of random variables is no smaller than the entropy of either random variable and no more than the sum of both.
--><p>Ta có thể xem <a class="reference internal" href="#equation-eq-joint-ent-def">(18.11.9)</a> như tổng mức độ ngẫu nhiên của
cặp biến ngẫu nhiên. Ở một cực trị, nếu chúng giống hệt nhau
(<span class="math notranslate nohighlight">\(X = Y\)</span>), thông tin của cặp biến này chính là thông tin của từng
biến: <span class="math notranslate nohighlight">\(H(X,Y) = H(X) = H(Y)\)</span>. Ở cực trị còn lại, nếu <span class="math notranslate nohighlight">\(X\)</span> và
<span class="math notranslate nohighlight">\(Y\)</span> độc lập thì <span class="math notranslate nohighlight">\(H(X,Y) = H(X) + H(Y)\)</span>. Tất nhiên, thông tin
chứa trong một cặp biến ngẫu nhiên sẽ không thể nhỏ hơn entropy của từng
biến ngẫu nhiên và không thể lớn hơn tổng entropy của chúng.</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-9">
<span class="eqno">(18.11.12)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-9" title="Permalink to this equation">¶</a></span>\[H(X), H(Y) \le H(X, Y) \le H(X) + H(Y).\]</div>
<!--
Let us implement joint entropy from scratch.
--><p>Hãy cùng lập trình entropy kết hợp từ đầu.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">joint_entropy</span><span class="p">(</span><span class="n">p_xy</span><span class="p">):</span>
    <span class="n">joint_ent</span> <span class="o">=</span> <span class="o">-</span><span class="n">p_xy</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_xy</span><span class="p">)</span>
    <span class="c1"># Operator nansum will sum up the non-nan number</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">nansum</span><span class="p">(</span><span class="n">joint_ent</span><span class="o">.</span><span class="n">as_nd_ndarray</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="n">joint_entropy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]]))</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">1.6854753</span><span class="p">]</span>
<span class="o">&lt;</span><span class="n">NDArray</span> <span class="mi">1</span> <span class="nd">@cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">&gt;</span>
</pre></div>
</div>
<!--
Notice that this is the same *code* as before, but now we interpret it differently as working on the joint distribution of the two random variables.
--><p>Hãy để ý rằng đây chính là <em>đoạn mã</em> từ trước, nhưng giờ ta hiểu nó theo
cách khác khi làm việc với phân phối kết hợp của hai biến ngẫu nhiên.</p>
<!--
### Conditional Entropy
--></div>
<div class="section" id="entropy-co-dieu-kien">
<h3><span class="section-number">18.11.3.2. </span>Entropy có Điều kiện<a class="headerlink" href="#entropy-co-dieu-kien" title="Permalink to this headline">¶</a></h3>
<!--
The joint entropy defined above the amount of information contained in a pair of random variables.
This is useful, but oftentimes it is not what we care about. Consider the setting of machine learning.
Let us take $X$ to be the random variable (or vector of random variables) that describes the pixel values of an image, and $Y$ to be the random variable which is the class label.
$X$ should contain substantial information---a natural image is a complex thing.
However, the information contained in $Y$ once the image has been show should be low.
Indeed, the image of a digit should already contain the information about what digit it is unless the digit is illegible.
Thus, to continue to extend our vocabulary of information theory, we need to be able to reason about the information content in a random variable conditional on another.
--><p>Entropy kết hợp định nghĩa phía trên là lượng thông tin chứa trong một
cặp biến ngẫu nhiên. Đại lượng này khá hữu ích, nhưng thường nó không
phải là thứ mà ta quan tâm. Hãy xem xét trong ngữ cảnh học máy. Gọi
<span class="math notranslate nohighlight">\(X\)</span> là biến ngẫu nhiên (hoặc vector biến ngẫu nhiên) mô tả giá trị
các điểm ảnh trong một bức ảnh, và <span class="math notranslate nohighlight">\(Y\)</span> là biến ngẫu nhiên mô tả
nhãn lớp. <span class="math notranslate nohighlight">\(X\)</span> chứa một lượng thông tin rất lớn — do một bức ảnh tự
nhiên khá phức tạp. Tuy nhiên, lượng thông tin trong <span class="math notranslate nohighlight">\(Y\)</span> khi ta đã
thấy bức ảnh nên là nhỏ. Tất nhiên, bức ảnh chứa một chữ số cũng nên
chứa thông tin đó là chữ số nào, trừ khi chữ số trong ảnh không thể đọc
được. Vì vậy, để tiếp tục mở rộng lý thuyết thông tin, ta cần suy luận
được lượng thông tin trong một biến ngẫu nhiên khi nó phụ thuộc vào một
biến khác.</p>
<!--
In the probability theory, we saw the definition of the *conditional probability* to measure the relationship between variables.
We now want to analogously define the *conditional entropy* $H(Y \mid X)$.  We can write this as
--><p>Trong lý thuyết xác suất, <em>xác suất có điều kiện</em> đo mối quan hệ giữa
các biến. Bây giờ ta muốn định nghĩa <em>entropy có điều kiện</em>
(<em>conditional entropy</em>) <span class="math notranslate nohighlight">\(H(Y \mid X)\)</span> theo cách tương tự dưới
dạng:</p>
<div class="math notranslate nohighlight" id="equation-eq-cond-ent-def">
<span class="eqno">(18.11.13)<a class="headerlink" href="#equation-eq-cond-ent-def" title="Permalink to this equation">¶</a></span>\[H(Y \mid X) = - E_{(x, y) \sim P} [\log p(y \mid x)],\]</div>
<!--
where $p(y \mid x) = \frac{p_{X, Y}(x, y)}{p_X(x)}$ is the conditional probability.
Specifically, if $(X, Y)$ is a pair of discrete random variables, then
--><p>trong đó <span class="math notranslate nohighlight">\(p(y \mid x) = \frac{p_{X, Y}(x, y)}{p_X(x)}\)</span> là xác suất
có điều kiện. Cụ thể, nếu <span class="math notranslate nohighlight">\((X,Y)\)</span> là rời rạc, ta có:</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-10">
<span class="eqno">(18.11.14)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-10" title="Permalink to this equation">¶</a></span>\[H(Y \mid X) = - \sum_{x} \sum_{y} p(x, y) \log p(y \mid x).\]</div>
<!--
If $(X, Y)$ is a pair of continuous random variables, then the *differential conditional entropy* is similarly defined as
--><p>Nếu <span class="math notranslate nohighlight">\((X,Y)\)</span> là liên tục, <em>entropy có điều kiện vi phân</em> được định
nghĩa tương tự như sau:</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-11">
<span class="eqno">(18.11.15)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-11" title="Permalink to this equation">¶</a></span>\[H(Y \mid X) = - \int_x \int_y p(x, y) \ \log p(y \mid x) \;dx \;dy.\]</div>
<!--
It is now natural to ask, how does the *conditional entropy* $H(Y \mid X)$ relate to the entropy $H(X)$ and the joint entropy $H(X, Y)$?
Using the definitions above, we can express this cleanly:
--><p>Bây giờ một câu hỏi tự nhiên là: <em>entropy có điều kiện</em>
<span class="math notranslate nohighlight">\(H(Y \mid X)\)</span> có mối quan hệ gì với entropy <span class="math notranslate nohighlight">\(H(X)\)</span> và
entropy kết hợp <span class="math notranslate nohighlight">\(H(X,Y)\)</span>? Sử dụng các định nghĩa ở trên, ta có thể
biểu diễn mối quan hệ đó một cách gọn gàng:</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-12">
<span class="eqno">(18.11.16)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-12" title="Permalink to this equation">¶</a></span>\[H(Y \mid X) = H(X, Y) - H(X).\]</div>
<!--
This has an intuitive interpretation: the information in $Y$ given $X$ ($H(Y \mid X)$) is the same as
the information in both $X$ and $Y$ together ($H(X, Y)$) minus the information already contained in $X$.
This gives us the information in $Y$ which is not also represented in $X$.
--><p>Điều này có thể được giải thích một cách trực quan như sau: thông tin
trong <span class="math notranslate nohighlight">\(Y\)</span> khi biết <span class="math notranslate nohighlight">\(X\)</span> (<span class="math notranslate nohighlight">\(H(Y \mid X)\)</span>) bằng với thông
tin trong cả <span class="math notranslate nohighlight">\(X\)</span> và <span class="math notranslate nohighlight">\(Y\)</span> (<span class="math notranslate nohighlight">\(H(X, Y)\)</span>) trừ đi thông tin
đã có trong <span class="math notranslate nohighlight">\(X\)</span>. Nó cho ta biết thông tin có trong <span class="math notranslate nohighlight">\(Y\)</span> mà
không chứa trong <span class="math notranslate nohighlight">\(X\)</span>.</p>
<!--
Now, let us implement conditional entropy :eqref:`eq_cond_ent_def` from scratch.
--><p>Bây giờ, hãy cùng lập trình entropy có điều kiện
<a class="reference internal" href="#equation-eq-cond-ent-def">(18.11.13)</a> từ đầu.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">conditional_entropy</span><span class="p">(</span><span class="n">p_xy</span><span class="p">,</span> <span class="n">p_x</span><span class="p">):</span>
    <span class="n">p_y_given_x</span> <span class="o">=</span> <span class="n">p_xy</span><span class="o">/</span><span class="n">p_x</span>
    <span class="n">cond_ent</span> <span class="o">=</span> <span class="o">-</span><span class="n">p_xy</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_y_given_x</span><span class="p">)</span>
    <span class="c1"># Operator nansum will sum up the non-nan number</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">nansum</span><span class="p">(</span><span class="n">cond_ent</span><span class="o">.</span><span class="n">as_nd_ndarray</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="n">conditional_entropy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]))</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">0.8635472</span><span class="p">]</span>
<span class="o">&lt;</span><span class="n">NDArray</span> <span class="mi">1</span> <span class="nd">@cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">&gt;</span>
</pre></div>
</div>
<!--
### Mutual Information
--></div>
<div class="section" id="id3">
<h3><span class="section-number">18.11.3.3. </span>Thông tin Tương hỗ<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<!--
Given the previous setting of random variables $(X, Y)$, you may wonder: "Now that we know how much information is contained in $Y$ but not in $X$,
can we similarly ask how much information is shared between $X$ and $Y$?" The answer will be the *mutual information* of $(X, Y)$, which we will write as $I(X, Y)$.
--><p>Với định nghĩa trước đó về các biến ngẫu nhiên <span class="math notranslate nohighlight">\((X, Y)\)</span>, bạn có
thể tự hỏi:” Ta đã biết có bao nhiêu thông tin nằm trong Y nhưng không
nằm ở trong X, liệu có thể biết được có bao nhiêu thông tin giống nhau
giữa <span class="math notranslate nohighlight">\(X\)</span> và <span class="math notranslate nohighlight">\(Y\)</span> không?”. Đại lượng đó là <em>thông tin tương
hỗ</em> của <span class="math notranslate nohighlight">\((X, Y)\)</span>, ký hiệu là <span class="math notranslate nohighlight">\(I(X, Y)\)</span>.</p>
<!--
Rather than diving straight into the formal definition, let us practice our intuition by first trying to derive an expression
for the mutual information entirely based on terms we have constructed before.
We wish to find the information shared between two random variables.
One way we could try to do this is to start with all the information contained in both $X$ and $Y$ together,
and then we take off the parts that are not shared.
The information contained in both $X$ and $Y$ together is written as $H(X, Y)$.
We want to subtract from this the information contained in $X$ but not in $Y$, and the information contained in $Y$ but not in $X$.
As we saw in the previous section, this is given by $H(X \mid Y)$ and $H(Y \mid X)$ respectively.
Thus, we have that the mutual information should be
--><p>Thay vì đề cập ngay đến định nghĩa chính thức, hãy cùng luyện tập trực
giác bằng cách suy luận biểu thức thông tin tương hỗ dựa trên những khái
niệm mà chúng ta đã xây dựng trước đó. Mục tiêu của chúng ta là tìm được
thông tin giống nhau giữa hai biến ngẫu nhiên. Ta có thể thử bắt đầu với
thông tin chứa trong cả <span class="math notranslate nohighlight">\(X\)</span> và <span class="math notranslate nohighlight">\(Y\)</span>, sau đó bỏ đi những thông
tin không giống nhau. Thông tin chứa trong cả <span class="math notranslate nohighlight">\(X\)</span> và <span class="math notranslate nohighlight">\(Y\)</span> là
<span class="math notranslate nohighlight">\(H(X, Y)\)</span>. Thông tin nằm trong <span class="math notranslate nohighlight">\(X\)</span> nhưng không nằm trong
<span class="math notranslate nohighlight">\(Y\)</span> là H(X <a href="#id4"><span class="problematic" id="id5">:raw-latex:`\mid `Y)$, tương tự, thông tin nằm trong
:math:`Y`</span></a> nhưng không nằm trong <span class="math notranslate nohighlight">\(X\)</span> là <span class="math notranslate nohighlight">\(H(Y \mid X)\)</span>. Do đó,
ta có thông tin tương hỗ như sau:</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-13">
<span class="eqno">(18.11.17)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-13" title="Permalink to this equation">¶</a></span>\[I(X, Y) = H(X, Y) - H(Y \mid X) − H(X \mid Y).\]</div>
<!--
Indeed, this is a valid definition for the mutual information.
If we expand out the definitions of these terms and combine them, a little algebra shows that this is the same as
--><p>Thật vậy, đây là định nghĩa hợp lệ của thông tin tương hỗ. Nếu ta thay
các số hạng trên bằng định nghĩa của chúng, tổng hợp lại, rồi biến đổi
đại số một chút, ta sẽ có:</p>
<div class="math notranslate nohighlight" id="equation-eq-mut-ent-def">
<span class="eqno">(18.11.18)<a class="headerlink" href="#equation-eq-mut-ent-def" title="Permalink to this equation">¶</a></span>\[I(X, Y) = E_{x} E_{y} \left\{ p_{X, Y}(x, y) \log\frac{p_{X, Y}(x, y)}{p_X(x) p_Y(y)} \right\}.\]</div>
<!--
We can summarize all of these relationships in image :numref:`fig_mutual_information`.
It is an excellent test of intuition to see why the following statements are all also equivalent to $I(X, Y)$.
--><p>Ta có thể tóm tắt tất cả những mối quan hệ nêu trên ở hình
<a class="reference internal" href="#fig-mutual-information"><span class="std std-numref">Fig. 18.11.1</span></a>. Đây là một minh họa trực quan tuyệt
vời để hiểu tại sao các mệnh đề sau đây đều tương đương với
<span class="math notranslate nohighlight">\(I(X, Y)\)</span>.</p>
<ul class="simple">
<li><span class="math notranslate nohighlight">\(H(X) − H(X \mid Y)\)</span></li>
<li><span class="math notranslate nohighlight">\(H(Y) − H(Y \mid X)\)</span></li>
<li><span class="math notranslate nohighlight">\(H(X) + H(Y) − H(X, Y)\)</span></li>
</ul>
<!--
![Mutual information's relationship with joint entropy and conditional entropy.](../img/mutual_information.svg)
--><div class="figure align-default" id="id7">
<span id="fig-mutual-information"></span><img alt="../_images/mutual_information.svg" src="../_images/mutual_information.svg" /><p class="caption"><span class="caption-number">Fig. 18.11.1 </span><span class="caption-text">Mối quan hệ giữa thông tin tương hỗ với entropy kết hợp và entropy có
điều kiện.</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
<!--
In many ways we can think of the mutual information :eqref:`eq_mut_ent_def` as principled extension of correlation coefficient we saw in :numref:`sec_random_variables`.
This allows us to ask not only for linear relationships between variables, but for the maximum information shared between the two random variables of any kind.
--><p>Theo nhiều cách ta có thể xem thông tin tương hỗ
<a class="reference internal" href="#equation-eq-mut-ent-def">(18.11.18)</a> như là phần mở rộng của hệ số tương quan trong
<a class="reference internal" href="random-variables_vn.html#sec-random-variables"><span class="std std-numref">Section 18.6</span></a>. Đại lượng này cho phép chúng ta hiểu
không chỉ về mối quan hệ tuyến tính của các biến, mà còn cả lượng thông
tin tối đa mà hai biến chia sẻ với nhau.</p>
<!--
Now, let us implement mutual information from scratch.
--><p>Bây giờ, hãy cùng lập trình thông tin tương hỗ từ đầu.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mutual_information</span><span class="p">(</span><span class="n">p_xy</span><span class="p">,</span> <span class="n">p_x</span><span class="p">,</span> <span class="n">p_y</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">p_xy</span> <span class="o">/</span> <span class="p">(</span><span class="n">p_x</span> <span class="o">*</span> <span class="n">p_y</span><span class="p">)</span>
    <span class="n">mutual</span> <span class="o">=</span> <span class="n">p_xy</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="c1"># Operator nansum will sum up the non-nan number</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">nansum</span><span class="p">(</span><span class="n">mutual</span><span class="o">.</span><span class="n">as_nd_ndarray</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="n">mutual_information</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]]),</span>
                   <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">]]))</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">0.7194603</span><span class="p">]</span>
<span class="o">&lt;</span><span class="n">NDArray</span> <span class="mi">1</span> <span class="nd">@cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">&gt;</span>
</pre></div>
</div>
<!--
### Properties of Mutual Information
--></div>
<div class="section" id="tinh-chat-cua-thong-tin-tuong-ho">
<h3><span class="section-number">18.11.3.4. </span>Tính chất của Thông tin Tương Hỗ<a class="headerlink" href="#tinh-chat-cua-thong-tin-tuong-ho" title="Permalink to this headline">¶</a></h3>
<!--
Rather than memorizing the definition of mutual information :eqref:`eq_mut_ent_def`, you only need to keep in mind its notable properties:
--><p>Thay vì ghi nhớ định nghĩa thông tin tương hỗ <a class="reference internal" href="#equation-eq-mut-ent-def">(18.11.18)</a>,
bạn chỉ cần lưu ý những tính chất nổi trội của nó:</p>
<!--
* Mutual information is symmetric, i.e., $I(X, Y) = I(Y, X)$.
* Mutual information is non-negative, i.e., $I(X, Y) \geq 0$.
* $I(X, Y) = 0$ if and only if $X$ and $Y$ are independent. For example, if $X$ and $Y$ are independent,
then knowing $Y$ does not give any information about $X$ and vice versa, so their mutual information is zero.
* Alternatively, if $X$ is an invertible function of $Y$, then $Y$ and $X$ share all information and $$I(X, Y) = H(Y) = H(X).$$
--><ul>
<li><p class="first">Thông tin tương hỗ có tính đối xứng: <span class="math notranslate nohighlight">\(I(X, Y) = I(Y, X)\)</span>.</p>
</li>
<li><p class="first">Thông tin tương hỗ có giá trị không âm: <span class="math notranslate nohighlight">\(I(X, Y) \geq 0\)</span>.</p>
</li>
<li><p class="first"><span class="math notranslate nohighlight">\(I(X, Y) = 0\)</span> khi và chỉ khi <span class="math notranslate nohighlight">\(X\)</span> và <span class="math notranslate nohighlight">\(Y\)</span> là hai biến
độc lập. Ví dụ, nếu <span class="math notranslate nohighlight">\(X\)</span> và <span class="math notranslate nohighlight">\(Y\)</span> độc lập thì việc biết
thông tin của <span class="math notranslate nohighlight">\(Y\)</span> không cho ta thông tin của <span class="math notranslate nohighlight">\(X\)</span> và ngược
lại, do đó thông tin tương hỗ của chúng bằng 0.</p>
</li>
<li><p class="first">Ngoài ra, nếu <span class="math notranslate nohighlight">\(X\)</span> là hàm nghịch đảo của <span class="math notranslate nohighlight">\(Y\)</span>, thì
<span class="math notranslate nohighlight">\(Y\)</span> và <span class="math notranslate nohighlight">\(X\)</span> có chung toàn bộ thông tin và</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-14">
<span class="eqno">(18.11.19)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-14" title="Permalink to this equation">¶</a></span>\[I(X, Y) = H(Y) = H(X).\]</div>
</li>
</ul>
<!--
### Pointwise Mutual Information
--></div>
<div class="section" id="thong-tin-tuong-ho-theo-tung-diem">
<h3><span class="section-number">18.11.3.5. </span>Thông tin Tương hỗ theo từng Điểm<a class="headerlink" href="#thong-tin-tuong-ho-theo-tung-diem" title="Permalink to this headline">¶</a></h3>
<!--
When we worked with entropy at the beginning of this chapter, we were able to provide an interpretation of $-\log(p_X(x))$ as how *surprised* we were with the particular outcome.
We may give a similar interpretation to the logarithmic term in the mutual information, which is often referred to as the *pointwise mutual information*:
--><p>Khi bắt đầu tìm hiểu về entropy ở đầu chương này, ta đã diễn giải
<span class="math notranslate nohighlight">\(-\log(p_X(x))\)</span> như mức độ <em>ngạc nhiên</em> với kết quả cụ thể của
biến ngẫu nhiên. Ta có thể diễn giải tương tự với logarit trong thông
tin tương hỗ, thường được biết đến với cái tên <em>thông tin tương hỗ theo
từng điểm (pointwise mutual information)</em>:</p>
<div class="math notranslate nohighlight" id="equation-eq-pmi-def">
<span class="eqno">(18.11.20)<a class="headerlink" href="#equation-eq-pmi-def" title="Permalink to this equation">¶</a></span>\[\mathrm{pmi}(x, y) = \log\frac{p_{X, Y}(x, y)}{p_X(x) p_Y(y)}.\]</div>
<!--
We can think of :eqref:`eq_pmi_def` as measuring how much more or less likely
the specific combination of outcomes $x$ and $y$ are compared to what we would expect for independent random outcomes.
If it is large and positive, then these two specific outcomes occur much more frequently than they would compared to random chance
(*note*: the denominator is $p_X(x) p_Y(y)$ which is the probability of the two outcomes were independent),
whereas if it is large and negative it represents the two outcomes happening far less than we would expect by random chance.
--><p><a class="reference internal" href="#equation-eq-pmi-def">(18.11.20)</a> so sánh xác suất <span class="math notranslate nohighlight">\(x\)</span> và <span class="math notranslate nohighlight">\(y\)</span> xảy ra
đồng thời qua phân phối kết hợp với khi chúng cùng xảy ra qua 2 phân
phối ngẫu nhiên độc lập. Nếu kết quả lớn và dương, thì <span class="math notranslate nohighlight">\(x\)</span> và
<span class="math notranslate nohighlight">\(y\)</span> có xác suất xảy ra đồng thời qua phân phối kết hợp cao hơn
nhiều. (<em>chú ý: mẫu số :math:`p_X(x) p_Y(y)` là xác suất của hai đầu ra
độc lập</em>), ngược lại nếu kết quả lớn và âm, thì xác suất xảy ra đồng
thời qua phân phối kết hợp sẽ rất thấp.</p>
<!--
This allows us to interpret the mutual information :eqref:`eq_mut_ent_def` as the average amount that
we were surprised to see two outcomes occurring together compared to what we would expect if they were independent.
--><p>Điều này cho phép ta diễn giải thông tin tương hỗ
<a class="reference internal" href="#equation-eq-mut-ent-def">(18.11.18)</a> như độ ngạc nhiên trung bình khi hai biến cố
xảy ra đồng thời so với độ ngạc nhiên khi chúng là hai biến độc lập.</p>
<!--
### Applications of Mutual Information
--></div>
<div class="section" id="ung-dung-thong-tin-tuong-ho">
<h3><span class="section-number">18.11.3.6. </span>Ứng dụng Thông tin Tương hỗ<a class="headerlink" href="#ung-dung-thong-tin-tuong-ho" title="Permalink to this headline">¶</a></h3>
<!--
Mutual information may be a little abstract in it pure definition, so how does it related to machine learning? In natural language processing,
one of the most difficult problems is the *ambiguity resolution*, or the issue of the meaning of a word being unclear from context.
For example, recently a headline in the news reported that "Amazon is on fire".
You may wonder whether the company Amazon has a building on fire, or the Amazon rain forest is on fire.
--><p>Thông tin tương hỗ có thể hơi trừu tượng theo định nghĩa thuần túy, vậy
nó liên quan như thế nào đến học máy? Trong xử lý ngôn ngữ tự nhiên, một
trong những vấn đề khó khăn nhất là <em>giải quyết sự mơ hồ</em>, tức nghĩa của
từ đang không rõ ràng trong ngữ cảnh. Ví dụ, gần đây có một tiêu đề
trong bản tin thông báo rằng “Amazon đang cháy”. Bạn có thể tự hỏi là
liệu công ty Amazon có một tòa nhà bị cháy, hay rừng Amazon đang cháy.</p>
<!--
In this case, mutual information can help us resolve this ambiguity.
We first find the group of words that each has a relatively large mutual information with the company Amazon, such as e-commerce, technology, and online.
Second, we find another group of words that each has a relatively large mutual information with the Amazon rain forest, such as rain, forest, and tropical.
When we need to disambiguate "Amazon", we can compare which group has more occurrence in the context of the word Amazon.
In this case the article would go on to describe the forest, and make the context clear.
--><p>Thông tin tương hỗ có thể giúp ta giải quyết sự mơ hồ này. Đầu tiên, ta
tìm nhóm từ có thông tin tương hỗ tương đối lớn tới công ty Amazon,
chẳng hạn như thương mại điện tử, công nghệ và trực tuyến. Thứ hai, ta
tìm một nhóm từ khác có một thông tin tương hỗ tương đối lớn tới rừng
mưa Amazon, chẳng hạn như mưa, rừng và nhiệt đới. Khi cần phân biệt
“Amazon”, ta có thể so sánh nhóm nào xuất hiện nhiều hơn trong ngữ cảnh
của từ này. Trong trường hợp này, bài báo sẽ tiếp tục mô tả khu rừng và
ngữ cảnh sẽ được làm rõ.</p>
<!--
## Kullback–Leibler Divergence
--></div>
</div>
<div class="section" id="phan-ky-kullbackleibler">
<h2><span class="section-number">18.11.4. </span>Phân kỳ Kullback–Leibler<a class="headerlink" href="#phan-ky-kullbackleibler" title="Permalink to this headline">¶</a></h2>
<!--
As what we have discussed in :numref:`sec_linear-algebra`, we can use norms to measure distance between two points in space of any dimensionality.
We would like to be able to do a similar task with probability distributions.
There are many ways to go about this, but information theory provides one of the nicest.
We now explore the *Kullback–Leibler (KL) divergence*, which provides a way to measure if two distributions are close together or not.
--><p>Như đã thảo luận trong <a class="reference internal" href="../chapter_preliminaries/linear-algebra_vn.html#sec-linear-algebra"><span class="std std-numref">Section 2.3</span></a>, ta có thể sử dụng
chuẩn (<em>norms</em>) để đo khoảng cách giữa hai điểm trong không gian với số
chiều bất kỳ. Ta muốn thực hiện công việc tương tự với các phân phối xác
suất. Có nhiều cách để giải quyết vấn đề này, nhưng lý thuyết thông tin
cung cấp một trong những cách tốt nhất. Bây giờ ta sẽ tìm hiểu về <em>phân
kỳ Kullback–Leibler (KL)</em> (<em>Kullback–Leibler divergence</em>), là phương
pháp đo lường xem hai phân phối có gần nhau hay không.</p>
<!--
### Definition
--><div class="section" id="id6">
<h3><span class="section-number">18.11.4.1. </span>Định nghĩa<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<!--
Given a random variable $X$ that follows the probability distribution $P$ with a p.d.f. or a p.m.f. $p(x)$,
and we estimate $P$ by another probability distribution $Q$ with a p.d.f. or a p.m.f. $q(x)$.
Then the *Kullback–Leibler (KL) divergence* (or *relative entropy*) between $P$ and $Q$ is
--><p>Cho một biến ngẫu nhiên <span class="math notranslate nohighlight">\(X\)</span> tuân theo phân phối xác suất <span class="math notranslate nohighlight">\(P\)</span>
với hàm mật độ xác suất hay hàm khối xác suất là <span class="math notranslate nohighlight">\(p(x)\)</span>, và ta ước
lượng <span class="math notranslate nohighlight">\(P\)</span> bằng một phân phối xác suất <span class="math notranslate nohighlight">\(Q\)</span> khác với hàm mật
độ xác suất hoặc hàm khối xác suất <span class="math notranslate nohighlight">\(q(x)\)</span>. Khi đó, <em>phân kỳ
Kullback–Leibler</em> (hoặc <em>entropy tương đối</em>) giữa <span class="math notranslate nohighlight">\(P\)</span> và <span class="math notranslate nohighlight">\(Q\)</span>
là</p>
<div class="math notranslate nohighlight" id="equation-eq-kl-def">
<span class="eqno">(18.11.21)<a class="headerlink" href="#equation-eq-kl-def" title="Permalink to this equation">¶</a></span>\[D_{\mathrm{KL}}(P\|Q) = E_{x \sim P} \left[ \log \frac{p(x)}{q(x)} \right].\]</div>
<!--
As with the pointwise mutual information :eqref:`eq_pmi_def`, we can again provide an interpretation of the logarithmic term:
$-\log \frac{q(x)}{p(x)} = -\log(q(x)) - (-\log(p(x)))$ will be large and positive if we see $x$ far more often under $P$ than we would expect for $Q$,
and large and negative if we see the outcome far less than expected.
In this way, we can interpret it as our *relative* surprise at observing the outcome compared to how surprised we would be observing it from our reference distribution.
--><p>Như với thông tin tương hỗ theo từng điểm <a class="reference internal" href="#equation-eq-pmi-def">(18.11.20)</a>, ta lại
có thể diễn giải hạng tử logarit:
<span class="math notranslate nohighlight">\(-\log \frac{q (x)}{p (x)} = -\log(q(x)) - (-\log(p(x)))\)</span> sẽ lớn
và dương nếu ta thấy <span class="math notranslate nohighlight">\(x\)</span> xuất hiện thường xuyên hơn theo phân phối
<span class="math notranslate nohighlight">\(P\)</span> so với mức ta kỳ vọng cho phân phối <span class="math notranslate nohighlight">\(Q\)</span>, và lớn và âm
nếu chúng ta thấy kết quả ít hơn nhiều so với kỳ vọng. Theo cách này, ta
có thể hiểu nó là mức độ ngạc nhiên <em>tương đối</em> khi quan sát phân phối
mục tiêu so với phân phối tham chiếu.</p>
<!--
Let us implement the KL divergence from Scratch.
--><p>Ta hãy thực hiện tính phân kỳ KL từ đầu.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">kl_divergence</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
    <span class="n">kl</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span> <span class="o">/</span> <span class="n">q</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">nansum</span><span class="p">(</span><span class="n">kl</span><span class="o">.</span><span class="n">as_nd_ndarray</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">asscalar</span><span class="p">()</span>
</pre></div>
</div>
<!--
### KL Divergence Properties
--></div>
<div class="section" id="cac-tinh-chat-cua-phan-ky-kl">
<h3><span class="section-number">18.11.4.2. </span>Các tính chất của Phân kỳ KL<a class="headerlink" href="#cac-tinh-chat-cua-phan-ky-kl" title="Permalink to this headline">¶</a></h3>
<!--
Let us take a look at some properties of the KL divergence :eqref:`eq_kl_def`.
--><p>Hãy cùng xem xét một số tính chất của phân kỳ KL <a class="reference internal" href="#equation-eq-kl-def">(18.11.21)</a>.</p>
<!--
* KL divergence is non-symmetric, i.e., there are $P,Q$ such that $$D_{\mathrm{KL}}(P\|Q) \neq D_{\mathrm{KL}}(Q\|P).$$
* KL divergence is non-negative, i.e., $$D_{\mathrm{KL}}(P\|Q) \geq 0.$$ Note that the equality holds only when $P = Q$.
* If there exists an $x$ such that $p(x) > 0$ and $q(x) = 0$, then $D_{\mathrm{KL}}(P\|Q) = \infty$.
* There is a close relationship between KL divergence and mutual information.
Besides the relationship shown in :numref:`fig_mutual_information`, $I(X, Y)$ is also numerically equivalent with the following terms:
    1. $D_{\mathrm{KL}}(P(X, Y)  \ \| \ P(X)P(Y))$;
    2. $E_Y \{ D_{\mathrm{KL}}(P(X \mid Y) \ \| \ P(X)) \}$;
    3. $E_X \{ D_{\mathrm{KL}}(P(Y \mid X) \ \| \ P(Y)) \}$.

  For the first term, we interpret mutual information as the KL divergence between $P(X, Y)$ and the product of $P(X)$ and $P(Y)$,
  and thus is a measure of how different the joint distribution is from the distribution if they were independent.
  For the second term, mutual information tells us the average reduction in uncertainty about $Y$
  that results from learning the value of the $X$'s distribution. Similarly to the third term.
--><ul>
<li><p class="first">Phân kỳ KL là bất đối xứng, tức tồn tại <span class="math notranslate nohighlight">\(P,Q\)</span> sao cho</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-15">
<span class="eqno">(18.11.22)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-15" title="Permalink to this equation">¶</a></span>\[D_{\mathrm{KL}}(P\|Q) \neq D_{\mathrm{KL}}(Q\|P).\]</div>
</li>
<li><p class="first">Phân kỳ KL có giá trị không âm, tức</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-16">
<span class="eqno">(18.11.23)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-16" title="Permalink to this equation">¶</a></span>\[D_{\mathrm{KL}}(P\|Q) \geq 0.\]</div>
<p>Chú ý rằng dấu bằng xảy ra chỉ khi <span class="math notranslate nohighlight">\(P = Q\)</span>.</p>
</li>
<li><p class="first">Nếu tồn tại <span class="math notranslate nohighlight">\(x\)</span> sao cho <span class="math notranslate nohighlight">\(p(x) &gt; 0\)</span> và <span class="math notranslate nohighlight">\(q(x) = 0\)</span>
thì <span class="math notranslate nohighlight">\(D_{\mathrm{KL}}(P\|Q) = \infty\)</span>.</p>
</li>
<li><p class="first">Phân kỳ KL có mối quan hệ mật thiết với thông tin tương hỗ. Ngoài các
dạng trong <a class="reference internal" href="#fig-mutual-information"><span class="std std-numref">Fig. 18.11.1</span></a>, thông tin tương hỗ
<span class="math notranslate nohighlight">\(I(X, Y)\)</span> về mặt số học cũng tương đương với các dạng sau:</p>
<ol class="arabic simple">
<li><span class="math notranslate nohighlight">\(D_{\mathrm{KL}}(P(X, Y) \ \| \ P(X)P(Y))\)</span>;</li>
<li><span class="math notranslate nohighlight">\(E_Y \{ D_{\mathrm{KL}}(P(X \mid Y) \ \| \ P(X)) \}\)</span>;</li>
<li><span class="math notranslate nohighlight">\(E_X \{ D_{\mathrm{KL}}(P(Y \mid X) \ \| \ P(Y)) \}\)</span>.</li>
</ol>
<p>Với dạng đầu tiên, ta diễn giải thông tin tương hỗ dưới dạng phân kỳ
KL giữa <span class="math notranslate nohighlight">\(P(X, Y)\)</span> và tích của <span class="math notranslate nohighlight">\(P(X)\)</span> và <span class="math notranslate nohighlight">\(P(Y)\)</span>, đây
là phép đo mức độ khác nhau của phân phối kết hợp so với phân phối
khi hai biến là độc lập. Với dạng thứ hai, thông tin tương hỗ cho ta
biết mức giảm trung bình trong độ bất định của <span class="math notranslate nohighlight">\(Y\)</span> xảy ra do
việc biết được giá trị trong phân phối của <span class="math notranslate nohighlight">\(X\)</span>. Dạng thứ ba
cũng tương tự.</p>
</li>
</ul>
<!--
### Example
--></div>
<div class="section" id="vi-du">
<h3><span class="section-number">18.11.4.3. </span>Ví dụ<a class="headerlink" href="#vi-du" title="Permalink to this headline">¶</a></h3>
<!--
Let us go through a toy example to see the non-symmetry explicitly.
--><p>Hãy cùng xét một ví dụ đơn giản để thấy rõ hơn tính bất đối xứng.</p>
<!--
First, let us generate and sort three tensors of length $10,000$: an objective tensor $p$ which follows a normal distribution $N(0, 1)$,
and two candidate tensors $q_1$ and $q_2$ which follow normal distributions $N(-1, 1)$ and $N(1, 1)$ respectively.
--><p>Đầu tiên, ta sinh ba tensor có độ dài <span class="math notranslate nohighlight">\(10,000\)</span> và sắp xếp chúng:
một tensor mục tiêu <span class="math notranslate nohighlight">\(p\)</span> tuân theo phân phối chuẩn <span class="math notranslate nohighlight">\(N(0, 1)\)</span>,
và hai tensor tiềm năng <span class="math notranslate nohighlight">\(q_1\)</span> và <span class="math notranslate nohighlight">\(q_2\)</span> lần lượt tuân theo
phân phối chuẩn <span class="math notranslate nohighlight">\(N(-1, 1)\)</span> và <span class="math notranslate nohighlight">\(N(1, 1)\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">nd_len</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nd_len</span><span class="p">,</span> <span class="p">))</span>
<span class="n">q1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nd_len</span><span class="p">,</span> <span class="p">))</span>
<span class="n">q2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nd_len</span><span class="p">,</span> <span class="p">))</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()))</span>
<span class="n">q1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">q1</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()))</span>
<span class="n">q2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">q2</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()))</span>
</pre></div>
</div>
<!--
Since $q_1$ and $q_2$ are symmetric with respect to the y-axis (i.e., $x=0$), we expect a similar value of
KL divergence between $D_{\mathrm{KL}}(p\|q_1)$ and $D_{\mathrm{KL}}(p\|q_2)$.
As you can see below, there is only a less than 3% off between $D_{\mathrm{KL}}(p\|q_1)$ and $D_{\mathrm{KL}}(p\|q_2)$.
--><p>Do <span class="math notranslate nohighlight">\(q_1\)</span> và <span class="math notranslate nohighlight">\(q_2\)</span> đối xứng qua trục y (có <span class="math notranslate nohighlight">\(x=0\)</span>), ta
kỳ vọng giá trị phân kỳ KL giữa <span class="math notranslate nohighlight">\(D_{\mathrm{KL}}(p\|q_1)\)</span> và
<span class="math notranslate nohighlight">\(D_{\mathrm{KL}}(p\|q_2)\)</span> là như nhau. Như có thể thấy,
<span class="math notranslate nohighlight">\(D_{\mathrm{KL}}(p\|q_1)\)</span> và <span class="math notranslate nohighlight">\(D_{\mathrm{KL}}(p\|q_2)\)</span> chỉ
chênh nhau không đến 3%.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">kl_pq1</span> <span class="o">=</span> <span class="n">kl_divergence</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q1</span><span class="p">)</span>
<span class="n">kl_pq2</span> <span class="o">=</span> <span class="n">kl_divergence</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q2</span><span class="p">)</span>
<span class="n">similar_percentage</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">kl_pq1</span> <span class="o">-</span> <span class="n">kl_pq2</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="n">kl_pq1</span> <span class="o">+</span> <span class="n">kl_pq2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

<span class="n">kl_pq1</span><span class="p">,</span> <span class="n">kl_pq2</span><span class="p">,</span> <span class="n">similar_percentage</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mf">8470.638</span><span class="p">,</span> <span class="mf">8664.998</span><span class="p">,</span> <span class="mf">2.268492904612395</span><span class="p">)</span>
</pre></div>
</div>
<!--
In contrast, you may find that $D_{\mathrm{KL}}(q_2 \|p)$ and $D_{\mathrm{KL}}(p \| q_2)$ are off a lot, with around 40% off as shown below.
--><p>Trái lại, giá trị <span class="math notranslate nohighlight">\(D_{\mathrm{KL}}(q_2 \|p)\)</span> và
<span class="math notranslate nohighlight">\(D_{\mathrm{KL}}(p \| q_2)\)</span> chênh nhau khá nhiều, với sai khác tới
khoảng 40% như dưới đây.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">kl_q2p</span> <span class="o">=</span> <span class="n">kl_divergence</span><span class="p">(</span><span class="n">q2</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
<span class="n">differ_percentage</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">kl_q2p</span> <span class="o">-</span> <span class="n">kl_pq2</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="n">kl_q2p</span> <span class="o">+</span> <span class="n">kl_pq2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

<span class="n">kl_q2p</span><span class="p">,</span> <span class="n">differ_percentage</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mf">13536.835</span><span class="p">,</span> <span class="mf">43.88680093791528</span><span class="p">)</span>
</pre></div>
</div>
<!--
## Cross Entropy
--></div>
</div>
<div class="section" id="entropy-cheo">
<h2><span class="section-number">18.11.5. </span>Entropy Chéo<a class="headerlink" href="#entropy-cheo" title="Permalink to this headline">¶</a></h2>
<!--
If you are curious about applications of information theory in deep learning, here is a quick example.
We define the true distribution $P$ with probability distribution $p(x)$,
and the estimated distribution $Q$ with probability distribution $q(x)$, and we will use them in the rest of this section.
--><p>Nếu bạn tò mò về ứng dụng của lý thuyết thông tin trong học sâu, đây là
một ví dụ nhanh. Ta định nghĩa phân phối thực là <span class="math notranslate nohighlight">\(P\)</span> với phân phối
xác suất <span class="math notranslate nohighlight">\(p(x)\)</span>, và phân phối xấp xỉ là <span class="math notranslate nohighlight">\(Q\)</span> với phân phối
xác suất <span class="math notranslate nohighlight">\(q(x)\)</span>. Ta sẽ sử dụng các định nghĩa này trong suốt phần
còn lại.</p>
<!--
Say we need to solve a binary classification problem based on given $n$ data examples {$x_1, \ldots, x_n$}.
Assume that we encode $1$ and $0$ as the positive and negative class label $y_i$ respectively, and our neural network is parameterized by $\theta$.
If we aim to find a best $\theta$ so that $\hat{y}_i= p_{\theta}(y_i \mid x_i)$,
it is natural to apply the maximum log-likelihood approach as was seen in :numref:`sec_maximum_likelihood`.
To be specific, for true labels $y_i$ and predictions $\hat{y}_i= p_{\theta}(y_i \mid x_i)$,
the probability to be classified as positive is $\pi_i= p_{\theta}(y_i = 1 \mid x_i)$.
Hence, the log-likelihood function would be
--><p>Giả sử ta cần giải bài toán phân loại nhị phân dựa vào <span class="math notranslate nohighlight">\(n\)</span> điểm dữ
liệu cho trước {<span class="math notranslate nohighlight">\(x_1, \ldots, x_n\)</span>}. Ta mã hóa <span class="math notranslate nohighlight">\(1\)</span> và
<span class="math notranslate nohighlight">\(0\)</span> lần lượt là lớp dương tính và âm tính cho nhãn <span class="math notranslate nohighlight">\(y_i\)</span>, và
mạng nơ-ron được tham số hóa bởi <span class="math notranslate nohighlight">\(\theta\)</span>. Nếu ta tập trung vào
việc tìm <span class="math notranslate nohighlight">\(\theta\)</span> tốt nhất sao cho
<span class="math notranslate nohighlight">\(\hat{y}_i= p_{\theta}(y_i \mid x_i)\)</span>, việc áp dụng hướng tiếp cận
log hợp lý cực đại (<em>maximum log-likelihood</em>) là hoàn toàn tự nhiên như
ta thấy trong <a class="reference internal" href="maximum-likelihood_vn.html#sec-maximum-likelihood"><span class="std std-numref">Section 18.7</span></a>. Cụ thể hơn, với nhãn
thực <span class="math notranslate nohighlight">\(y_i\)</span> và các dự đoán
<span class="math notranslate nohighlight">\(\hat{y}_i= p_{\theta}(y_i \mid x_i)\)</span>, xác suất được phân loại
thành nhãn dương là <span class="math notranslate nohighlight">\(\pi_i= p_{\theta}(y_i = 1 \mid x_i)\)</span>. Do đó,
hàm log hợp lý sẽ là</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-17">
<span class="eqno">(18.11.24)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-17" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
l(\theta) &amp;= \log L(\theta) \\
  &amp;= \log \prod_{i=1}^n \pi_i^{y_i} (1 - \pi_i)^{1 - y_i} \\
  &amp;= \sum_{i=1}^n y_i \log(\pi_i) + (1 - y_i) \log (1 - \pi_i). \\
\end{aligned}\end{split}\]</div>
<!--
Maximizing the log-likelihood function $l(\theta)$ is identical to minimizing $- l(\theta)$,
and hence we can find the best $\theta$ from here.
To generalize the above loss to any distributions, we also called $-l(\theta)$ the *cross entropy loss* $\mathrm{CE}(y, \hat{y})$,
where $y$ follows the true distribution $P$ and $\hat{y}$ follows the estimated distribution $Q$.
--><p>Việc cực đại hóa hàm log hợp lý <span class="math notranslate nohighlight">\(l(\theta)\)</span> giống hệt với việc cực
tiểu hóa <span class="math notranslate nohighlight">\(- l(\theta)\)</span>, và do đó ta có thể tìm <span class="math notranslate nohighlight">\(\theta\)</span> tốt
nhất từ đây. Để khái quát hóa hàm mất mát trên với mọi phân phối, ta gọi
<span class="math notranslate nohighlight">\(-l(\theta)\)</span> là <em>mất mát entropy chéo (cross entropy loss)</em>
<span class="math notranslate nohighlight">\(\mathrm{CE}(y, \hat{y})\)</span>, trong đó <span class="math notranslate nohighlight">\(y\)</span> tuân theo phân phối
thực <span class="math notranslate nohighlight">\(P\)</span> và <span class="math notranslate nohighlight">\(\hat{y}\)</span> tuân theo phân phối ước lượng
<span class="math notranslate nohighlight">\(Q\)</span>.</p>
<!--
This was all derived by working from the maximum likelihood point of view.
However, if we look closely we can see that terms like $\log(\pi_i)$ have entered into our computation
which is a solid indication that we can understand the expression from an information theoretic point of view.
--><p>Điều này được suy ra theo góc nhìn của hợp lý cực đại. Tuy nhiên, nếu
quan sát kỹ hơn ta có thể thấy rằng các số hạng như <span class="math notranslate nohighlight">\(\log(\pi_i)\)</span>
có tham gia vào phép tính, và đây là một dấu hiệu cho thấy ta có thể
hiểu được biểu thức theo góc nhìn của lý thuyết thông tin.</p>
<!--
### Formal Definition
--><div class="section" id="dinh-nghia-chuan">
<h3><span class="section-number">18.11.5.1. </span>Định nghĩa Chuẩn<a class="headerlink" href="#dinh-nghia-chuan" title="Permalink to this headline">¶</a></h3>
<!--
Like KL divergence, for a random variable $X$, we can also measure the divergence between the estimating distribution $Q$ and the true distribution $P$ via *cross entropy*,
--><p>Giống với phân kỳ KL, với biến ngẫu nhiên <span class="math notranslate nohighlight">\(X\)</span>, ta cũng có thể đo
được độ phân kỳ giữa phân phối ước lượng <span class="math notranslate nohighlight">\(Q\)</span> và phân phối thực
<span class="math notranslate nohighlight">\(P\)</span> thông qua <em>entropy chéo</em>,</p>
<div class="math notranslate nohighlight" id="equation-eq-ce-def">
<span class="eqno">(18.11.25)<a class="headerlink" href="#equation-eq-ce-def" title="Permalink to this equation">¶</a></span>\[\mathrm{CE}(P, Q) = - E_{x \sim P} [\log(q(x))].\]</div>
<!--
By using properties of entropy discussed above, we can also interpret it as the summation of the entropy $H(P)$ and the KL divergence between $P$ and $Q$, i.e.,
--><p>Bằng cách sử dụng các tính chất của entropy đã liệt kê ở trên, ta có thể
viết lại công thức trên dưới dạng tổng giữa entropy <span class="math notranslate nohighlight">\(H(P)\)</span> và phân
kỳ KL giữa <span class="math notranslate nohighlight">\(P\)</span> và <span class="math notranslate nohighlight">\(Q\)</span>, tức</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-18">
<span class="eqno">(18.11.26)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-18" title="Permalink to this equation">¶</a></span>\[\mathrm{CE} (P, Q) = H(P) + D_{\mathrm{KL}}(P\|Q).\]</div>
<!--
We can implement the cross entropy loss as below.
--><p>Ta có thể lập trình mất mát entropy chéo như dưới đây.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">ce</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)),</span> <span class="n">y</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">ce</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<!--
Now define two tensors for the labels and predictions, and calculate the cross entropy loss of them.
--><p>Giờ ta định nghĩa hai tensor cho nhãn và giá trị dự đoán, và tính mất
mát entropy chéo của chúng.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>

<span class="n">cross_entropy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">(</span><span class="mf">0.94856</span><span class="p">)</span>
</pre></div>
</div>
<!--
### Properties
--></div>
<div class="section" id="tinh-chat">
<h3><span class="section-number">18.11.5.2. </span>Tính chất<a class="headerlink" href="#tinh-chat" title="Permalink to this headline">¶</a></h3>
<!--
As alluded in the beginning of this section, cross entropy :eqref:`eq_ce_def` can be used to define a loss function in the optimization problem.
It turns out that the following are equivalent:
--><p>Như đã ám chỉ ở đoạn đầu của phần này, entropy chéo <a class="reference internal" href="#equation-eq-ce-def">(18.11.25)</a>
có thể được sử dụng để định nghĩa hàm mất mát trong bài toán tối ưu. Các
mục tiêu sau là tương đương:</p>
<!--
1. Maximizing predictive probability of $Q$ for distribution $P$, (i.e., $E_{x \sim P} [\log (q(x))]$);
2. Minimizing cross entropy $\mathrm{CE} (P, Q)$;
3. Minimizing the KL divergence $D_{\mathrm{KL}}(P\|Q)$.
--><ol class="arabic simple">
<li>Cực đại hóa xác suất dự đoán của <span class="math notranslate nohighlight">\(Q\)</span> cho phân phối <span class="math notranslate nohighlight">\(P\)</span>,
tức <span class="math notranslate nohighlight">\(E_{x \sim P} [\log (q(x))]\)</span>);</li>
<li>Cực tiểu hóa entropy chéo <span class="math notranslate nohighlight">\(\mathrm{CE} (P, Q)\)</span>;</li>
<li>Cực tiểu hóa phân kỳ KL <span class="math notranslate nohighlight">\(D_{\mathrm{KL}}(P\|Q)\)</span>.</li>
</ol>
<!--
The definition of cross entropy indirectly proves the equivalent relationship between objective 2 and objective 3, as long as the entropy of true data $H(P)$ is constant.
--><p>Định nghĩa của entropy chéo gián tiếp chứng minh mối quan hệ tương đồng
giữa mục tiêu 2 và mục tiêu 3, miễn là entropy của dữ liệu thực
<span class="math notranslate nohighlight">\(H(P)\)</span> là hằng số.</p>
<!--
### Cross Entropy as An Objective Function of Multi-class Classification
--></div>
<div class="section" id="ham-muc-tieu-entropy-cheo-khi-phan-loai-da-lop">
<h3><span class="section-number">18.11.5.3. </span>Hàm Mục tiêu Entropy Chéo khi Phân loại Đa lớp<a class="headerlink" href="#ham-muc-tieu-entropy-cheo-khi-phan-loai-da-lop" title="Permalink to this headline">¶</a></h3>
<!--
If we dive deep into the classification objective function with cross entropy loss $\mathrm{CE}$,
we will find minimizing $\mathrm{CE}$ is equivalent to maximizing the log-likelihood function $L$.
--><p>Nếu đi sâu vào hàm mục tiêu mất mát entropy chéo <span class="math notranslate nohighlight">\(\mathrm{CE}\)</span> cho
bài toán phân loại, ta sẽ thấy rằng cực tiểu hóa <span class="math notranslate nohighlight">\(\mathrm{CE}\)</span>
tương đương với cực đại hóa hàm log hợp lý <span class="math notranslate nohighlight">\(L\)</span>.</p>
<!--
To begin with, suppose that we are given a dataset with $n$ examples, and it can be classified into $k$-classes.
For each data example $i$, we represent any $k$-class label $\mathbf{y}_i = (y_{i1}, \ldots, y_{ik})$ by *one-hot encoding*.
To be specific, if the  example $i$ belongs to class $j$, then we set the $j$-th entry to $1$, and all other components to $0$, i.e.,
--><p>Đề bắt đầu, giả sử ta có tập dữ liệu với <span class="math notranslate nohighlight">\(n\)</span> mẫu, được phân loại
thành <span class="math notranslate nohighlight">\(k\)</span> lớp. Với mỗi mẫu dữ liệu <span class="math notranslate nohighlight">\(i\)</span>, ta biểu diễn nhãn
lớp <span class="math notranslate nohighlight">\(k\)</span> bất kì <span class="math notranslate nohighlight">\(\mathbf{y}_i = (y_{i1}, \ldots, y_{ik})\)</span>
bằng <em>biểu diễn one-hot</em>. Cụ thể, nếu mẫu <span class="math notranslate nohighlight">\(i\)</span> thuộc về lớp
<span class="math notranslate nohighlight">\(j\)</span> thì ta đặt phần tử thứ <span class="math notranslate nohighlight">\(j\)</span> bằng <span class="math notranslate nohighlight">\(1\)</span>, và tất cả các
phần tử khác bằng <span class="math notranslate nohighlight">\(0\)</span>, tức</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-19">
<span class="eqno">(18.11.27)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-19" title="Permalink to this equation">¶</a></span>\[\begin{split}y_{ij} = \begin{cases}1 &amp; j \in J; \\ 0 &amp;\text{otherwise.}\end{cases}\end{split}\]</div>
<!--
For instance, if a multi-class classification problem contains three classes $A$, $B$, and $C$,
then the labels $\mathbf{y}_i$ can be encoded in {$A: (1, 0, 0); B: (0, 1, 0); C: (0, 0, 1)$}.
--><p>Ví dụ, nếu một bài toán phân loại gồm có ba lớp <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span>, và
<span class="math notranslate nohighlight">\(C\)</span>, thì các nhãn <span class="math notranslate nohighlight">\(\mathbf{y}_i\)</span> có thể được mã hóa thành
{<span class="math notranslate nohighlight">\(A: (1, 0, 0); B: (0, 1, 0); C: (0, 0, 1)\)</span>}.</p>
<!--
Assume that our neural network is parameterized by $\theta$.
For true label vectors $\mathbf{y}_i$ and predictions
--><p>Giả sử mạng nơ-ron được tham số hóa bởi <span class="math notranslate nohighlight">\(\theta\)</span>. Với vector nhãn
gốc <span class="math notranslate nohighlight">\(\mathbf{y}_i\)</span> và dự đoán</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-20">
<span class="eqno">(18.11.28)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-20" title="Permalink to this equation">¶</a></span>\[\hat{\mathbf{y}}_i= p_{\theta}(\mathbf{y}_i \mid \mathbf{x}_i) = \sum_{j=1}^k y_{ij} p_{\theta} (y_{ij}  \mid  \mathbf{x}_i).\]</div>
<!--
Hence, the *cross entropy loss* would be
--><p>Từ đó, <em>mất mát entropy chéo</em> sẽ là</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-21">
<span class="eqno">(18.11.29)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-21" title="Permalink to this equation">¶</a></span>\[\begin{split}\mathrm{CE}(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{i=1}^n \mathbf{y}_i \log \hat{\mathbf{y}}_i
 = - \sum_{i=1}^n \sum_{j=1}^k y_{ij} \log{p_{\theta} (y_{ij}  \mid  \mathbf{x}_i)}.\\\end{split}\]</div>
<!--
On the other side, we can also approach the problem through maximum likelihood estimation.
To begin with, let us quickly introduce a $k$-class multinoulli distribution.
It is an extension of the Bernoulli distribution from binary class to multi-class.
If a random variable $\mathbf{z} = (z_{1}, \ldots, z_{k})$ follows a $k$-class *multinoulli distribution* with probabilities $\mathbf{p} =$ ($p_{1}, \ldots, p_{k}$), i.e.,
$$p(\mathbf{z}) = p(z_1, \ldots, z_k) = \mathrm{Multi} (p_1, \ldots, p_k), \text{ where } \sum_{i=1}^k p_i = 1,$$
then the joint probability mass function(p.m.f.) of $\mathbf{z}$ is
$$\mathbf{p}^\mathbf{z} = \prod_{j=1}^k p_{j}^{z_{j}}.$$
--><p>Mặt khác, ta cũng có thể tiếp cận bài toán thông qua ước lượng hợp lý
cực đại. Đề bắt đầu, chúng tôi sẽ giới thiệu nhanh về phân phối đa thức
(<em>multinoulli distribution</em>) <span class="math notranslate nohighlight">\(k\)</span> lớp. Đây là dạng mở rộng của phân
phối Bernoulli từ hai lớp thành nhiều lớp. Nếu một biến ngẫu nhiên
<span class="math notranslate nohighlight">\(\mathbf{z} = (z_{1}, \ldots, z_{k})\)</span> tuân theo <em>phân phối đa
thức</em> <span class="math notranslate nohighlight">\(k\)</span> lớp với xác suất <span class="math notranslate nohighlight">\(\mathbf{p} =\)</span>
(<span class="math notranslate nohighlight">\(p_{1}, \ldots, p_{k}\)</span>), tức</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-22">
<span class="eqno">(18.11.30)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-22" title="Permalink to this equation">¶</a></span>\[ \begin{align}\begin{aligned}p(\mathbf{z}) = p(z_1, \ldots, z_k) = \mathrm{Multi} (p_1, \ldots, p_k), \text{ với } \sum_{i=1}^k p_i = 1,\\thì hàm khối xác suất (*probability mass function - p.m.f*) kết hợp của\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(\mathbf{z}\)</span> bằng</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-23">
<span class="eqno">(18.11.31)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-23" title="Permalink to this equation">¶</a></span>\[\mathbf{p}^\mathbf{z} = \prod_{j=1}^k p_{j}^{z_{j}}.\]</div>
<!--
It can be seen that the label of each data example, $\mathbf{y}_i$,
is following a $k$-class multinoulli distribution with probabilities $\boldsymbol{\pi} =$ ($\pi_{1}, \ldots, \pi_{k}$).
Therefore, the joint p.m.f. of each data example $\mathbf{y}_i$ is  $\mathbf{\pi}^{\mathbf{y}_i} = \prod_{j=1}^k \pi_{j}^{y_{ij}}.$
Hence, the log-likelihood function would be
--><p>Có thể thấy nhãn của từng mẫu dữ liệu, <span class="math notranslate nohighlight">\(\mathbf{y}_i\)</span>, tuân theo
một phân phối đa thức <span class="math notranslate nohighlight">\(k\)</span> lớp với xác suất
<span class="math notranslate nohighlight">\(\boldsymbol{\pi} =\)</span> (<span class="math notranslate nohighlight">\(\pi_{1}, \ldots, \pi_{k}\)</span>). Do đó,
hàm khối xác suất kết hợp của mỗi mẫu dữ liệu là <span class="math notranslate nohighlight">\(\mathbf{y}_i\)</span> is
<span class="math notranslate nohighlight">\(\mathbf{\pi}^{\mathbf{y}_i} = \prod_{j=1}^k \pi_{j}^{y_{ij}}.\)</span> Từ
đây, hàm log hợp lý sẽ là</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-24">
<span class="eqno">(18.11.32)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-24" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
l(\theta)
 = \log L(\theta)
 = \log \prod_{i=1}^n \boldsymbol{\pi}^{\mathbf{y}_i}
 = \log \prod_{i=1}^n \prod_{j=1}^k \pi_{j}^{y_{ij}}
 = \sum_{i=1}^n \sum_{j=1}^k y_{ij} \log{\pi_{j}}.\\
\end{aligned}\end{split}\]</div>
<!--
Since in maximum likelihood estimation, we maximizing the objective function $l(\theta)$ by having $\pi_{j} = p_{\theta} (y_{ij}  \mid  \mathbf{x}_i)$.
Therefore, for any multi-class classification, maximizing the above log-likelihood function $l(\theta)$ is equivalent to minimizing the CE loss $\mathrm{CE}(y, \hat{y})$.
--><p>Do trong ước lượng hợp lý cực đại, ta cực đại hóa hàm mục tiêu
<span class="math notranslate nohighlight">\(l(\theta)\)</span> với
<span class="math notranslate nohighlight">\(\pi_{j} = p_{\theta} (y_{ij} \mid \mathbf{x}_i)\)</span>. Vậy nên với bài
toán phân loại đa lớp bất kỳ, việc cực đại hóa hàm log hợp lý trên
<span class="math notranslate nohighlight">\(l(\theta)\)</span> tương đương với việc cực tiểu hóa hàm mất mát CE
<span class="math notranslate nohighlight">\(\mathrm{CE}(y, \hat{y})\)</span>.</p>
<!--
To test the above proof, let us apply the built-in measure `NegativeLogLikelihood`.
Using the same `labels` and `preds` as in the earlier example, we will get the same numerical loss as the previous example up to the 5 decimal place.
--><p>Để kiểm tra chứng minh trên, hãy áp dụng phép đo
<code class="docutils literal notranslate"><span class="pre">NegativeLogLikelihood</span></code> được tích hợp sẵn. Với việc sử dụng <code class="docutils literal notranslate"><span class="pre">labels</span></code>
và <code class="docutils literal notranslate"><span class="pre">preds</span></code> giống như ví dụ trước, ta sẽ thu được mất mát xấp xỉ giống
ví dụ trước tới 5 số thập phân sau dấu phẩy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nll_loss</span> <span class="o">=</span> <span class="n">NegativeLogLikelihood</span><span class="p">()</span>
<span class="n">nll_loss</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">as_nd_ndarray</span><span class="p">(),</span> <span class="n">preds</span><span class="o">.</span><span class="n">as_nd_ndarray</span><span class="p">())</span>
<span class="n">nll_loss</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="s1">&#39;nll-loss&#39;</span><span class="p">,</span> <span class="mf">0.9485599994659424</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="tom-tat">
<h2><span class="section-number">18.11.6. </span>Tóm tắt<a class="headerlink" href="#tom-tat" title="Permalink to this headline">¶</a></h2>
<!--
* Information theory is a field of study about encoding, decoding, transmitting, and manipulating information.
* Entropy is the unit to measure how much information is presented in different signals.
* KL divergence can also measure the divergence between two distributions.
* Cross Entropy can be viewed as an objective function of multi-class classification.
Minimizing cross entropy loss is equivalent to maximizing the log-likelihood function.
--><ul class="simple">
<li>Lý thuyết thông tin là một lĩnh vực nghiên cứu về mã hóa, giải mã,
truyền phát và xử lý thông tin.</li>
<li>Entropy là đơn vị đo lượng thông tin có trong các tín hiệu khác nhau.</li>
<li>Phân kỳ KL có thể đo khoảng cách giữa hai phân phối.</li>
<li>Entropy Chéo có thể được coi như một hàm mục tiêu trong phân loại đa
lớp. Việc cực tiểu hóa mất mát entropy chéo tương đương với việc cực
đại hóa hàm log hợp lý.</li>
</ul>
</div>
<div class="section" id="bai-tap">
<h2><span class="section-number">18.11.7. </span>Bài tập<a class="headerlink" href="#bai-tap" title="Permalink to this headline">¶</a></h2>
<!--
1. Verify that the card examples from the first section indeed have the claimed entropy.
2. Show that the KL divergence $D(p\|q)$ is nonnegative for all distributions $p$ and $q$.
Hint: use Jensen's inequality, i.e., use the fact that $-\log x$ is a convex function.
3. Let us compute the entropy from a few data sources:
    * Assume that you are watching the output generated by a monkey at a typewriter.
    The monkey presses any of the $44$ keys of the typewriter at random (you can assume that it has not discovered any special keys or the shift key yet).
    How many bits of randomness per character do you observe?
    * Being unhappy with the monkey, you replaced it by a drunk typesetter.
    It is able to generate words, albeit not coherently.
    Instead, it picks a random word out of a vocabulary of $2,000$ words.
    Let us assume that the average length of a word is $4.5$ letters in English.
    How many bits of randomness do you observe per character now?
    * Still being unhappy with the result, you replace the typesetter by a high quality language model.
    The language model can currently obtain a perplexity as low as $15$ points per word.
    The character *perplexity* of a language model on a test word is defined as the product of the inverse probability of each character appeared in the test word,
    normalized by the length of the word, i.e.,
    $$PPL(\text{word}) = \left[\prod_i p(\text{character}_i)\right]^{ -\frac{1}{\text{length(word)}} }.$$
    Assume the test word has $4.5$ letters, how many bits of randomness do you observe per character now?
4. Explain intuitively why $I(X, Y) = H(X) - H(X|Y)$. Then, show this is true by expressing both sides as an expectation with respect to the joint distribution.
5. What is the KL Divergence between the two Gaussian distributions $\mathcal{N}(\mu_1, \sigma_1^2)$ and $\mathcal{N}(\mu_2, \sigma_2^2)$?
--><ol class="arabic">
<li><p class="first">Kiểm chứng rằng ví dụ lá bài ở phần đầu quả thực có entropy như đã
nhận định.</p>
</li>
<li><p class="first">Chứng minh rằng phân kỳ KL <span class="math notranslate nohighlight">\(D(p\|q)\)</span> là không âm với mọi phân
phối <span class="math notranslate nohighlight">\(p\)</span> và <span class="math notranslate nohighlight">\(q\)</span>. Gợi ý: sử dụng bất đẳng thức Jensen, tức
là sử dụng thực tế là <span class="math notranslate nohighlight">\(-\log x\)</span> là một hàm lồi.</p>
</li>
<li><p class="first">Hãy tính entropy từ một số nguồn dữ liệu sau:</p>
<ul>
<li><p class="first">Giả sử bạn đang theo dõi văn bản sinh ra khi một con khỉ dùng máy
đánh chữ. Con khỉ nhấn ngẫu nhiên bất kì phím nào trong <span class="math notranslate nohighlight">\(44\)</span>
phím của máy đánh chữ (bạn có thể giả sử nó chưa phát hiện ra phím
shift hay bất kì phím đặc biệt nào). Mỗi kí tự ngẫu nhiên bạn quan
sát được chứa bao nhiêu bit?</p>
</li>
<li><p class="first">Giả sử thay vì con khỉ, ta có một người đang say rượu đánh chữ.
Người đó có thể tạo ra các từ ngẫu nhiên trong bảng từ vựng gồm
<span class="math notranslate nohighlight">\(2,000\)</span> từ, mặc dù câu văn không được mạch lạc. Giả sử độ
dài trung bình của một từ là <span class="math notranslate nohighlight">\(4.5\)</span> chữ cái Tiếng Anh. Lúc
này mỗi ký tự ngẫu nhiên bạn quan sát được chứa bao nhiêu bit?</p>
</li>
<li><p class="first">Vẫn không hài lòng với kết quả, bạn dùng một mô hình ngôn ngữ chất
lượng cao, có perplexity chỉ cỡ <span class="math notranslate nohighlight">\(15\)</span> điểm cho mỗi từ.
<em>Perplexity</em> mức ký tự của một mô hình ngôn ngữ trên một từ được
định nghĩa là tích của nghịch đảo xác suất của mỗi ký tự xuất hiện
trong từ đó, rồi được chuẩn hóa bằng độ dài của từ như sau</p>
<div class="math notranslate nohighlight" id="equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-25">
<span class="eqno">(18.11.33)<a class="headerlink" href="#equation-chapter-appendix-mathematics-for-deep-learning-information-theory-vn-25" title="Permalink to this equation">¶</a></span>\[ \begin{align}\begin{aligned}PPL(\text{từ}) = \left[\prod_i p(\text{ký tự}_i)\right]^{ -\frac{1}{\text{length(từ)}} }.\\Giả sử từ kiểm tra có :math:`4.5` chữ cái, lúc này mỗi ký tự ngẫu\end{aligned}\end{align} \]</div>
<p>nhiên bạn quan sát được chứa bao nhiêu bit?</p>
</li>
</ul>
</li>
<li><p class="first">Giải thích một cách trực quan tại sao
<span class="math notranslate nohighlight">\(I(X, Y) = H(X) - H(X|Y)\)</span>. Sau đó, chứng minh biểu thức này
đúng bằng cách biểu diễn hai vế theo kỳ vọng của phân phối kết hợp.</p>
</li>
<li><p class="first">Phân kỳ KL giữa hai phân phối Gauss
<span class="math notranslate nohighlight">\(\mathcal{N}(\mu_1, \sigma_1^2)\)</span> và
<span class="math notranslate nohighlight">\(\mathcal{N}(\mu_2, \sigma_2^2)\)</span> là gì?</p>
</li>
</ol>
</div>
<div class="section" id="thao-luan">
<h2><span class="section-number">18.11.8. </span>Thảo luận<a class="headerlink" href="#thao-luan" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Tiếng Anh: <a class="reference external" href="https://discuss.d2l.ai/t/420">MXNet</a></li>
<li>Tiếng Việt: <a class="reference external" href="https://forum.machinelearningcoban.com/c/d2l">Diễn đàn Machine Learning Cơ
Bản</a></li>
</ul>
</div>
<div class="section" id="nhung-nguoi-thuc-hien">
<h2><span class="section-number">18.11.9. </span>Những người thực hiện<a class="headerlink" href="#nhung-nguoi-thuc-hien" title="Permalink to this headline">¶</a></h2>
<p>Bản dịch trong trang này được thực hiện bởi:</p>
<ul class="simple">
<li>Đoàn Võ Duy Thanh</li>
<li>Trần Yến Thy</li>
<li>Nguyễn Thanh Hòa</li>
<li>Lê Khắc Hồng Phúc</li>
<li>Nguyễn Lê Quang Nhật</li>
<li>Phạm Hồng Vinh</li>
<li>Phạm Minh Đức</li>
<li>Nguyễn Mai Hoàng Long</li>
<li>Đỗ Trường Giang</li>
<li>Nguyễn Văn Cường</li>
</ul>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">18.11. Lý thuyết Thông tin</a><ul>
<li><a class="reference internal" href="#thong-tin">18.11.1. Thông tin</a><ul>
<li><a class="reference internal" href="#luong-tin">18.11.1.1. Lượng tin</a></li>
</ul>
</li>
<li><a class="reference internal" href="#entropy">18.11.2. Entropy</a><ul>
<li><a class="reference internal" href="#phat-trien-ly-thuyet-entropy">18.11.2.1. Phát triển Lý thuyết Entropy</a></li>
<li><a class="reference internal" href="#dinh-nghia">18.11.2.2. Định nghĩa</a></li>
<li><a class="reference internal" href="#dien-giai">18.11.2.3. Diễn giải</a></li>
<li><a class="reference internal" href="#tinh-chat-cua-entropy">18.11.2.4. Tính chất của Entropy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#thong-tin-tuong-ho">18.11.3. Thông tin Tương hỗ</a><ul>
<li><a class="reference internal" href="#entropy-ket-hop">18.11.3.1. Entropy Kết hợp</a></li>
<li><a class="reference internal" href="#entropy-co-dieu-kien">18.11.3.2. Entropy có Điều kiện</a></li>
<li><a class="reference internal" href="#id3">18.11.3.3. Thông tin Tương hỗ</a></li>
<li><a class="reference internal" href="#tinh-chat-cua-thong-tin-tuong-ho">18.11.3.4. Tính chất của Thông tin Tương Hỗ</a></li>
<li><a class="reference internal" href="#thong-tin-tuong-ho-theo-tung-diem">18.11.3.5. Thông tin Tương hỗ theo từng Điểm</a></li>
<li><a class="reference internal" href="#ung-dung-thong-tin-tuong-ho">18.11.3.6. Ứng dụng Thông tin Tương hỗ</a></li>
</ul>
</li>
<li><a class="reference internal" href="#phan-ky-kullbackleibler">18.11.4. Phân kỳ Kullback–Leibler</a><ul>
<li><a class="reference internal" href="#id6">18.11.4.1. Định nghĩa</a></li>
<li><a class="reference internal" href="#cac-tinh-chat-cua-phan-ky-kl">18.11.4.2. Các tính chất của Phân kỳ KL</a></li>
<li><a class="reference internal" href="#vi-du">18.11.4.3. Ví dụ</a></li>
</ul>
</li>
<li><a class="reference internal" href="#entropy-cheo">18.11.5. Entropy Chéo</a><ul>
<li><a class="reference internal" href="#dinh-nghia-chuan">18.11.5.1. Định nghĩa Chuẩn</a></li>
<li><a class="reference internal" href="#tinh-chat">18.11.5.2. Tính chất</a></li>
<li><a class="reference internal" href="#ham-muc-tieu-entropy-cheo-khi-phan-loai-da-lop">18.11.5.3. Hàm Mục tiêu Entropy Chéo khi Phân loại Đa lớp</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tom-tat">18.11.6. Tóm tắt</a></li>
<li><a class="reference internal" href="#bai-tap">18.11.7. Bài tập</a></li>
<li><a class="reference internal" href="#thao-luan">18.11.8. Thảo luận</a></li>
<li><a class="reference internal" href="#nhung-nguoi-thuc-hien">18.11.9. Những người thực hiện</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="statistics_vn.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>18.10. Thống kê</div>
         </div>
     </a>
     <a id="button-next" href="../chapter_appendix-tools-for-deep-learning/index_vn.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>19. Phụ lục: Công cụ cho Học Sâu</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>