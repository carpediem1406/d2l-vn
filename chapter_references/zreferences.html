<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>Tài liệu tham khảo &#8212; Đắm mình vào Học Sâu 0.14.4 documentation</title>

    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Bảng thuật ngữ" href="../glossary.html" />
    <link rel="prev" title="19.7. Tài liệu API của d2l" href="../chapter_appendix-tools-for-deep-learning/d2l_vn.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link is-active">Tài liệu tham khảo</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_references/zreferences.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/aivivn/d2l-vn">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://forum.machinelearningcoban.com/">
                  <i class="fab fa-discourse"></i>
                  Forum
              </a>
          
              <a  class="mdl-navigation__link" href="https://www.d2l.ai/">
                  <i class="fas fa-external-link-alt"></i>
                  English
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text-vi.png" alt="Đắm mình vào Học Sâu"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro_vn.html">Giới thiệu từ nhóm dịch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index_vn.html">Lời nói đầu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_install/index_vn.html">Cài đặt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index_vn.html">Ký hiệu</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index_vn.html">1. Giới thiệu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index_vn.html">2. Sơ bộ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray_vn.html">2.1. Thao tác với Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas_vn.html">2.2. Tiền xử lý dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra_vn.html">2.3. Đại số tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus_vn.html">2.4. Giải tích</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd_vn.html">2.5. Tính vi phân Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability_vn.html">2.6. Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api_vn.html">2.7. Tài liệu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-networks/index_vn.html">3. Mạng nơ-ron Tuyến tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression_vn.html">3.1. Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-scratch_vn.html">3.2. Lập trình Hồi quy Tuyến tính từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-gluon_vn.html">3.3. Cách lập trình súc tích Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression_vn.html">3.4. Hồi quy Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/fashion-mnist_vn.html">3.5. Bộ dữ liệu Phân loại Ảnh (Fashion-MNIST)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-scratch_vn.html">3.6. Lập trình Hồi quy Sofmax từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-gluon_vn.html">3.7. Cách lập trình súc tích Hồi quy Softmax</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index_vn.html">4. Perceptron Đa tầng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp_vn.html">4.1. Perceptron đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-scratch_vn.html">4.2. Lập trình Perceptron Đa tầng từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-gluon_vn.html">4.3. Cách lập trình súc tích Perceptron Đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/underfit-overfit_vn.html">4.4. Lựa Chọn Mô Hình, Dưới Khớp và Quá Khớp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/weight-decay_vn.html">4.5. Suy giảm trọng số</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout_vn.html">4.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop_vn.html">4.7. Lan truyền xuôi, Lan truyền ngược và Đồ thị tính toán</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init_vn.html">4.8. Ổn định Số học và Khởi tạo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/environment_vn.html">4.9. Cân nhắc tới Môi trường</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price_vn.html">4.10. Dự đoán Giá Nhà trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_deep-learning-computation/index_vn.html">5. Tính toán Học sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/model-construction_vn.html">5.1. Tầng và Khối</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/parameters_vn.html">5.2. Quản lý Tham số</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/deferred-init_vn.html">5.3. Khởi tạo trễ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/custom-layer_vn.html">5.4. Các tầng Tuỳ chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/read-write_vn.html">5.5. Đọc/Ghi tệp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/use-gpu_vn.html">5.6. GPU</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index_vn.html">6. Mạng Nơ-ron Tích chập</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv_vn.html">6.1. Từ Tầng Kết nối Dày đặc đến phép Tích chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer_vn.html">6.2. Phép Tích chập cho Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides_vn.html">6.3. Đệm và Sải Bước</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels_vn.html">6.4. Đa kênh Đầu vào và Đầu ra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling_vn.html">6.5. Gộp (<em>Pooling</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet_vn.html">6.6. Mạng Nơ-ron Tích chập (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index_vn.html">7. Mạng Nơ-ron Tích chập Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet_vn.html">7.1. Mạng Nơ-ron Tích chập Sâu (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/vgg_vn.html">7.2. Mạng sử dụng Khối (VGG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/nin_vn.html">7.3. Mạng trong Mạng (<em>Network in Network - NiN</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet_vn.html">7.4. Mạng nối song song (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm_vn.html">7.5. Chuẩn hoá theo batch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet_vn.html">7.6. Mạng phần dư (ResNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet_vn.html">7.7. Mạng Tích chập Kết nối Dày đặc (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index_vn.html">8. Mạng Nơ-ron Hồi tiếp</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence_vn.html">8.1. Mô hình chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-preprocessing_vn.html">8.2. Tiền Xử lý Dữ liệu Văn bản</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-models-and-dataset_vn.html">8.3. Mô hình Ngôn ngữ và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn_vn.html">8.4. Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch_vn.html">8.5. Lập trình Mạng nơ-ron Hồi tiếp từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-gluon_vn.html">8.6. Lập trình súc tích Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt_vn.html">8.7. Lan truyền Ngược qua Thời gian</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index_vn.html">9. Mạng Nơ-ron Hồi tiếp Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru_vn.html">9.1. Nút Hồi tiếp có Cổng (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm_vn.html">9.2. Bộ nhớ Ngắn hạn Dài (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn_vn.html">9.3. Mạng Nơ-ron Hồi tiếp Sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/bi-rnn_vn.html">9.4. Mạng Nơ-ron Hồi tiếp Hai chiều</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset_vn.html">9.5. Dịch Máy và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder_vn.html">9.6. Kiến trúc Mã hoá - Giải mã</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq_vn.html">9.7. Chuỗi sang Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search_vn.html">9.8. Tìm kiếm Chùm</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms/index_vn.html">10. Cơ chế Tập trung</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/attention_vn.html">10.1. Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/seq2seq-attention_vn.html">10.2. Chuỗi sang Chuỗi áp dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/transformer_vn.html">10.3. Kiến trúc Transformer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index_vn.html">11. Thuật toán Tối ưu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html">11.1. Tối ưu và Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-thach-thuc-cua-toi-uu-trong-hoc-sau">11.2. Các Thách thức của Tối ưu trong Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-vung-cuc-tieu">11.3. Các vùng Cực tiểu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-diem-yen-ngua">11.4. Các điểm Yên ngựa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#tieu-bien-gradient">11.5. Tiêu biến Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity_vn.html">11.6. Tính lồi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd_vn.html">11.7. Hạ Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd_vn.html">11.8. Hạ Gradient Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd_vn.html">11.9. Hạ Gradient Ngẫu nhiên theo Minibatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum_vn.html">11.10. Động lượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad_vn.html">11.11. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop_vn.html">11.12. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta_vn.html">11.13. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam_vn.html">11.14. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler_vn.html">11.15. Định thời Tốc độ Học</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational-performance/index_vn.html">12. Hiệu năng Tính toán</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hybridize_vn.html">12.1. Trình biên dịch và Trình thông dịch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/async-computation_vn.html">12.2. Tính toán Bất đồng bộ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/auto-parallelism_vn.html">12.3. Song song hóa Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hardware_vn.html">12.4. Phần cứng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus_vn.html">12.5. Huấn luyện đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus-concise_vn.html">12.6. Cách lập trình Súc tích đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/parameterserver_vn.html">12.7. Máy chủ Tham số</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index_vn.html">13. Thị giác Máy tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation_vn.html">13.1. Tăng cường Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning_vn.html">13.2. Tinh Chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box_vn.html">13.3. Phát hiện Vật thể và Khoanh vùng Đối tượng (Khung chứa)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor_vn.html">13.4. Khung neo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection_vn.html">13.5. Phát hiện Vật thể Đa tỷ lệ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset_vn.html">13.6. Tập dữ liệu Phát hiện Đối tượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd_vn.html">13.7. Phát hiện Nhiều khung Một lượt (SSD)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn_vn.html">13.8. CNN theo Vùng (R-CNN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset_vn.html">13.9. Phân vùng theo Ngữ nghĩa và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv_vn.html">13.10. Tích chập Chuyển vị</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn_vn.html">13.11. Mạng Tích chập Đầy đủ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style_vn.html">13.12. Truyền tải Phong cách Nơ-ron</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10_vn.html">13.13. Phân loại ảnh (CIFAR-10) trên Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog_vn.html">13.14. Nhận diện Giống Chó (ImageNet Dogs) trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index_vn.html">14. Xử lý Ngôn ngữ Tự nhiên: Tiền Huấn luyện</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec_vn.html">14.1. Embedding Từ (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training_vn.html">14.2. Huấn luyện Gần đúng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset_vn.html">14.3. Tập dữ liệu để Tiền Huấn luyện Embedding Từ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining_vn.html">14.4. Tiền huấn luyện word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove_vn.html">14.5. Embedding từ với Vector Toàn cục (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding_vn.html">14.6. Embedding từ con</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy_vn.html">14.7. Tìm kiếm từ Đồng nghĩa và Loại suy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert_vn.html">14.8. Biểu diễn Mã hóa hai chiều từ Transformer (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset_vn.html">14.9. Tập dữ liệu để Tiền huấn luyện BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining_vn.html">14.10. Tiền Huấn luyện BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index_vn.html">15. Xử lý Ngôn ngữ Tự nhiên: Ứng dụng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset_vn.html">15.1. Tác vụ Phân tích Cảm xúc và Bộ Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn_vn.html">15.2. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn_vn.html">15.3. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Tích Chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset_vn.html">15.4. Suy luận ngôn ngữ tự nhiên và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention_vn.html">15.5. Suy luận Ngôn ngữ Tự nhiên: Sử dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert_vn.html">15.6. Tinh chỉnh BERT cho các Ứng dụng Cấp Chuỗi và Cấp Token</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-bert_vn.html">15.7. Suy luận Ngôn ngữ Tự nhiên: Tinh chỉnh BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender-systems/index_vn.html">16. Hệ thống Đề xuất</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/recsys-intro_vn.html">16.1. Tổng quan về Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/movielens_vn.html">16.2. Tập dữ liệu MovieLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/mf_vn.html">16.3. Phân rã Ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/autorec_vn.html">16.4. AutoRec: Dự đoán Đánh giá với Bộ tự Mã hóa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ranking_vn.html">16.5. Cá nhân hóa Xếp hạng trong Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/neumf_vn.html">16.6. Lọc Cộng tác Nơ-ron cho Cá nhân hóa Xếp hạng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/seqrec_vn.html">16.7. Hệ thống Đề xuất có Nhận thức về Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ctr_vn.html">16.8. Hệ thống Đề xuất Giàu Đặc trưng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/fm_vn.html">16.9. Máy Phân rã ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/deepfm_vn.html">16.10. Máy Phân rã Ma trận Sâu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_generative-adversarial-networks/index_vn.html">17. Mạng Đối sinh</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/gan_vn.html">17.1. Mạng Đối sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/dcgan_vn.html">17.2. Mạng Đối sinh Tích chập Sâu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/index_vn.html">18. Phụ lục: Toán học cho Học Sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops_vn.html">18.1. Các phép toán Hình học và Đại số Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition_vn.html">18.2. Phân rã trị riêng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus_vn.html">18.3. Giải tích một biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus_vn.html">18.4. Giải tích Nhiều biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus_vn.html">18.5. Giải tích Tích phân</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/random-variables_vn.html">18.6. Biến Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood_vn.html">18.7. Hợp lý Cực đại</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/distributions_vn.html">18.8. Các Phân phối Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes_vn.html">18.9. Bộ phân loại Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/statistics_vn.html">18.10. Thống kê</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/information-theory_vn.html">18.11. Lý thuyết Thông tin</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index_vn.html">19. Phụ lục: Công cụ cho Học Sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/jupyter_vn.html">19.1. Sử dụng Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/sagemaker_vn.html">19.2. Sử dụng Amazon SageMaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/aws_vn.html">19.3. Sử dụng Máy ảo AWS EC2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/colab_vn.html">19.4. Sử dụng Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus_vn.html">19.5. Lựa chọn Máy chủ &amp; GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/contributing_vn.html">19.6. Đóng góp cho Quyển sách</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/d2l_vn.html">19.7. Tài liệu API của <code class="docutils literal notranslate"><span class="pre">d2l</span></code></a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tài liệu tham khảo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Bảng thuật ngữ</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text-vi.png" alt="Đắm mình vào Học Sâu"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro_vn.html">Giới thiệu từ nhóm dịch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index_vn.html">Lời nói đầu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_install/index_vn.html">Cài đặt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index_vn.html">Ký hiệu</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index_vn.html">1. Giới thiệu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index_vn.html">2. Sơ bộ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray_vn.html">2.1. Thao tác với Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas_vn.html">2.2. Tiền xử lý dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra_vn.html">2.3. Đại số tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus_vn.html">2.4. Giải tích</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd_vn.html">2.5. Tính vi phân Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability_vn.html">2.6. Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api_vn.html">2.7. Tài liệu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-networks/index_vn.html">3. Mạng nơ-ron Tuyến tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression_vn.html">3.1. Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-scratch_vn.html">3.2. Lập trình Hồi quy Tuyến tính từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-gluon_vn.html">3.3. Cách lập trình súc tích Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression_vn.html">3.4. Hồi quy Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/fashion-mnist_vn.html">3.5. Bộ dữ liệu Phân loại Ảnh (Fashion-MNIST)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-scratch_vn.html">3.6. Lập trình Hồi quy Sofmax từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-gluon_vn.html">3.7. Cách lập trình súc tích Hồi quy Softmax</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index_vn.html">4. Perceptron Đa tầng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp_vn.html">4.1. Perceptron đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-scratch_vn.html">4.2. Lập trình Perceptron Đa tầng từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-gluon_vn.html">4.3. Cách lập trình súc tích Perceptron Đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/underfit-overfit_vn.html">4.4. Lựa Chọn Mô Hình, Dưới Khớp và Quá Khớp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/weight-decay_vn.html">4.5. Suy giảm trọng số</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout_vn.html">4.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop_vn.html">4.7. Lan truyền xuôi, Lan truyền ngược và Đồ thị tính toán</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init_vn.html">4.8. Ổn định Số học và Khởi tạo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/environment_vn.html">4.9. Cân nhắc tới Môi trường</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price_vn.html">4.10. Dự đoán Giá Nhà trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_deep-learning-computation/index_vn.html">5. Tính toán Học sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/model-construction_vn.html">5.1. Tầng và Khối</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/parameters_vn.html">5.2. Quản lý Tham số</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/deferred-init_vn.html">5.3. Khởi tạo trễ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/custom-layer_vn.html">5.4. Các tầng Tuỳ chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/read-write_vn.html">5.5. Đọc/Ghi tệp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deep-learning-computation/use-gpu_vn.html">5.6. GPU</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index_vn.html">6. Mạng Nơ-ron Tích chập</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv_vn.html">6.1. Từ Tầng Kết nối Dày đặc đến phép Tích chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer_vn.html">6.2. Phép Tích chập cho Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides_vn.html">6.3. Đệm và Sải Bước</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels_vn.html">6.4. Đa kênh Đầu vào và Đầu ra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling_vn.html">6.5. Gộp (<em>Pooling</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet_vn.html">6.6. Mạng Nơ-ron Tích chập (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index_vn.html">7. Mạng Nơ-ron Tích chập Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet_vn.html">7.1. Mạng Nơ-ron Tích chập Sâu (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/vgg_vn.html">7.2. Mạng sử dụng Khối (VGG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/nin_vn.html">7.3. Mạng trong Mạng (<em>Network in Network - NiN</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet_vn.html">7.4. Mạng nối song song (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm_vn.html">7.5. Chuẩn hoá theo batch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet_vn.html">7.6. Mạng phần dư (ResNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet_vn.html">7.7. Mạng Tích chập Kết nối Dày đặc (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index_vn.html">8. Mạng Nơ-ron Hồi tiếp</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence_vn.html">8.1. Mô hình chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-preprocessing_vn.html">8.2. Tiền Xử lý Dữ liệu Văn bản</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-models-and-dataset_vn.html">8.3. Mô hình Ngôn ngữ và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn_vn.html">8.4. Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch_vn.html">8.5. Lập trình Mạng nơ-ron Hồi tiếp từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-gluon_vn.html">8.6. Lập trình súc tích Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt_vn.html">8.7. Lan truyền Ngược qua Thời gian</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index_vn.html">9. Mạng Nơ-ron Hồi tiếp Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru_vn.html">9.1. Nút Hồi tiếp có Cổng (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm_vn.html">9.2. Bộ nhớ Ngắn hạn Dài (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn_vn.html">9.3. Mạng Nơ-ron Hồi tiếp Sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/bi-rnn_vn.html">9.4. Mạng Nơ-ron Hồi tiếp Hai chiều</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset_vn.html">9.5. Dịch Máy và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder_vn.html">9.6. Kiến trúc Mã hoá - Giải mã</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq_vn.html">9.7. Chuỗi sang Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search_vn.html">9.8. Tìm kiếm Chùm</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms/index_vn.html">10. Cơ chế Tập trung</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/attention_vn.html">10.1. Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/seq2seq-attention_vn.html">10.2. Chuỗi sang Chuỗi áp dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/transformer_vn.html">10.3. Kiến trúc Transformer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index_vn.html">11. Thuật toán Tối ưu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html">11.1. Tối ưu và Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-thach-thuc-cua-toi-uu-trong-hoc-sau">11.2. Các Thách thức của Tối ưu trong Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-vung-cuc-tieu">11.3. Các vùng Cực tiểu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-diem-yen-ngua">11.4. Các điểm Yên ngựa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#tieu-bien-gradient">11.5. Tiêu biến Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity_vn.html">11.6. Tính lồi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd_vn.html">11.7. Hạ Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd_vn.html">11.8. Hạ Gradient Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd_vn.html">11.9. Hạ Gradient Ngẫu nhiên theo Minibatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum_vn.html">11.10. Động lượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad_vn.html">11.11. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop_vn.html">11.12. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta_vn.html">11.13. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam_vn.html">11.14. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler_vn.html">11.15. Định thời Tốc độ Học</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational-performance/index_vn.html">12. Hiệu năng Tính toán</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hybridize_vn.html">12.1. Trình biên dịch và Trình thông dịch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/async-computation_vn.html">12.2. Tính toán Bất đồng bộ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/auto-parallelism_vn.html">12.3. Song song hóa Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hardware_vn.html">12.4. Phần cứng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus_vn.html">12.5. Huấn luyện đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus-concise_vn.html">12.6. Cách lập trình Súc tích đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/parameterserver_vn.html">12.7. Máy chủ Tham số</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index_vn.html">13. Thị giác Máy tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation_vn.html">13.1. Tăng cường Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning_vn.html">13.2. Tinh Chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box_vn.html">13.3. Phát hiện Vật thể và Khoanh vùng Đối tượng (Khung chứa)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor_vn.html">13.4. Khung neo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection_vn.html">13.5. Phát hiện Vật thể Đa tỷ lệ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset_vn.html">13.6. Tập dữ liệu Phát hiện Đối tượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd_vn.html">13.7. Phát hiện Nhiều khung Một lượt (SSD)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn_vn.html">13.8. CNN theo Vùng (R-CNN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset_vn.html">13.9. Phân vùng theo Ngữ nghĩa và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv_vn.html">13.10. Tích chập Chuyển vị</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn_vn.html">13.11. Mạng Tích chập Đầy đủ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style_vn.html">13.12. Truyền tải Phong cách Nơ-ron</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10_vn.html">13.13. Phân loại ảnh (CIFAR-10) trên Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog_vn.html">13.14. Nhận diện Giống Chó (ImageNet Dogs) trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index_vn.html">14. Xử lý Ngôn ngữ Tự nhiên: Tiền Huấn luyện</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec_vn.html">14.1. Embedding Từ (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training_vn.html">14.2. Huấn luyện Gần đúng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset_vn.html">14.3. Tập dữ liệu để Tiền Huấn luyện Embedding Từ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining_vn.html">14.4. Tiền huấn luyện word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove_vn.html">14.5. Embedding từ với Vector Toàn cục (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding_vn.html">14.6. Embedding từ con</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy_vn.html">14.7. Tìm kiếm từ Đồng nghĩa và Loại suy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert_vn.html">14.8. Biểu diễn Mã hóa hai chiều từ Transformer (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset_vn.html">14.9. Tập dữ liệu để Tiền huấn luyện BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining_vn.html">14.10. Tiền Huấn luyện BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index_vn.html">15. Xử lý Ngôn ngữ Tự nhiên: Ứng dụng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset_vn.html">15.1. Tác vụ Phân tích Cảm xúc và Bộ Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn_vn.html">15.2. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn_vn.html">15.3. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Tích Chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset_vn.html">15.4. Suy luận ngôn ngữ tự nhiên và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention_vn.html">15.5. Suy luận Ngôn ngữ Tự nhiên: Sử dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert_vn.html">15.6. Tinh chỉnh BERT cho các Ứng dụng Cấp Chuỗi và Cấp Token</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-bert_vn.html">15.7. Suy luận Ngôn ngữ Tự nhiên: Tinh chỉnh BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender-systems/index_vn.html">16. Hệ thống Đề xuất</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/recsys-intro_vn.html">16.1. Tổng quan về Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/movielens_vn.html">16.2. Tập dữ liệu MovieLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/mf_vn.html">16.3. Phân rã Ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/autorec_vn.html">16.4. AutoRec: Dự đoán Đánh giá với Bộ tự Mã hóa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ranking_vn.html">16.5. Cá nhân hóa Xếp hạng trong Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/neumf_vn.html">16.6. Lọc Cộng tác Nơ-ron cho Cá nhân hóa Xếp hạng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/seqrec_vn.html">16.7. Hệ thống Đề xuất có Nhận thức về Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ctr_vn.html">16.8. Hệ thống Đề xuất Giàu Đặc trưng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/fm_vn.html">16.9. Máy Phân rã ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/deepfm_vn.html">16.10. Máy Phân rã Ma trận Sâu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_generative-adversarial-networks/index_vn.html">17. Mạng Đối sinh</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/gan_vn.html">17.1. Mạng Đối sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/dcgan_vn.html">17.2. Mạng Đối sinh Tích chập Sâu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/index_vn.html">18. Phụ lục: Toán học cho Học Sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops_vn.html">18.1. Các phép toán Hình học và Đại số Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition_vn.html">18.2. Phân rã trị riêng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus_vn.html">18.3. Giải tích một biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus_vn.html">18.4. Giải tích Nhiều biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus_vn.html">18.5. Giải tích Tích phân</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/random-variables_vn.html">18.6. Biến Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood_vn.html">18.7. Hợp lý Cực đại</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/distributions_vn.html">18.8. Các Phân phối Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes_vn.html">18.9. Bộ phân loại Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/statistics_vn.html">18.10. Thống kê</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/information-theory_vn.html">18.11. Lý thuyết Thông tin</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index_vn.html">19. Phụ lục: Công cụ cho Học Sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/jupyter_vn.html">19.1. Sử dụng Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/sagemaker_vn.html">19.2. Sử dụng Amazon SageMaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/aws_vn.html">19.3. Sử dụng Máy ảo AWS EC2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/colab_vn.html">19.4. Sử dụng Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus_vn.html">19.5. Lựa chọn Máy chủ &amp; GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/contributing_vn.html">19.6. Đóng góp cho Quyển sách</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/d2l_vn.html">19.7. Tài liệu API của <code class="docutils literal notranslate"><span class="pre">d2l</span></code></a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tài liệu tham khảo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Bảng thuật ngữ</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="tai-lieu-tham-khao">
<h1>Tài liệu tham khảo<a class="headerlink" href="#tai-lieu-tham-khao" title="Permalink to this headline">¶</a></h1>
</div>
<p id="bibtex-bibliography-chapter_references/zreferences-0"><table class="bibtex docutils citation" frame="void" id="ahmed-aly-gonzalez-ea-2012" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Ahmed et al., 2012]</td><td>Ahmed, A., Aly, M., Gonzalez, J., Narayanamurthy, S., &amp; Smola, A.&nbsp;J. (2012). Scalable inference in latent variable models. <em>Proceedings of the fifth ACM international conference on Web search and data mining</em> (pp.&nbsp;123–132).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="aji-mceliece-2000" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Aji &amp; McEliece, 2000]</td><td>Aji, S.&nbsp;M., &amp; McEliece, R.&nbsp;J. (2000). The generalized distributive law. <em>IEEE transactions on Information Theory</em>, <em>46</em>(2), 325–343.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="bahdanau-cho-bengio-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Bahdanau et al., 2014]</td><td>Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. <em>arXiv preprint arXiv:1409.0473</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="bishop-1995" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Bishop, 1995]</td><td>Bishop, C.&nbsp;M. (1995). Training with noise is equivalent to tikhonov regularization. <em>Neural computation</em>, <em>7</em>(1), 108–116.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="bishop-2006" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Bishop, 2006]</td><td>Bishop, C.&nbsp;M. (2006). <em>Pattern recognition and machine learning</em>. springer.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="bojanowski-grave-joulin-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Bojanowski et al., 2017]</td><td>Bojanowski, P., Grave, E., Joulin, A., &amp; Mikolov, T. (2017). Enriching word vectors with subword information. <em>Transactions of the Association for Computational Linguistics</em>, <em>5</em>, 135–146.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="bollobas-1999" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Bollobas, 1999]</td><td>Bollobás, B. (1999). <em>Linear analysis</em>. Cambridge University Press, Cambridge.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="bowman-angeli-potts-ea-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Bowman et al., 2015]</td><td>Bowman, S.&nbsp;R., Angeli, G., Potts, C., &amp; Manning, C.&nbsp;D. (2015). A large annotated corpus for learning natural language inference. <em>arXiv preprint arXiv:1508.05326</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="boyd-vandenberghe-2004" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Boyd &amp; Vandenberghe, 2004]</td><td>Boyd, S., &amp; Vandenberghe, L. (2004). <em>Convex Optimization</em>. Cambridge, England: Cambridge University Press.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="brown-sandholm-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Brown &amp; Sandholm, 2017]</td><td>Brown, N., &amp; Sandholm, T. (2017). Libratus: the superhuman ai for no-limit poker. <em>IJCAI</em> (pp.&nbsp;5226–5228).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="campbell-hoane-jr-hsu-2002" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Campbell et al., 2002]</td><td>Campbell, M., Hoane&nbsp;Jr, A.&nbsp;J., &amp; Hsu, F.-h. (2002). Deep blue. <em>Artificial intelligence</em>, <em>134</em>(1-2), 57–83.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="cer-diab-agirre-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Cer et al., 2017]</td><td>Cer, D., Diab, M., Agirre, E., Lopez-Gazpio, I., &amp; Specia, L. (2017). Semeval-2017 task 1: semantic textual similarity multilingual and crosslingual focused evaluation. <em>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</em> (pp.&nbsp;1–14).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="cho-van-merrienboer-bahdanau-ea-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Cho et al., 2014]</td><td>Cho, K., Van&nbsp;Merriënboer, B., Bahdanau, D., &amp; Bengio, Y. (2014). On the properties of neural machine translation: encoder-decoder approaches. <em>arXiv preprint arXiv:1409.1259</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="chung-gulcehre-cho-ea-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Chung et al., 2014]</td><td>Chung, J., Gulcehre, C., Cho, K., &amp; Bengio, Y. (2014). Empirical evaluation of gated recurrent neural networks on sequence modeling. <em>arXiv preprint arXiv:1412.3555</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="csiszar-2008" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Csiszar, 2008]</td><td>Csiszár, I. (2008). Axiomatic characterizations of information measures. <em>Entropy</em>, <em>10</em>(3), 261–273.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="de-cock-2011" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[DeCock, 2011]</td><td>De&nbsp;Cock, D. (2011). Ames, iowa: alternative to the boston housing data as an end of semester regression project. <em>Journal of Statistics Education</em>, <em>19</em>(3).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="decandia-hastorun-jampani-ea-2007" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[DeCandia et al., 2007]</td><td>DeCandia, G., Hastorun, D., Jampani, M., Kakulapati, G., Lakshman, A., Pilchin, A., … Vogels, W. (2007). Dynamo: amazon’s highly available key-value store. <em>ACM SIGOPS operating systems review</em> (pp.&nbsp;205–220).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="devlin-chang-lee-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Devlin et al., 2018]</td><td>Devlin, J., Chang, M.-W., Lee, K., &amp; Toutanova, K. (2018). Bert: pre-training of deep bidirectional transformers for language understanding. <em>arXiv preprint arXiv:1810.04805</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="doucet-de-freitas-gordon-2001" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Doucet et al., 2001]</td><td>Doucet, A., De&nbsp;Freitas, N., &amp; Gordon, N. (2001). An introduction to sequential monte carlo methods. <em>Sequential Monte Carlo methods in practice</em> (pp.&nbsp;3–14). Springer.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="duchi-hazan-singer-2011" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Duchi et al., 2011]</td><td>Duchi, J., Hazan, E., &amp; Singer, Y. (2011). Adaptive subgradient methods for online learning and stochastic optimization. <em>Journal of Machine Learning Research</em>, <em>12</em>(Jul), 2121–2159.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="dumoulin-visin-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Dumoulin &amp; Visin, 2016]</td><td>Dumoulin, V., &amp; Visin, F. (2016). A guide to convolution arithmetic for deep learning. <em>arXiv preprint arXiv:1603.07285</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="edelman-ostrovsky-schwarz-2007" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Edelman et al., 2007]</td><td>Edelman, B., Ostrovsky, M., &amp; Schwarz, M. (2007). Internet advertising and the generalized second-price auction: selling billions of dollars worth of keywords. <em>American economic review</em>, <em>97</em>(1), 242–259.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="flammarion-bach-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Flammarion &amp; Bach, 2015]</td><td>Flammarion, N., &amp; Bach, F. (2015). From averaging to acceleration, there is only a step-size. <em>Conference on Learning Theory</em> (pp.&nbsp;658–695).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="gatys-ecker-bethge-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Gatys et al., 2016]</td><td>Gatys, L.&nbsp;A., Ecker, A.&nbsp;S., &amp; Bethge, M. (2016). Image style transfer using convolutional neural networks. <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp.&nbsp;2414–2423).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="ginibre-1965" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Ginibre, 1965]</td><td>Ginibre, J. (1965). Statistical ensembles of complex, quaternion, and real matrices. <em>Journal of Mathematical Physics</em>, <em>6</em>(3), 440–449.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="girshick-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Girshick, 2015]</td><td>Girshick, R. (2015). Fast r-cnn. <em>Proceedings of the IEEE international conference on computer vision</em> (pp.&nbsp;1440–1448).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="girshick-donahue-darrell-ea-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Girshick et al., 2014]</td><td>Girshick, R., Donahue, J., Darrell, T., &amp; Malik, J. (2014). Rich feature hierarchies for accurate object detection and semantic segmentation. <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp.&nbsp;580–587).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="glorot-bengio-2010" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Glorot &amp; Bengio, 2010]</td><td>Glorot, X., &amp; Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks. <em>Proceedings of the thirteenth international conference on artificial intelligence and statistics</em> (pp.&nbsp;249–256).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="goh-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Goh, 2017]</td><td>Goh, G. (2017). Why momentum really works. <em>Distill</em>. URL: <a class="reference external" href="http://distill.pub/2017/momentum">http://distill.pub/2017/momentum</a>, <a class="reference external" href="https://doi.org/10.23915/distill.00006">doi:10.23915/distill.00006</a></td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="goldberg-nichols-oki-ea-1992" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Goldberg et al., 1992]</td><td>Goldberg, D., Nichols, D., Oki, B.&nbsp;M., &amp; Terry, D. (1992). Using collaborative filtering to weave an information tapestry. <em>Communications of the ACM</em>, <em>35</em>(12), 61–71.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="goodfellow-bengio-courville-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Goodfellow et al., 2016]</td><td>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). <em>Deep Learning</em>. MIT Press. <span><a class="reference external" href="#"></a></span>http://www.deeplearningbook.org.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="goodfellow-pouget-abadie-mirza-ea-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Goodfellow et al., 2014]</td><td>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … Bengio, Y. (2014). Generative adversarial nets. <em>Advances in neural information processing systems</em> (pp.&nbsp;2672–2680).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="gotmare-keskar-xiong-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Gotmare et al., 2018]</td><td>Gotmare, A., Keskar, N.&nbsp;S., Xiong, C., &amp; Socher, R. (2018). A closer look at deep learning heuristics: learning rate restarts, warmup and distillation. <em>arXiv preprint arXiv:1810.13243</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="graves-schmidhuber-2005" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Graves &amp; Schmidhuber, 2005]</td><td>Graves, A., &amp; Schmidhuber, J. (2005). Framewise phoneme classification with bidirectional lstm and other neural network architectures. <em>Neural networks</em>, <em>18</em>(5-6), 602–610.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="gunawardana-shani-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Gunawardana &amp; Shani, 2015]</td><td>Gunawardana, A., &amp; Shani, G. (2015). Evaluating recommender systems. <em>Recommender systems handbook</em> (pp.&nbsp;265–308). Springer.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="guo-tang-ye-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Guo et al., 2017]</td><td>Guo, H., Tang, R., Ye, Y., Li, Z., &amp; He, X. (2017). Deepfm: a factorization-machine based neural network for ctr prediction. <em>Proceedings of the 26th International Joint Conference on Artificial Intelligence</em> (pp.&nbsp;1725–1731).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="he-gkioxari-dollar-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[He et al., 2017a]</td><td>He, K., Gkioxari, G., Dollár, P., &amp; Girshick, R. (2017). Mask r-cnn. <em>Proceedings of the IEEE international conference on computer vision</em> (pp.&nbsp;2961–2969).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="he-zhang-ren-ea-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[He et al., 2016a]</td><td>He, K., Zhang, X., Ren, S., &amp; Sun, J. (2016). Deep residual learning for image recognition. <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp.&nbsp;770–778).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="he-zhang-ren-ea-2016-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[He et al., 2016b]</td><td>He, K., Zhang, X., Ren, S., &amp; Sun, J. (2016). Identity mappings in deep residual networks. <em>European conference on computer vision</em> (pp.&nbsp;630–645).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="he-chua-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[He &amp; Chua, 2017]</td><td>He, X., &amp; Chua, T.-S. (2017). Neural factorization machines for sparse predictive analytics. <em>Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</em> (pp.&nbsp;355–364).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="he-liao-zhang-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[He et al., 2017b]</td><td>He, X., Liao, L., Zhang, H., Nie, L., Hu, X., &amp; Chua, T.-S. (2017). Neural collaborative filtering. <em>Proceedings of the 26th international conference on world wide web</em> (pp.&nbsp;173–182).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="hebb-hebb-1949" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Hebb &amp; Hebb, 1949]</td><td>Hebb, D.&nbsp;O., &amp; Hebb, D. (1949). <em>The organization of behavior</em>. Vol.&nbsp;65. Wiley New York.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="hendrycks-gimpel-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Hendrycks &amp; Gimpel, 2016]</td><td>Hendrycks, D., &amp; Gimpel, K. (2016). Gaussian error linear units (gelus). <em>arXiv preprint arXiv:1606.08415</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="hennessy-patterson-2011" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Hennessy &amp; Patterson, 2011]</td><td>Hennessy, J.&nbsp;L., &amp; Patterson, D.&nbsp;A. (2011). <em>Computer architecture: a quantitative approach</em>. Elsevier.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="herlocker-konstan-borchers-ea-1999" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Herlocker et al., 1999]</td><td>Herlocker, J.&nbsp;L., Konstan, J.&nbsp;A., Borchers, A., &amp; Riedl, J. (1999). An algorithmic framework for performing collaborative filtering. <em>22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 1999</em> (pp.&nbsp;230–237).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="hidasi-karatzoglou-baltrunas-ea-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Hidasi et al., 2015]</td><td>Hidasi, B., Karatzoglou, A., Baltrunas, L., &amp; Tikk, D. (2015). Session-based recommendations with recurrent neural networks. <em>arXiv preprint arXiv:1511.06939</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="hochreiter-schmidhuber-1997" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Hochreiter &amp; Schmidhuber, 1997]</td><td>Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. <em>Neural computation</em>, <em>9</em>(8), 1735–1780.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="hoyer-janzing-mooij-ea-2009" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Hoyer et al., 2009]</td><td>Hoyer, P.&nbsp;O., Janzing, D., Mooij, J.&nbsp;M., Peters, J., &amp; Schölkopf, B. (2009). Nonlinear causal discovery with additive noise models. <em>Advances in neural information processing systems</em> (pp.&nbsp;689–696).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="hu-shen-sun-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Hu et al., 2018]</td><td>Hu, J., Shen, L., &amp; Sun, G. (2018). Squeeze-and-excitation networks. <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp.&nbsp;7132–7141).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="hu-koren-volinsky-2008" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Hu et al., 2008]</td><td>Hu, Y., Koren, Y., &amp; Volinsky, C. (2008). Collaborative filtering for implicit feedback datasets. <em>2008 Eighth IEEE International Conference on Data Mining</em> (pp.&nbsp;263–272).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="huang-liu-van-der-maaten-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Huang et al., 2017]</td><td>Huang, G., Liu, Z., Van Der&nbsp;Maaten, L., &amp; Weinberger, K.&nbsp;Q. (2017). Densely connected convolutional networks. <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp.&nbsp;4700–4708).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="ioffe-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Ioffe, 2017]</td><td>Ioffe, S. (2017). Batch renormalization: towards reducing minibatch dependence in batch-normalized models. <em>Advances in neural information processing systems</em> (pp.&nbsp;1945–1953).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="ioffe-szegedy-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Ioffe &amp; Szegedy, 2015]</td><td>Ioffe, S., &amp; Szegedy, C. (2015). Batch normalization: accelerating deep network training by reducing internal covariate shift. <em>arXiv preprint arXiv:1502.03167</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="izmailov-podoprikhin-garipov-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Izmailov et al., 2018]</td><td>Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., &amp; Wilson, A.&nbsp;G. (2018). Averaging weights leads to wider optima and better generalization. <em>arXiv preprint arXiv:1803.05407</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="jia-song-he-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Jia et al., 2018]</td><td>Jia, X., Song, S., He, W., Wang, Y., Rong, H., Zhou, F., … others. (2018). Highly scalable deep learning training system with mixed-precision: training imagenet in four minutes. <em>arXiv preprint arXiv:1807.11205</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="jouppi-young-patil-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Jouppi et al., 2017]</td><td>Jouppi, N.&nbsp;P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., … others. (2017). In-datacenter performance analysis of a tensor processing unit. <em>2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)</em> (pp.&nbsp;1–12).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="kim-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Kim, 2014]</td><td>Kim, Y. (2014). Convolutional neural networks for sentence classification. <em>arXiv preprint arXiv:1408.5882</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="kingma-ba-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Kingma &amp; Ba, 2014]</td><td>Kingma, D.&nbsp;P., &amp; Ba, J. (2014). Adam: a method for stochastic optimization. <em>arXiv preprint arXiv:1412.6980</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="koller-friedman-2009" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Koller &amp; Friedman, 2009]</td><td>Koller, D., &amp; Friedman, N. (2009). <em>Probabilistic graphical models: principles and techniques</em>. MIT press.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="kolter-2008" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Kolter, 2008]</td><td>Kolter, Z. (2008). Linear algebra review and reference. <em>Available online: http</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="koren-2009" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Koren, 2009]</td><td>Koren, Y. (2009). Collaborative filtering with temporal dynamics. <em>Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</em> (pp.&nbsp;447–456).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="koren-bell-volinsky-2009" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Koren et al., 2009]</td><td>Koren, Y., Bell, R., &amp; Volinsky, C. (2009). Matrix factorization techniques for recommender systems. <em>Computer</em>, pp.&nbsp;30–37.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="krizhevsky-sutskever-hinton-2012" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Krizhevsky et al., 2012]</td><td>Krizhevsky, A., Sutskever, I., &amp; Hinton, G.&nbsp;E. (2012). Imagenet classification with deep convolutional neural networks. <em>Advances in neural information processing systems</em> (pp.&nbsp;1097–1105).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="kung-1988" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Kung, 1988]</td><td>Kung, S.&nbsp;Y. (1988). Vlsi array processors. <em>Englewood Cliffs, NJ, Prentice Hall, 1988, 685 p. Research supported by the Semiconductor Research Corp., SDIO, NSF, and US Navy.</em></td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="lecun-bottou-bengio-ea-1998" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[LeCun et al., 1998]</td><td>LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., &amp; others. (1998). Gradient-based learning applied to document recognition. <em>Proceedings of the IEEE</em>, <em>86</em>(11), 2278–2324.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="li-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Li, 2017]</td><td>Li, M. (2017). <em>Scaling Distributed Machine Learning with System and Algorithm Co-design</em> (Doctoral dissertation). PhD Thesis, CMU.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="li-andersen-park-ea-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Li et al., 2014]</td><td>Li, M., Andersen, D.&nbsp;G., Park, J.&nbsp;W., Smola, A.&nbsp;J., Ahmed, A., Josifovski, V., … Su, B.-Y. (2014). Scaling distributed machine learning with the parameter server. <em>11th $\$USENIX$\$ Symposium on Operating Systems Design and Implementation ($\$OSDI$\$ 14)</em> (pp.&nbsp;583–598).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="lin-chen-yan-2013" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Lin et al., 2013]</td><td>Lin, M., Chen, Q., &amp; Yan, S. (2013). Network in network. <em>arXiv preprint arXiv:1312.4400</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="lin-goyal-girshick-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Lin et al., 2017]</td><td>Lin, T.-Y., Goyal, P., Girshick, R., He, K., &amp; Dollár, P. (2017). Focal loss for dense object detection. <em>Proceedings of the IEEE international conference on computer vision</em> (pp.&nbsp;2980–2988).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="lin-lv-zhu-ea-2010" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Lin et al., 2010]</td><td>Lin, Y., Lv, F., Zhu, S., Yang, M., Cour, T., Yu, K., … others. (2010). Imagenet classification: fast descriptor coding and large-scale svm training. <em>Large scale visual recognition challenge</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="lipton-steinhardt-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Lipton &amp; Steinhardt, 2018]</td><td>Lipton, Z.&nbsp;C., &amp; Steinhardt, J. (2018). Troubling trends in machine learning scholarship. <em>arXiv preprint arXiv:1807.03341</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="liu-anguelov-erhan-ea-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Liu et al., 2016]</td><td>Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., &amp; Berg, A.&nbsp;C. (2016). Ssd: single shot multibox detector. <em>European conference on computer vision</em> (pp.&nbsp;21–37).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="liu-ott-goyal-ea-2019" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Liu et al., 2019]</td><td>Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., … Stoyanov, V. (2019). Roberta: a robustly optimized bert pretraining approach. <em>arXiv preprint arXiv:1907.11692</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="long-shelhamer-darrell-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Long et al., 2015]</td><td>Long, J., Shelhamer, E., &amp; Darrell, T. (2015). Fully convolutional networks for semantic segmentation. <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp.&nbsp;3431–3440).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="loshchilov-hutter-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Loshchilov &amp; Hutter, 2016]</td><td>Loshchilov, I., &amp; Hutter, F. (2016). Sgdr: stochastic gradient descent with warm restarts. <em>arXiv preprint arXiv:1608.03983</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="luo-wang-shao-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Luo et al., 2018]</td><td>Luo, P., Wang, X., Shao, W., &amp; Peng, Z. (2018). Towards understanding regularization in batch normalization. <em>arXiv preprint</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="maas-daly-pham-ea-2011" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Maas et al., 2011]</td><td>Maas, A.&nbsp;L., Daly, R.&nbsp;E., Pham, P.&nbsp;T., Huang, D., Ng, A.&nbsp;Y., &amp; Potts, C. (2011). Learning word vectors for sentiment analysis. <em>Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies-volume 1</em> (pp.&nbsp;142–150).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="mccann-bradbury-xiong-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[McCann et al., 2017]</td><td>McCann, B., Bradbury, J., Xiong, C., &amp; Socher, R. (2017). Learned in translation: contextualized word vectors. <em>Advances in Neural Information Processing Systems</em> (pp.&nbsp;6294–6305).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="mcculloch-pitts-1943" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[McCulloch &amp; Pitts, 1943]</td><td>McCulloch, W.&nbsp;S., &amp; Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. <em>The bulletin of mathematical biophysics</em>, <em>5</em>(4), 115–133.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="mcmahan-holt-sculley-ea-2013" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[McMahan et al., 2013]</td><td>McMahan, H.&nbsp;B., Holt, G., Sculley, D., Young, M., Ebner, D., Grady, J., … others. (2013). Ad click prediction: a view from the trenches. <em>Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</em> (pp.&nbsp;1222–1230).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="merity-xiong-bradbury-ea-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Merity et al., 2016]</td><td>Merity, S., Xiong, C., Bradbury, J., &amp; Socher, R. (2016). Pointer sentinel mixture models. <em>arXiv preprint arXiv:1609.07843</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="mikolov-chen-corrado-ea-2013" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Mikolov et al., 2013a]</td><td>Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013). Efficient estimation of word representations in vector space. <em>arXiv preprint arXiv:1301.3781</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="mikolov-sutskever-chen-ea-2013" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Mikolov et al., 2013b]</td><td>Mikolov, T., Sutskever, I., Chen, K., Corrado, G.&nbsp;S., &amp; Dean, J. (2013). Distributed representations of words and phrases and their compositionality. <em>Advances in neural information processing systems</em> (pp.&nbsp;3111–3119).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="mirhoseini-pham-le-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Mirhoseini et al., 2017]</td><td>Mirhoseini, A., Pham, H., Le, Q.&nbsp;V., Steiner, B., Larsen, R., Zhou, Y., … Dean, J. (2017). Device placement optimization with reinforcement learning. <em>Proceedings of the 34th International Conference on Machine Learning-Volume 70</em> (pp.&nbsp;2430–2439).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="morey-hoekstra-rouder-ea-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Morey et al., 2016]</td><td>Morey, R.&nbsp;D., Hoekstra, R., Rouder, J.&nbsp;N., Lee, M.&nbsp;D., &amp; Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. <em>Psychonomic bulletin &amp; review</em>, <em>23</em>(1), 103–123.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="nesterov-vial-2000" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Nesterov &amp; Vial, 2000]</td><td>Nesterov, Y., &amp; Vial, J.-P. (2000). <em>Confidence level solutions for stochastic programming, Stochastic Programming E-Print Series</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="nesterov-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Nesterov, 2018]</td><td>Nesterov, Y. (2018). <em>Lectures on convex optimization</em>. Vol. 137. Springer.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="neyman-1937" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Neyman, 1937]</td><td>Neyman, J. (1937). Outline of a theory of statistical estimation based on the classical theory of probability. <em>Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences</em>, <em>236</em>(767), 333–380.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="parikh-tackstrom-das-ea-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Parikh et al., 2016]</td><td>Parikh, A.&nbsp;P., Täckström, O., Das, D., &amp; Uszkoreit, J. (2016). A decomposable attention model for natural language inference. <em>arXiv preprint arXiv:1606.01933</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="pennington-schoenholz-ganguli-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Pennington et al., 2017]</td><td>Pennington, J., Schoenholz, S., &amp; Ganguli, S. (2017). Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice. <em>Advances in neural information processing systems</em> (pp.&nbsp;4785–4795).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="pennington-socher-manning-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Pennington et al., 2014]</td><td>Pennington, J., Socher, R., &amp; Manning, C. (2014). Glove: global vectors for word representation. <em>Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</em> (pp.&nbsp;1532–1543).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="peters-janzing-scholkopf-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Peters et al., 2017a]</td><td>Peters, J., Janzing, D., &amp; Schölkopf, B. (2017). <em>Elements of causal inference: foundations and learning algorithms</em>. MIT press.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="peters-ammar-bhagavatula-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Peters et al., 2017b]</td><td>Peters, M., Ammar, W., Bhagavatula, C., &amp; Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. <em>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em> (pp.&nbsp;1756–1765).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="peters-neumann-iyyer-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Peters et al., 2018]</td><td>Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., &amp; Zettlemoyer, L. (2018). Deep contextualized word representations. <em>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</em> (pp.&nbsp;2227–2237).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="petersen-pedersen-ea-2008" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Petersen et al., 2008]</td><td>Petersen, K.&nbsp;B., Pedersen, M.&nbsp;S., &amp; others. (2008). The matrix cookbook. <em>Technical University of Denmark</em>, <em>7</em>(15), 510.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="polyak-1964" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Polyak, 1964]</td><td>Polyak, B.&nbsp;T. (1964). Some methods of speeding up the convergence of iteration methods. <em>USSR Computational Mathematics and Mathematical Physics</em>, <em>4</em>(5), 1–17.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="quadrana-cremonesi-jannach-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Quadrana et al., 2018]</td><td>Quadrana, M., Cremonesi, P., &amp; Jannach, D. (2018). Sequence-aware recommender systems. <em>ACM Computing Surveys (CSUR)</em>, <em>51</em>(4), 66.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="radford-metz-chintala-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Radford et al., 2015]</td><td>Radford, A., Metz, L., &amp; Chintala, S. (2015). Unsupervised representation learning with deep convolutional generative adversarial networks. <em>arXiv preprint arXiv:1511.06434</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="radford-narasimhan-salimans-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Radford et al., 2018]</td><td>Radford, A., Narasimhan, K., Salimans, T., &amp; Sutskever, I. (2018). Improving language understanding by generative pre-training. <em>OpenAI</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="radford-wu-child-ea-2019" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Radford et al., 2019]</td><td>Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., &amp; Sutskever, I. (2019). Language models are unsupervised multitask learners. <em>OpenAI Blog</em>, <em>1</em>(8), 9.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="rajpurkar-zhang-lopyrev-ea-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Rajpurkar et al., 2016]</td><td>Rajpurkar, P., Zhang, J., Lopyrev, K., &amp; Liang, P. (2016). Squad: 100,000+ questions for machine comprehension of text. <em>arXiv preprint arXiv:1606.05250</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="reddi-kale-kumar-2019" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Reddi et al., 2019]</td><td>Reddi, S.&nbsp;J., Kale, S., &amp; Kumar, S. (2019). On the convergence of adam and beyond. <em>arXiv preprint arXiv:1904.09237</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="reed-de-freitas-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Reed &amp; DeFreitas, 2015]</td><td>Reed, S., &amp; De&nbsp;Freitas, N. (2015). Neural programmer-interpreters. <em>arXiv preprint arXiv:1511.06279</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="ren-he-girshick-ea-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Ren et al., 2015]</td><td>Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster r-cnn: towards real-time object detection with region proposal networks. <em>Advances in neural information processing systems</em> (pp.&nbsp;91–99).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="rendle-2010" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Rendle, 2010]</td><td>Rendle, S. (2010). Factorization machines. <em>2010 IEEE International Conference on Data Mining</em> (pp.&nbsp;995–1000).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="rendle-freudenthaler-gantner-ea-2009" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Rendle et al., 2009]</td><td>Rendle, S., Freudenthaler, C., Gantner, Z., &amp; Schmidt-Thieme, L. (2009). Bpr: bayesian personalized ranking from implicit feedback. <em>Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence</em> (pp.&nbsp;452–461).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="rumelhart-hinton-williams-ea-1988" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Rumelhart et al., 1988]</td><td>Rumelhart, D.&nbsp;E., Hinton, G.&nbsp;E., Williams, R.&nbsp;J., &amp; others. (1988). Learning representations by back-propagating errors. <em>Cognitive modeling</em>, <em>5</em>(3), 1.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="russell-norvig-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Russell &amp; Norvig, 2016]</td><td>Russell, S.&nbsp;J., &amp; Norvig, P. (2016). <em>Artificial intelligence: a modern approach</em>. Malaysia; Pearson Education Limited,.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="santurkar-tsipras-ilyas-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Santurkar et al., 2018]</td><td>Santurkar, S., Tsipras, D., Ilyas, A., &amp; Madry, A. (2018). How does batch normalization help optimization? <em>Advances in Neural Information Processing Systems</em> (pp.&nbsp;2483–2493).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="sarwar-karypis-konstan-ea-2001" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Sarwar et al., 2001]</td><td>Sarwar, B.&nbsp;M., Karypis, G., Konstan, J.&nbsp;A., Riedl, J., &amp; others. (2001). Item-based collaborative filtering recommendation algorithms. <em>Www</em>, <em>1</em>, 285–295.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="schein-popescul-ungar-ea-2002" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Schein et al., 2002]</td><td>Schein, A.&nbsp;I., Popescul, A., Ungar, L.&nbsp;H., &amp; Pennock, D.&nbsp;M. (2002). Methods and metrics for cold-start recommendations. <em>Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval</em> (pp.&nbsp;253–260).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="schuster-paliwal-1997" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Schuster &amp; Paliwal, 1997]</td><td>Schuster, M., &amp; Paliwal, K.&nbsp;K. (1997). Bidirectional recurrent neural networks. <em>IEEE Transactions on Signal Processing</em>, <em>45</em>(11), 2673–2681.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="sedhain-menon-sanner-ea-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Sedhain et al., 2015]</td><td>Sedhain, S., Menon, A.&nbsp;K., Sanner, S., &amp; Xie, L. (2015). Autorec: autoencoders meet collaborative filtering. <em>Proceedings of the 24th International Conference on World Wide Web</em> (pp.&nbsp;111–112).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="sennrich-haddow-birch-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Sennrich et al., 2015]</td><td>Sennrich, R., Haddow, B., &amp; Birch, A. (2015). Neural machine translation of rare words with subword units. <em>arXiv preprint arXiv:1508.07909</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="sergeev-del-balso-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Sergeev &amp; DelBalso, 2018]</td><td>Sergeev, A., &amp; Del&nbsp;Balso, M. (2018). Horovod: fast and easy distributed deep learning in tensorflow. <em>arXiv preprint arXiv:1802.05799</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="shannon-1948" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Shannon, 1948]</td><td>Shannon, C.&nbsp;E. (1948 , 7). A mathematical theory of communication. <em>The Bell System Technical Journal</em>, <em>27</em>(3), 379–423.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="silver-huang-maddison-ea-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Silver et al., 2016]</td><td>Silver, D., Huang, A., Maddison, C.&nbsp;J., Guez, A., Sifre, L., Van Den&nbsp;Driessche, G., … others. (2016). Mastering the game of go with deep neural networks and tree search. <em>nature</em>, <em>529</em>(7587), 484.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="simonyan-zisserman-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Simonyan &amp; Zisserman, 2014]</td><td>Simonyan, K., &amp; Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. <em>arXiv preprint arXiv:1409.1556</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="smola-narayanamurthy-2010" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Smola &amp; Narayanamurthy, 2010]</td><td>Smola, A., &amp; Narayanamurthy, S. (2010). An architecture for parallel topic models. <em>Proceedings of the VLDB Endowment</em>, <em>3</em>(1-2), 703–710.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="srivastava-hinton-krizhevsky-ea-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Srivastava et al., 2014]</td><td>Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. <em>The Journal of Machine Learning Research</em>, <em>15</em>(1), 1929–1958.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="strang-1993" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Strang, 1993]</td><td>Strang, G. (1993). <em>Introduction to linear algebra</em>. Vol.&nbsp;3. Wellesley-Cambridge Press Wellesley, MA.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="su-khoshgoftaar-2009" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Su &amp; Khoshgoftaar, 2009]</td><td>Su, X., &amp; Khoshgoftaar, T.&nbsp;M. (2009). A survey of collaborative filtering techniques. <em>Advances in artificial intelligence</em>, <em>2009</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="sukhbaatar-weston-fergus-ea-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Sukhbaatar et al., 2015]</td><td>Sukhbaatar, S., Weston, J., Fergus, R., &amp; others. (2015). End-to-end memory networks. <em>Advances in neural information processing systems</em> (pp.&nbsp;2440–2448).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="sutskever-martens-dahl-ea-2013" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Sutskever et al., 2013]</td><td>Sutskever, I., Martens, J., Dahl, G., &amp; Hinton, G. (2013). On the importance of initialization and momentum in deep learning. <em>International conference on machine learning</em> (pp.&nbsp;1139–1147).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="szegedy-ioffe-vanhoucke-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Szegedy et al., 2017]</td><td>Szegedy, C., Ioffe, S., Vanhoucke, V., &amp; Alemi, A.&nbsp;A. (2017). Inception-v4, inception-resnet and the impact of residual connections on learning. <em>Thirty-First AAAI Conference on Artificial Intelligence</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="szegedy-liu-jia-ea-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Szegedy et al., 2015]</td><td>Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., … Rabinovich, A. (2015). Going deeper with convolutions. <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp.&nbsp;1–9).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="szegedy-vanhoucke-ioffe-ea-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Szegedy et al., 2016]</td><td>Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., &amp; Wojna, Z. (2016). Rethinking the inception architecture for computer vision. <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp.&nbsp;2818–2826).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="tallec-ollivier-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Tallec &amp; Ollivier, 2017]</td><td>Tallec, C., &amp; Ollivier, Y. (2017). Unbiasing truncated backpropagation through time. <em>arXiv preprint arXiv:1705.08209</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="tang-wang-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Tang &amp; Wang, 2018]</td><td>Tang, J., &amp; Wang, K. (2018). Personalized top-n sequential recommendation via convolutional sequence embedding. <em>Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining</em> (pp.&nbsp;565–573).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="teye-azizpour-smith-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Teye et al., 2018]</td><td>Teye, M., Azizpour, H., &amp; Smith, K. (2018). Bayesian uncertainty estimation for batch normalized deep networks. <em>arXiv preprint arXiv:1802.06455</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="tieleman-hinton-2012" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Tieleman &amp; Hinton, 2012]</td><td>Tieleman, T., &amp; Hinton, G. (2012). Lecture 6.5-rmsprop: divide the gradient by a running average of its recent magnitude. <em>COURSERA: Neural networks for machine learning</em>, <em>4</em>(2), 26–31.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="treisman-gelade-1980" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Treisman &amp; Gelade, 1980]</td><td>Treisman, A.&nbsp;M., &amp; Gelade, G. (1980). A feature-integration theory of attention. <em>Cognitive psychology</em>, <em>12</em>(1), 97–136.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="toscher-jahrer-bell-2009" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Toscher et al., 2009]</td><td>Töscher, A., Jahrer, M., &amp; Bell, R.&nbsp;M. (2009). The bigchaos solution to the netflix grand prize. <em>Netflix prize documentation</em>, pp.&nbsp;1–52.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="uijlings-van-de-sande-gevers-ea-2013" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Uijlings et al., 2013]</td><td>Uijlings, J.&nbsp;R., Van De&nbsp;Sande, K.&nbsp;E., Gevers, T., &amp; Smeulders, A.&nbsp;W. (2013). Selective search for object recognition. <em>International journal of computer vision</em>, <em>104</em>(2), 154–171.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="van-loan-golub-1983" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[VanLoan &amp; Golub, 1983]</td><td>Van&nbsp;Loan, C.&nbsp;F., &amp; Golub, G.&nbsp;H. (1983). <em>Matrix computations</em>. Johns Hopkins University Press.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="vaswani-shazeer-parmar-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Vaswani et al., 2017]</td><td>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.&nbsp;N., … Polosukhin, I. (2017). Attention is all you need. <em>Advances in neural information processing systems</em> (pp.&nbsp;5998–6008).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="wang-li-liberty-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Wang et al., 2018]</td><td>Wang, L., Li, M., Liberty, E., &amp; Smola, A.&nbsp;J. (2018). Optimal message scheduling for aggregation. <em>NETWORKS</em>, <em>2</em>(3), 2–3.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="wang-davidson-pan-ea-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Wang et al., 2016]</td><td>Wang, Y., Davidson, A., Pan, Y., Wu, Y., Riffel, A., &amp; Owens, J.&nbsp;D. (2016). Gunrock: a high-performance graph processing library on the gpu. <em>ACM SIGPLAN Notices</em> (p.&nbsp;11).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="warstadt-singh-bowman-2019" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Warstadt et al., 2019]</td><td>Warstadt, A., Singh, A., &amp; Bowman, S.&nbsp;R. (2019). Neural network acceptability judgments. <em>Transactions of the Association for Computational Linguistics</em>, <em>7</em>, 625–641.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="wasserman-2013" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Wasserman, 2013]</td><td>Wasserman, L. (2013). <em>All of statistics: a concise course in statistical inference</em>. Springer Science &amp; Business Media.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="watkins-dayan-1992" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Watkins &amp; Dayan, 1992]</td><td>Watkins, C.&nbsp;J., &amp; Dayan, P. (1992). Q-learning. <em>Machine learning</em>, <em>8</em>(3-4), 279–292.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="welling-teh-2011" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Welling &amp; Teh, 2011]</td><td>Welling, M., &amp; Teh, Y.&nbsp;W. (2011). Bayesian learning via stochastic gradient langevin dynamics. <em>Proceedings of the 28th international conference on machine learning (ICML-11)</em> (pp.&nbsp;681–688).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="wigner-1958" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Wigner, 1958]</td><td>Wigner, E.&nbsp;P. (1958). On the distribution of the roots of certain symmetric matrices. <em>Ann. Math</em> (pp.&nbsp;325–327).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="wood-gasthaus-archambeau-ea-2011" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Wood et al., 2011]</td><td>Wood, F., Gasthaus, J., Archambeau, C., James, L., &amp; Teh, Y.&nbsp;W. (2011). The sequence memoizer. <em>Communications of the ACM</em>, <em>54</em>(2), 91–98.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="wu-ahmed-beutel-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Wu et al., 2017]</td><td>Wu, C.-Y., Ahmed, A., Beutel, A., Smola, A.&nbsp;J., &amp; Jing, H. (2017). Recurrent recommender networks. <em>Proceedings of the tenth ACM international conference on web search and data mining</em> (pp.&nbsp;495–503).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="wu-schuster-chen-ea-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Wu et al., 2016]</td><td>Wu, Y., Schuster, M., Chen, Z., Le, Q.&nbsp;V., Norouzi, M., Macherey, W., … others. (2016). Google’s neural machine translation system: bridging the gap between human and machine translation. <em>arXiv preprint arXiv:1609.08144</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="xiao-rasul-vollgraf-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Xiao et al., 2017]</td><td>Xiao, H., Rasul, K., &amp; Vollgraf, R. (2017). Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. <em>arXiv preprint arXiv:1708.07747</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="xiong-wu-alleva-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Xiong et al., 2018]</td><td>Xiong, W., Wu, L., Alleva, F., Droppo, J., Huang, X., &amp; Stolcke, A. (2018). The microsoft 2017 conversational speech recognition system. <em>2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> (pp.&nbsp;5934–5938).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="ye-yin-lee-ea-2011" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Ye et al., 2011]</td><td>Ye, M., Yin, P., Lee, W.-C., &amp; Lee, D.-L. (2011). Exploiting geographical influence for collaborative point-of-interest recommendation. <em>Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval</em> (pp.&nbsp;325–334).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="you-gitman-ginsburg-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[You et al., 2017]</td><td>You, Y., Gitman, I., &amp; Ginsburg, B. (2017). Large batch training of convolutional networks. <em>arXiv preprint arXiv:1708.03888</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="zaheer-reddi-sachan-ea-2018" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Zaheer et al., 2018]</td><td>Zaheer, M., Reddi, S., Sachan, D., Kale, S., &amp; Kumar, S. (2018). Adaptive methods for nonconvex optimization. <em>Advances in Neural Information Processing Systems</em> (pp.&nbsp;9793–9803).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="zeiler-2012" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Zeiler, 2012]</td><td>Zeiler, M.&nbsp;D. (2012). Adadelta: an adaptive learning rate method. <em>arXiv preprint arXiv:1212.5701</em>.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="zhang-yao-sun-ea-2019" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Zhang et al., 2019]</td><td>Zhang, S., Yao, L., Sun, A., &amp; Tay, Y. (2019). Deep learning based recommender system: a survey and new perspectives. <em>ACM Computing Surveys (CSUR)</em>, <em>52</em>(1), 5.</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="zhu-park-isola-ea-2017" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Zhu et al., 2017]</td><td>Zhu, J.-Y., Park, T., Isola, P., &amp; Efros, A.&nbsp;A. (2017). Unpaired image-to-image translation using cycle-consistent adversarial networks. <em>Proceedings of the IEEE international conference on computer vision</em> (pp.&nbsp;2223–2232).</td></tr>
</tbody>
</table>
<table class="bibtex docutils citation" frame="void" id="zhu-kiros-zemel-ea-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Zhu et al., 2015]</td><td>Zhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., &amp; Fidler, S. (2015). Aligning books and movies: towards story-like visual explanations by watching movies and reading books. <em>Proceedings of the IEEE international conference on computer vision</em> (pp.&nbsp;19–27).</td></tr>
</tbody>
</table>
</p>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="../chapter_appendix-tools-for-deep-learning/d2l_vn.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>19.7. Tài liệu API của d2l</div>
         </div>
     </a>
     <a id="button-next" href="../glossary.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>Bảng thuật ngữ</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>