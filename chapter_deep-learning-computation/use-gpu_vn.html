<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>5.6. GPU &#8212; Đắm mình vào Học Sâu 0.14.4 documentation</title>

    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6. Mạng Nơ-ron Tích chập" href="../chapter_convolutional-neural-networks/index_vn.html" />
    <link rel="prev" title="5.5. Đọc/Ghi tệp" href="read-write_vn.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index_vn.html"><span class="section-number">5. </span>Tính toán Học sâu</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">5.6. </span>GPU</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_deep-learning-computation/use-gpu_vn.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/aivivn/d2l-vn">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://forum.machinelearningcoban.com/">
                  <i class="fab fa-discourse"></i>
                  Forum
              </a>
          
              <a  class="mdl-navigation__link" href="https://www.d2l.ai/">
                  <i class="fas fa-external-link-alt"></i>
                  English
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text-vi.png" alt="Đắm mình vào Học Sâu"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro_vn.html">Giới thiệu từ nhóm dịch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index_vn.html">Lời nói đầu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_install/index_vn.html">Cài đặt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index_vn.html">Ký hiệu</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index_vn.html">1. Giới thiệu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index_vn.html">2. Sơ bộ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray_vn.html">2.1. Thao tác với Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas_vn.html">2.2. Tiền xử lý dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra_vn.html">2.3. Đại số tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus_vn.html">2.4. Giải tích</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd_vn.html">2.5. Tính vi phân Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability_vn.html">2.6. Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api_vn.html">2.7. Tài liệu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-networks/index_vn.html">3. Mạng nơ-ron Tuyến tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression_vn.html">3.1. Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-scratch_vn.html">3.2. Lập trình Hồi quy Tuyến tính từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-gluon_vn.html">3.3. Cách lập trình súc tích Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression_vn.html">3.4. Hồi quy Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/fashion-mnist_vn.html">3.5. Bộ dữ liệu Phân loại Ảnh (Fashion-MNIST)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-scratch_vn.html">3.6. Lập trình Hồi quy Sofmax từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-gluon_vn.html">3.7. Cách lập trình súc tích Hồi quy Softmax</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index_vn.html">4. Perceptron Đa tầng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp_vn.html">4.1. Perceptron đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-scratch_vn.html">4.2. Lập trình Perceptron Đa tầng từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-gluon_vn.html">4.3. Cách lập trình súc tích Perceptron Đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/underfit-overfit_vn.html">4.4. Lựa Chọn Mô Hình, Dưới Khớp và Quá Khớp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/weight-decay_vn.html">4.5. Suy giảm trọng số</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout_vn.html">4.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop_vn.html">4.7. Lan truyền xuôi, Lan truyền ngược và Đồ thị tính toán</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init_vn.html">4.8. Ổn định Số học và Khởi tạo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/environment_vn.html">4.9. Cân nhắc tới Môi trường</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price_vn.html">4.10. Dự đoán Giá Nhà trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index_vn.html">5. Tính toán Học sâu</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="model-construction_vn.html">5.1. Tầng và Khối</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameters_vn.html">5.2. Quản lý Tham số</a></li>
<li class="toctree-l2"><a class="reference internal" href="deferred-init_vn.html">5.3. Khởi tạo trễ</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom-layer_vn.html">5.4. Các tầng Tuỳ chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="read-write_vn.html">5.5. Đọc/Ghi tệp</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">5.6. GPU</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index_vn.html">6. Mạng Nơ-ron Tích chập</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv_vn.html">6.1. Từ Tầng Kết nối Dày đặc đến phép Tích chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer_vn.html">6.2. Phép Tích chập cho Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides_vn.html">6.3. Đệm và Sải Bước</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels_vn.html">6.4. Đa kênh Đầu vào và Đầu ra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling_vn.html">6.5. Gộp (<em>Pooling</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet_vn.html">6.6. Mạng Nơ-ron Tích chập (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index_vn.html">7. Mạng Nơ-ron Tích chập Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet_vn.html">7.1. Mạng Nơ-ron Tích chập Sâu (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/vgg_vn.html">7.2. Mạng sử dụng Khối (VGG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/nin_vn.html">7.3. Mạng trong Mạng (<em>Network in Network - NiN</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet_vn.html">7.4. Mạng nối song song (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm_vn.html">7.5. Chuẩn hoá theo batch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet_vn.html">7.6. Mạng phần dư (ResNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet_vn.html">7.7. Mạng Tích chập Kết nối Dày đặc (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index_vn.html">8. Mạng Nơ-ron Hồi tiếp</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence_vn.html">8.1. Mô hình chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-preprocessing_vn.html">8.2. Tiền Xử lý Dữ liệu Văn bản</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-models-and-dataset_vn.html">8.3. Mô hình Ngôn ngữ và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn_vn.html">8.4. Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch_vn.html">8.5. Lập trình Mạng nơ-ron Hồi tiếp từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-gluon_vn.html">8.6. Lập trình súc tích Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt_vn.html">8.7. Lan truyền Ngược qua Thời gian</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index_vn.html">9. Mạng Nơ-ron Hồi tiếp Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru_vn.html">9.1. Nút Hồi tiếp có Cổng (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm_vn.html">9.2. Bộ nhớ Ngắn hạn Dài (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn_vn.html">9.3. Mạng Nơ-ron Hồi tiếp Sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/bi-rnn_vn.html">9.4. Mạng Nơ-ron Hồi tiếp Hai chiều</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset_vn.html">9.5. Dịch Máy và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder_vn.html">9.6. Kiến trúc Mã hoá - Giải mã</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq_vn.html">9.7. Chuỗi sang Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search_vn.html">9.8. Tìm kiếm Chùm</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms/index_vn.html">10. Cơ chế Tập trung</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/attention_vn.html">10.1. Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/seq2seq-attention_vn.html">10.2. Chuỗi sang Chuỗi áp dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/transformer_vn.html">10.3. Kiến trúc Transformer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index_vn.html">11. Thuật toán Tối ưu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html">11.1. Tối ưu và Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-thach-thuc-cua-toi-uu-trong-hoc-sau">11.2. Các Thách thức của Tối ưu trong Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-vung-cuc-tieu">11.3. Các vùng Cực tiểu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-diem-yen-ngua">11.4. Các điểm Yên ngựa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#tieu-bien-gradient">11.5. Tiêu biến Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity_vn.html">11.6. Tính lồi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd_vn.html">11.7. Hạ Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd_vn.html">11.8. Hạ Gradient Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd_vn.html">11.9. Hạ Gradient Ngẫu nhiên theo Minibatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum_vn.html">11.10. Động lượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad_vn.html">11.11. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop_vn.html">11.12. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta_vn.html">11.13. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam_vn.html">11.14. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler_vn.html">11.15. Định thời Tốc độ Học</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational-performance/index_vn.html">12. Hiệu năng Tính toán</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hybridize_vn.html">12.1. Trình biên dịch và Trình thông dịch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/async-computation_vn.html">12.2. Tính toán Bất đồng bộ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/auto-parallelism_vn.html">12.3. Song song hóa Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hardware_vn.html">12.4. Phần cứng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus_vn.html">12.5. Huấn luyện đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus-concise_vn.html">12.6. Cách lập trình Súc tích đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/parameterserver_vn.html">12.7. Máy chủ Tham số</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index_vn.html">13. Thị giác Máy tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation_vn.html">13.1. Tăng cường Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning_vn.html">13.2. Tinh Chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box_vn.html">13.3. Phát hiện Vật thể và Khoanh vùng Đối tượng (Khung chứa)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor_vn.html">13.4. Khung neo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection_vn.html">13.5. Phát hiện Vật thể Đa tỷ lệ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset_vn.html">13.6. Tập dữ liệu Phát hiện Đối tượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd_vn.html">13.7. Phát hiện Nhiều khung Một lượt (SSD)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn_vn.html">13.8. CNN theo Vùng (R-CNN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset_vn.html">13.9. Phân vùng theo Ngữ nghĩa và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv_vn.html">13.10. Tích chập Chuyển vị</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn_vn.html">13.11. Mạng Tích chập Đầy đủ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style_vn.html">13.12. Truyền tải Phong cách Nơ-ron</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10_vn.html">13.13. Phân loại ảnh (CIFAR-10) trên Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog_vn.html">13.14. Nhận diện Giống Chó (ImageNet Dogs) trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index_vn.html">14. Xử lý Ngôn ngữ Tự nhiên: Tiền Huấn luyện</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec_vn.html">14.1. Embedding Từ (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training_vn.html">14.2. Huấn luyện Gần đúng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset_vn.html">14.3. Tập dữ liệu để Tiền Huấn luyện Embedding Từ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining_vn.html">14.4. Tiền huấn luyện word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove_vn.html">14.5. Embedding từ với Vector Toàn cục (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding_vn.html">14.6. Embedding từ con</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy_vn.html">14.7. Tìm kiếm từ Đồng nghĩa và Loại suy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert_vn.html">14.8. Biểu diễn Mã hóa hai chiều từ Transformer (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset_vn.html">14.9. Tập dữ liệu để Tiền huấn luyện BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining_vn.html">14.10. Tiền Huấn luyện BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index_vn.html">15. Xử lý Ngôn ngữ Tự nhiên: Ứng dụng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset_vn.html">15.1. Tác vụ Phân tích Cảm xúc và Bộ Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn_vn.html">15.2. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn_vn.html">15.3. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Tích Chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset_vn.html">15.4. Suy luận ngôn ngữ tự nhiên và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention_vn.html">15.5. Suy luận Ngôn ngữ Tự nhiên: Sử dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert_vn.html">15.6. Tinh chỉnh BERT cho các Ứng dụng Cấp Chuỗi và Cấp Token</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-bert_vn.html">15.7. Suy luận Ngôn ngữ Tự nhiên: Tinh chỉnh BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender-systems/index_vn.html">16. Hệ thống Đề xuất</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/recsys-intro_vn.html">16.1. Tổng quan về Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/movielens_vn.html">16.2. Tập dữ liệu MovieLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/mf_vn.html">16.3. Phân rã Ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/autorec_vn.html">16.4. AutoRec: Dự đoán Đánh giá với Bộ tự Mã hóa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ranking_vn.html">16.5. Cá nhân hóa Xếp hạng trong Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/neumf_vn.html">16.6. Lọc Cộng tác Nơ-ron cho Cá nhân hóa Xếp hạng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/seqrec_vn.html">16.7. Hệ thống Đề xuất có Nhận thức về Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ctr_vn.html">16.8. Hệ thống Đề xuất Giàu Đặc trưng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/fm_vn.html">16.9. Máy Phân rã ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/deepfm_vn.html">16.10. Máy Phân rã Ma trận Sâu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_generative-adversarial-networks/index_vn.html">17. Mạng Đối sinh</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/gan_vn.html">17.1. Mạng Đối sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/dcgan_vn.html">17.2. Mạng Đối sinh Tích chập Sâu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/index_vn.html">18. Phụ lục: Toán học cho Học Sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops_vn.html">18.1. Các phép toán Hình học và Đại số Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition_vn.html">18.2. Phân rã trị riêng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus_vn.html">18.3. Giải tích một biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus_vn.html">18.4. Giải tích Nhiều biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus_vn.html">18.5. Giải tích Tích phân</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/random-variables_vn.html">18.6. Biến Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood_vn.html">18.7. Hợp lý Cực đại</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/distributions_vn.html">18.8. Các Phân phối Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes_vn.html">18.9. Bộ phân loại Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/statistics_vn.html">18.10. Thống kê</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/information-theory_vn.html">18.11. Lý thuyết Thông tin</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index_vn.html">19. Phụ lục: Công cụ cho Học Sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/jupyter_vn.html">19.1. Sử dụng Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/sagemaker_vn.html">19.2. Sử dụng Amazon SageMaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/aws_vn.html">19.3. Sử dụng Máy ảo AWS EC2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/colab_vn.html">19.4. Sử dụng Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus_vn.html">19.5. Lựa chọn Máy chủ &amp; GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/contributing_vn.html">19.6. Đóng góp cho Quyển sách</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/d2l_vn.html">19.7. Tài liệu API của <code class="docutils literal notranslate"><span class="pre">d2l</span></code></a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/zreferences.html">Tài liệu tham khảo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Bảng thuật ngữ</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text-vi.png" alt="Đắm mình vào Học Sâu"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro_vn.html">Giới thiệu từ nhóm dịch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index_vn.html">Lời nói đầu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_install/index_vn.html">Cài đặt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index_vn.html">Ký hiệu</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index_vn.html">1. Giới thiệu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index_vn.html">2. Sơ bộ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray_vn.html">2.1. Thao tác với Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas_vn.html">2.2. Tiền xử lý dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra_vn.html">2.3. Đại số tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus_vn.html">2.4. Giải tích</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd_vn.html">2.5. Tính vi phân Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability_vn.html">2.6. Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api_vn.html">2.7. Tài liệu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-networks/index_vn.html">3. Mạng nơ-ron Tuyến tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression_vn.html">3.1. Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-scratch_vn.html">3.2. Lập trình Hồi quy Tuyến tính từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/linear-regression-gluon_vn.html">3.3. Cách lập trình súc tích Hồi quy Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression_vn.html">3.4. Hồi quy Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/fashion-mnist_vn.html">3.5. Bộ dữ liệu Phân loại Ảnh (Fashion-MNIST)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-scratch_vn.html">3.6. Lập trình Hồi quy Sofmax từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-networks/softmax-regression-gluon_vn.html">3.7. Cách lập trình súc tích Hồi quy Softmax</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index_vn.html">4. Perceptron Đa tầng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp_vn.html">4.1. Perceptron đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-scratch_vn.html">4.2. Lập trình Perceptron Đa tầng từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-gluon_vn.html">4.3. Cách lập trình súc tích Perceptron Đa tầng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/underfit-overfit_vn.html">4.4. Lựa Chọn Mô Hình, Dưới Khớp và Quá Khớp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/weight-decay_vn.html">4.5. Suy giảm trọng số</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout_vn.html">4.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop_vn.html">4.7. Lan truyền xuôi, Lan truyền ngược và Đồ thị tính toán</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init_vn.html">4.8. Ổn định Số học và Khởi tạo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/environment_vn.html">4.9. Cân nhắc tới Môi trường</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price_vn.html">4.10. Dự đoán Giá Nhà trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index_vn.html">5. Tính toán Học sâu</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="model-construction_vn.html">5.1. Tầng và Khối</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameters_vn.html">5.2. Quản lý Tham số</a></li>
<li class="toctree-l2"><a class="reference internal" href="deferred-init_vn.html">5.3. Khởi tạo trễ</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom-layer_vn.html">5.4. Các tầng Tuỳ chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="read-write_vn.html">5.5. Đọc/Ghi tệp</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">5.6. GPU</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index_vn.html">6. Mạng Nơ-ron Tích chập</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv_vn.html">6.1. Từ Tầng Kết nối Dày đặc đến phép Tích chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer_vn.html">6.2. Phép Tích chập cho Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides_vn.html">6.3. Đệm và Sải Bước</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels_vn.html">6.4. Đa kênh Đầu vào và Đầu ra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling_vn.html">6.5. Gộp (<em>Pooling</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet_vn.html">6.6. Mạng Nơ-ron Tích chập (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index_vn.html">7. Mạng Nơ-ron Tích chập Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet_vn.html">7.1. Mạng Nơ-ron Tích chập Sâu (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/vgg_vn.html">7.2. Mạng sử dụng Khối (VGG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/nin_vn.html">7.3. Mạng trong Mạng (<em>Network in Network - NiN</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet_vn.html">7.4. Mạng nối song song (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm_vn.html">7.5. Chuẩn hoá theo batch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet_vn.html">7.6. Mạng phần dư (ResNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet_vn.html">7.7. Mạng Tích chập Kết nối Dày đặc (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index_vn.html">8. Mạng Nơ-ron Hồi tiếp</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence_vn.html">8.1. Mô hình chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-preprocessing_vn.html">8.2. Tiền Xử lý Dữ liệu Văn bản</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-models-and-dataset_vn.html">8.3. Mô hình Ngôn ngữ và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn_vn.html">8.4. Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch_vn.html">8.5. Lập trình Mạng nơ-ron Hồi tiếp từ đầu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-gluon_vn.html">8.6. Lập trình súc tích Mạng nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt_vn.html">8.7. Lan truyền Ngược qua Thời gian</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index_vn.html">9. Mạng Nơ-ron Hồi tiếp Hiện đại</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru_vn.html">9.1. Nút Hồi tiếp có Cổng (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm_vn.html">9.2. Bộ nhớ Ngắn hạn Dài (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn_vn.html">9.3. Mạng Nơ-ron Hồi tiếp Sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/bi-rnn_vn.html">9.4. Mạng Nơ-ron Hồi tiếp Hai chiều</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset_vn.html">9.5. Dịch Máy và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder_vn.html">9.6. Kiến trúc Mã hoá - Giải mã</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq_vn.html">9.7. Chuỗi sang Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search_vn.html">9.8. Tìm kiếm Chùm</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms/index_vn.html">10. Cơ chế Tập trung</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/attention_vn.html">10.1. Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/seq2seq-attention_vn.html">10.2. Chuỗi sang Chuỗi áp dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms/transformer_vn.html">10.3. Kiến trúc Transformer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index_vn.html">11. Thuật toán Tối ưu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html">11.1. Tối ưu và Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-thach-thuc-cua-toi-uu-trong-hoc-sau">11.2. Các Thách thức của Tối ưu trong Học sâu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-vung-cuc-tieu">11.3. Các vùng Cực tiểu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#cac-diem-yen-ngua">11.4. Các điểm Yên ngựa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro_vn.html#tieu-bien-gradient">11.5. Tiêu biến Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity_vn.html">11.6. Tính lồi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd_vn.html">11.7. Hạ Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd_vn.html">11.8. Hạ Gradient Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd_vn.html">11.9. Hạ Gradient Ngẫu nhiên theo Minibatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum_vn.html">11.10. Động lượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad_vn.html">11.11. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop_vn.html">11.12. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta_vn.html">11.13. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam_vn.html">11.14. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler_vn.html">11.15. Định thời Tốc độ Học</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational-performance/index_vn.html">12. Hiệu năng Tính toán</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hybridize_vn.html">12.1. Trình biên dịch và Trình thông dịch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/async-computation_vn.html">12.2. Tính toán Bất đồng bộ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/auto-parallelism_vn.html">12.3. Song song hóa Tự động</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hardware_vn.html">12.4. Phần cứng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus_vn.html">12.5. Huấn luyện đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus-concise_vn.html">12.6. Cách lập trình Súc tích đa GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/parameterserver_vn.html">12.7. Máy chủ Tham số</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index_vn.html">13. Thị giác Máy tính</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation_vn.html">13.1. Tăng cường Ảnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning_vn.html">13.2. Tinh Chỉnh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box_vn.html">13.3. Phát hiện Vật thể và Khoanh vùng Đối tượng (Khung chứa)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor_vn.html">13.4. Khung neo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection_vn.html">13.5. Phát hiện Vật thể Đa tỷ lệ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset_vn.html">13.6. Tập dữ liệu Phát hiện Đối tượng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd_vn.html">13.7. Phát hiện Nhiều khung Một lượt (SSD)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn_vn.html">13.8. CNN theo Vùng (R-CNN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset_vn.html">13.9. Phân vùng theo Ngữ nghĩa và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv_vn.html">13.10. Tích chập Chuyển vị</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn_vn.html">13.11. Mạng Tích chập Đầy đủ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style_vn.html">13.12. Truyền tải Phong cách Nơ-ron</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10_vn.html">13.13. Phân loại ảnh (CIFAR-10) trên Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog_vn.html">13.14. Nhận diện Giống Chó (ImageNet Dogs) trên Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index_vn.html">14. Xử lý Ngôn ngữ Tự nhiên: Tiền Huấn luyện</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec_vn.html">14.1. Embedding Từ (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training_vn.html">14.2. Huấn luyện Gần đúng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset_vn.html">14.3. Tập dữ liệu để Tiền Huấn luyện Embedding Từ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining_vn.html">14.4. Tiền huấn luyện word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove_vn.html">14.5. Embedding từ với Vector Toàn cục (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding_vn.html">14.6. Embedding từ con</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy_vn.html">14.7. Tìm kiếm từ Đồng nghĩa và Loại suy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert_vn.html">14.8. Biểu diễn Mã hóa hai chiều từ Transformer (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset_vn.html">14.9. Tập dữ liệu để Tiền huấn luyện BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining_vn.html">14.10. Tiền Huấn luyện BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index_vn.html">15. Xử lý Ngôn ngữ Tự nhiên: Ứng dụng</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset_vn.html">15.1. Tác vụ Phân tích Cảm xúc và Bộ Dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn_vn.html">15.2. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Hồi tiếp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn_vn.html">15.3. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Tích Chập</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset_vn.html">15.4. Suy luận ngôn ngữ tự nhiên và Tập dữ liệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention_vn.html">15.5. Suy luận Ngôn ngữ Tự nhiên: Sử dụng Cơ chế Tập trung</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert_vn.html">15.6. Tinh chỉnh BERT cho các Ứng dụng Cấp Chuỗi và Cấp Token</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-bert_vn.html">15.7. Suy luận Ngôn ngữ Tự nhiên: Tinh chỉnh BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender-systems/index_vn.html">16. Hệ thống Đề xuất</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/recsys-intro_vn.html">16.1. Tổng quan về Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/movielens_vn.html">16.2. Tập dữ liệu MovieLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/mf_vn.html">16.3. Phân rã Ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/autorec_vn.html">16.4. AutoRec: Dự đoán Đánh giá với Bộ tự Mã hóa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ranking_vn.html">16.5. Cá nhân hóa Xếp hạng trong Hệ thống Đề xuất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/neumf_vn.html">16.6. Lọc Cộng tác Nơ-ron cho Cá nhân hóa Xếp hạng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/seqrec_vn.html">16.7. Hệ thống Đề xuất có Nhận thức về Chuỗi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ctr_vn.html">16.8. Hệ thống Đề xuất Giàu Đặc trưng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/fm_vn.html">16.9. Máy Phân rã ma trận</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/deepfm_vn.html">16.10. Máy Phân rã Ma trận Sâu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_generative-adversarial-networks/index_vn.html">17. Mạng Đối sinh</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/gan_vn.html">17.1. Mạng Đối sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/dcgan_vn.html">17.2. Mạng Đối sinh Tích chập Sâu</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/index_vn.html">18. Phụ lục: Toán học cho Học Sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops_vn.html">18.1. Các phép toán Hình học và Đại số Tuyến tính</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition_vn.html">18.2. Phân rã trị riêng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus_vn.html">18.3. Giải tích một biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus_vn.html">18.4. Giải tích Nhiều biến</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus_vn.html">18.5. Giải tích Tích phân</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/random-variables_vn.html">18.6. Biến Ngẫu nhiên</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood_vn.html">18.7. Hợp lý Cực đại</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/distributions_vn.html">18.8. Các Phân phối Xác suất</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes_vn.html">18.9. Bộ phân loại Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/statistics_vn.html">18.10. Thống kê</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/information-theory_vn.html">18.11. Lý thuyết Thông tin</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index_vn.html">19. Phụ lục: Công cụ cho Học Sâu</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/jupyter_vn.html">19.1. Sử dụng Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/sagemaker_vn.html">19.2. Sử dụng Amazon SageMaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/aws_vn.html">19.3. Sử dụng Máy ảo AWS EC2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/colab_vn.html">19.4. Sử dụng Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus_vn.html">19.5. Lựa chọn Máy chủ &amp; GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/contributing_vn.html">19.6. Đóng góp cho Quyển sách</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/d2l_vn.html">19.7. Tài liệu API của <code class="docutils literal notranslate"><span class="pre">d2l</span></code></a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/zreferences.html">Tài liệu tham khảo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Bảng thuật ngữ</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <!-- ===================== Bắt đầu dịch Phần 1 ===================== --><!-- ========================================= REVISE PHẦN 1 - BẮT ĐẦU =================================== --><!--
# GPUs
--><div class="section" id="gpu">
<span id="sec-use-gpu"></span><h1><span class="section-number">5.6. </span>GPU<a class="headerlink" href="#gpu" title="Permalink to this headline">¶</a></h1>
<!--
In the introduction, we discussed the rapid growth of computation over the past two decades.
In a nutshell, GPU performance has increased by a factor of 1000 every decade since 2000.
This offers great opportunity but it also suggests a significant need to provide such performance.
--><p>Trong phần giới thiệu của cuốn sách này, chúng ta đã thảo luận về sự
tăng trưởng đột phá của năng lực tính toán trong hai thập niên vừa qua.
Một cách ngắn gọn, hiệu năng GPU đã tăng lên gấp 1000 lần trong mỗi thập
niên kể từ năm 2000. Điều này mang lại cơ hội to lớn nhưng kèm theo đó
là một nhu cầu không hề nhỏ để cung cấp hiệu năng tính toán như vậy.</p>
<!--
|Decade|Dataset|Memory|Floating Point Calculations per Second|
|:--|:-|:-|:-|
|1970|100 (Iris)|1 KB|100 KF (Intel 8080)|
|1980|1 K (House prices in Boston)|100 KB|1 MF (Intel 80186)|
|1990|10 K (optical character recognition)|10 MB|10 MF (Intel 80486)|
|2000|10 M (web pages)|100 MB|1 GF (Intel Core)|
|2010|10 G (advertising)|1 GB|1 TF (NVIDIA C2050)|
|2020|1 T (social network)|100 GB|1 PF (NVIDIA DGX-2)|
--><table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Thập niên</th>
<th class="head">Tập dữ liệu</th>
<th class="head">Bộ nhớ</th>
<th class="head">Số Phép tính
Dấu phẩy động
trên Giây</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1970</td>
<td>100 (Iris)</td>
<td>1 KB</td>
<td>100 KF (Intel
8080)</td>
</tr>
<tr class="row-odd"><td>1980</td>
<td>1 K (Giá nhà
tại Boston)</td>
<td>100 KB</td>
<td>1 MF (Intel
80186)</td>
</tr>
<tr class="row-even"><td>1990</td>
<td>10 K (Nhận diện
ký tự quang
học)</td>
<td>10 MB</td>
<td>10 MF (Intel
80486)</td>
</tr>
<tr class="row-odd"><td>2000</td>
<td>10 M (các trang
web)</td>
<td>100 MB</td>
<td>1 GF (Intel
Core)</td>
</tr>
<tr class="row-even"><td>2010</td>
<td>10 G (quảng
cáo)</td>
<td>1 GB</td>
<td>1 TF (NVIDIA
C2050)</td>
</tr>
<tr class="row-odd"><td>2020</td>
<td>1 T (mạng xã
hội)</td>
<td>100 GB</td>
<td>1 PF (NVIDIA
DGX-2)</td>
</tr>
</tbody>
</table>
<!--
In this section, we begin to discuss how to harness this compute performance for your research.
First by using single GPUs and at a later point, how to use multiple GPUs and multiple servers (with multiple GPUs).
You might have noticed that MXNet `ndarray` looks almost identical to NumPy. But there are a few crucial differences.
One of the key features that distinguishes MXNet from NumPy is its support for diverse hardware devices.
--><p>Trong phần này, ta bắt đầu thảo luận cách khai thác hiệu năng tính toán
này cho việc nghiên cứu. Đầu tiên ta sẽ tìm hiểu cách sử dụng một GPU
duy nhất, rồi sau này tiến tới nhiều GPU và nhiều máy chủ (cùng với
nhiều GPU). Bạn có thể đã nhận ra MXNet <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> trông gần như giống
hệt NumPy, nhưng chúng có một vài điểm khác biệt quan trọng. Một trong
những tính năng chính khiến cho MXNet khác với NumPy là MXNet hỗ trợ
nhiều loại phần cứng đa dạng.</p>
<!--
In MXNet, every array has a context.
So far, by default, all variables and associated computation have been assigned to the CPU.
Typically, other contexts might be various GPUs.
Things can get even hairier when we deploy jobs across multiple servers.
By assigning arrays to contexts intelligently, we can minimize the time spent transferring data between devices.
For example, when training neural networks on a server with a GPU, we typically prefer for the model’s parameters to live on the GPU.
--><p>Trong MXNet, mỗi mảng có một bối cảnh. Cho tới giờ, tất cả các biến và
phép toán liên quan đều được giao cho CPU theo mặc định. Các bối cảnh
thường có thể là nhiều GPU khác. Mọi thứ còn có thể trở nên rối rắm hơn
khi ta triển khai công việc trên nhiều máy chủ. Bằng cách chỉ định bối
cảnh cho các mảng một cách thông minh, ta có thể giảm thiểu thời gian
truyền tải dữ liệu giữa các thiết bị. Ví dụ, khi huấn luyện mạng nơ-ron
trên máy chủ có GPU, ta thường muốn các tham số mô hình nằm ở trên GPU.</p>
<!-- ===================== Kết thúc dịch Phần 1 ===================== --><!-- ===================== Bắt đầu dịch Phần 2 ===================== --><!--
In short, for complex neural networks and large-scale data, using only CPUs for computation may be inefficient.
In this section, we will discuss how to use a single NVIDIA GPU for calculations.
First, make sure you have at least one NVIDIA GPU installed.
Then, [download CUDA](https://developer.nvidia.com/cuda-downloads) and follow the prompts to set the appropriate path.
Once these preparations are complete, the `nvidia-smi` command can be used to view the graphics card information.
--><p>Nói ngắn gọn, với những mạng nơ-ron phức tạp và dữ liệu quy mô lớn, việc
chỉ sử dụng CPU để tính toán có thể sẽ không hiệu quả. Trong phần này,
ta sẽ thảo luận về cách sử dụng một GPU NVIDIA duy nhất cho việc tính
toán. Đầu tiên, hãy chắc chắn rằng bạn đã lắp đặt ít nhất một GPU
NVIDIA. Sau đó, hãy <a class="reference external" href="https://developer.nvidia.com/cuda-downloads">tải
CUDA</a> và làm theo gợi ý
để thiết lập đường dẫn hợp lý. Một khi các bước chuẩn bị đã được hoàn
thành, ta có thể dùng lệnh <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> để xem thông tin card đồ họa.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!nvidia-smi
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Thu</span> <span class="n">Aug</span> <span class="mi">13</span> <span class="mi">03</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">01</span> <span class="mi">2020</span>
<span class="o">+-----------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">NVIDIA</span><span class="o">-</span><span class="n">SMI</span> <span class="mf">430.50</span>       <span class="n">Driver</span> <span class="n">Version</span><span class="p">:</span> <span class="mf">430.50</span>       <span class="n">CUDA</span> <span class="n">Version</span><span class="p">:</span> <span class="mf">10.1</span>     <span class="o">|</span>
<span class="o">|-------------------------------+----------------------+----------------------+</span>
<span class="o">|</span> <span class="n">GPU</span>  <span class="n">Name</span>        <span class="n">Persistence</span><span class="o">-</span><span class="n">M</span><span class="o">|</span> <span class="n">Bus</span><span class="o">-</span><span class="n">Id</span>        <span class="n">Disp</span><span class="o">.</span><span class="n">A</span> <span class="o">|</span> <span class="n">Volatile</span> <span class="n">Uncorr</span><span class="o">.</span> <span class="n">ECC</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">Fan</span>  <span class="n">Temp</span>  <span class="n">Perf</span>  <span class="n">Pwr</span><span class="p">:</span><span class="n">Usage</span><span class="o">/</span><span class="n">Cap</span><span class="o">|</span>         <span class="n">Memory</span><span class="o">-</span><span class="n">Usage</span> <span class="o">|</span> <span class="n">GPU</span><span class="o">-</span><span class="n">Util</span>  <span class="n">Compute</span> <span class="n">M</span><span class="o">.</span> <span class="o">|</span>
<span class="o">|===============================+======================+======================|</span>
<span class="o">|</span>   <span class="mi">0</span>  <span class="n">TITAN</span> <span class="n">Xp</span>            <span class="n">On</span>   <span class="o">|</span> <span class="mi">00000000</span><span class="p">:</span><span class="mi">04</span><span class="p">:</span><span class="mf">00.0</span> <span class="n">Off</span> <span class="o">|</span>                  <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="o">|</span>
<span class="o">|</span> <span class="mi">35</span><span class="o">%</span>   <span class="mi">60</span><span class="n">C</span>    <span class="n">P2</span>   <span class="mi">187</span><span class="n">W</span> <span class="o">/</span> <span class="mi">250</span><span class="n">W</span> <span class="o">|</span>  <span class="mi">11751</span><span class="n">MiB</span> <span class="o">/</span> <span class="mi">12196</span><span class="n">MiB</span> <span class="o">|</span>     <span class="mi">49</span><span class="o">%</span>      <span class="n">Default</span> <span class="o">|</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>
<span class="o">|</span>   <span class="mi">1</span>  <span class="n">TITAN</span> <span class="n">Xp</span>            <span class="n">On</span>   <span class="o">|</span> <span class="mi">00000000</span><span class="p">:</span><span class="mi">06</span><span class="p">:</span><span class="mf">00.0</span> <span class="n">Off</span> <span class="o">|</span>                  <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="o">|</span>
<span class="o">|</span> <span class="mi">38</span><span class="o">%</span>   <span class="mi">64</span><span class="n">C</span>    <span class="n">P2</span>    <span class="mi">92</span><span class="n">W</span> <span class="o">/</span> <span class="mi">250</span><span class="n">W</span> <span class="o">|</span>  <span class="mi">11751</span><span class="n">MiB</span> <span class="o">/</span> <span class="mi">12196</span><span class="n">MiB</span> <span class="o">|</span>     <span class="mi">60</span><span class="o">%</span>      <span class="n">Default</span> <span class="o">|</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>
<span class="o">|</span>   <span class="mi">2</span>  <span class="n">TITAN</span> <span class="n">Xp</span>            <span class="n">On</span>   <span class="o">|</span> <span class="mi">00000000</span><span class="p">:</span><span class="mi">07</span><span class="p">:</span><span class="mf">00.0</span> <span class="n">Off</span> <span class="o">|</span>                  <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="o">|</span>
<span class="o">|</span> <span class="mi">30</span><span class="o">%</span>   <span class="mi">40</span><span class="n">C</span>    <span class="n">P8</span>    <span class="mi">10</span><span class="n">W</span> <span class="o">/</span> <span class="mi">250</span><span class="n">W</span> <span class="o">|</span>      <span class="mi">0</span><span class="n">MiB</span> <span class="o">/</span> <span class="mi">12196</span><span class="n">MiB</span> <span class="o">|</span>      <span class="mi">0</span><span class="o">%</span>      <span class="n">Default</span> <span class="o">|</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>
<span class="o">|</span>   <span class="mi">3</span>  <span class="n">TITAN</span> <span class="n">Xp</span>            <span class="n">On</span>   <span class="o">|</span> <span class="mi">00000000</span><span class="p">:</span><span class="mi">08</span><span class="p">:</span><span class="mf">00.0</span> <span class="n">Off</span> <span class="o">|</span>                  <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="o">|</span>
<span class="o">|</span> <span class="mi">23</span><span class="o">%</span>   <span class="mi">21</span><span class="n">C</span>    <span class="n">P8</span>     <span class="mi">9</span><span class="n">W</span> <span class="o">/</span> <span class="mi">250</span><span class="n">W</span> <span class="o">|</span>      <span class="mi">0</span><span class="n">MiB</span> <span class="o">/</span> <span class="mi">12196</span><span class="n">MiB</span> <span class="o">|</span>      <span class="mi">0</span><span class="o">%</span>      <span class="n">Default</span> <span class="o">|</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>
<span class="o">|</span>   <span class="mi">4</span>  <span class="n">TITAN</span> <span class="n">Xp</span>            <span class="n">On</span>   <span class="o">|</span> <span class="mi">00000000</span><span class="p">:</span><span class="mi">0</span><span class="n">C</span><span class="p">:</span><span class="mf">00.0</span> <span class="n">Off</span> <span class="o">|</span>                  <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="o">|</span>
<span class="o">|</span> <span class="mi">23</span><span class="o">%</span>   <span class="mi">21</span><span class="n">C</span>    <span class="n">P8</span>     <span class="mi">8</span><span class="n">W</span> <span class="o">/</span> <span class="mi">250</span><span class="n">W</span> <span class="o">|</span>  <span class="mi">11767</span><span class="n">MiB</span> <span class="o">/</span> <span class="mi">12196</span><span class="n">MiB</span> <span class="o">|</span>      <span class="mi">0</span><span class="o">%</span>      <span class="n">Default</span> <span class="o">|</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>
<span class="o">|</span>   <span class="mi">5</span>  <span class="n">TITAN</span> <span class="n">Xp</span>            <span class="n">On</span>   <span class="o">|</span> <span class="mi">00000000</span><span class="p">:</span><span class="mi">0</span><span class="n">D</span><span class="p">:</span><span class="mf">00.0</span> <span class="n">Off</span> <span class="o">|</span>                  <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="o">|</span>
<span class="o">|</span> <span class="mi">23</span><span class="o">%</span>   <span class="mi">21</span><span class="n">C</span>    <span class="n">P8</span>     <span class="mi">7</span><span class="n">W</span> <span class="o">/</span> <span class="mi">250</span><span class="n">W</span> <span class="o">|</span>      <span class="mi">0</span><span class="n">MiB</span> <span class="o">/</span> <span class="mi">12196</span><span class="n">MiB</span> <span class="o">|</span>      <span class="mi">0</span><span class="o">%</span>      <span class="n">Default</span> <span class="o">|</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>
<span class="o">|</span>   <span class="mi">6</span>  <span class="n">TITAN</span> <span class="n">Xp</span>            <span class="n">On</span>   <span class="o">|</span> <span class="mi">00000000</span><span class="p">:</span><span class="mi">0</span><span class="n">E</span><span class="p">:</span><span class="mf">00.0</span> <span class="n">Off</span> <span class="o">|</span>                  <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="o">|</span>
<span class="o">|</span> <span class="mi">26</span><span class="o">%</span>   <span class="mi">46</span><span class="n">C</span>    <span class="n">P2</span>    <span class="mi">83</span><span class="n">W</span> <span class="o">/</span> <span class="mi">250</span><span class="n">W</span> <span class="o">|</span>   <span class="mi">5697</span><span class="n">MiB</span> <span class="o">/</span> <span class="mi">12196</span><span class="n">MiB</span> <span class="o">|</span>      <span class="mi">0</span><span class="o">%</span>      <span class="n">Default</span> <span class="o">|</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>
<span class="o">|</span>   <span class="mi">7</span>  <span class="n">TITAN</span> <span class="n">Xp</span>            <span class="n">On</span>   <span class="o">|</span> <span class="mi">00000000</span><span class="p">:</span><span class="mi">0</span><span class="n">F</span><span class="p">:</span><span class="mf">00.0</span> <span class="n">Off</span> <span class="o">|</span>                  <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="o">|</span>
<span class="o">|</span> <span class="mi">23</span><span class="o">%</span>   <span class="mi">20</span><span class="n">C</span>    <span class="n">P8</span>     <span class="mi">8</span><span class="n">W</span> <span class="o">/</span> <span class="mi">250</span><span class="n">W</span> <span class="o">|</span>      <span class="mi">0</span><span class="n">MiB</span> <span class="o">/</span> <span class="mi">12196</span><span class="n">MiB</span> <span class="o">|</span>      <span class="mi">0</span><span class="o">%</span>      <span class="n">Default</span> <span class="o">|</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>

<span class="o">+-----------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">Processes</span><span class="p">:</span>                                                       <span class="n">GPU</span> <span class="n">Memory</span> <span class="o">|</span>
<span class="o">|</span>  <span class="n">GPU</span>       <span class="n">PID</span>   <span class="n">Type</span>   <span class="n">Process</span> <span class="n">name</span>                             <span class="n">Usage</span>      <span class="o">|</span>
<span class="o">|=============================================================================|</span>
<span class="o">|</span>    <span class="mi">0</span>     <span class="mi">10621</span>      <span class="n">C</span>   <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">conda</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span>                      <span class="mi">11739</span><span class="n">MiB</span> <span class="o">|</span>
<span class="o">|</span>    <span class="mi">1</span>     <span class="mi">10734</span>      <span class="n">C</span>   <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">conda</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span>                      <span class="mi">11739</span><span class="n">MiB</span> <span class="o">|</span>
<span class="o">|</span>    <span class="mi">4</span>     <span class="mi">30712</span>      <span class="n">C</span>   <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span>                           <span class="mi">11757</span><span class="n">MiB</span> <span class="o">|</span>
<span class="o">|</span>    <span class="mi">6</span>     <span class="mi">25599</span>      <span class="n">C</span>   <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span>                            <span class="mi">5687</span><span class="n">MiB</span> <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------+</span>
</pre></div>
</div>
<!--
Next, we need to confirm that the GPU version of MXNet is installed.
If a CPU version of MXNet is already installed, we need to uninstall it first.
For example, use the `pip uninstall mxnet` command, then install the corresponding MXNet version according to your CUDA version.
Assuming you have CUDA 9.0 installed, you can install the MXNet version that supports CUDA 9.0 via `pip install mxnet-cu90`.
To run the programs in this section, you need at least two GPUs.
--><p>Tiếp theo, cần chắc chắn rằng ta đã cài đặt phiên bản GPU của MXNet. Nếu
phiên bản CPU của MXNet đã được cài đặt trước, ta cần phải gỡ bỏ nó. Ví
dụ, hãy sử dụng lệnh <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">uninstall</span> <span class="pre">mxnet</span></code>, sau đó cài đặt phiên bản
MXNet tương ứng với phiên bản CUDA. Giả sử như bạn đã cài CUDA 9.0, bạn
có thể cài phiên bản MXNet có hỗ trợ CUDA 9.0 bằng lệnh
<code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">mxnet-cu90</span></code>. Để chạy các chương trình trong phần này, bạn
cần ít nhất hai GPU.</p>
<!--
Note that this might be extravagant for most desktop computers but it is easily available in the cloud,
e.g., by using the AWS EC2 multi-GPU instances. Almost all other sections do *not* require multiple GPUs.
Instead, this is simply to illustrate how data flows between different devices.
--><p>Yêu cầu này có vẻ khá phung phí với hầu hết các bộ máy tính để bàn nhưng
lại rất dễ dàng nếu ta dùng các dịch vụ đám mây, chẳng hạn ta có thể
thuê một máy chủ AWS EC2 đa GPU. Hầu hết các phần khác trong cuốn sách
này <em>không</em> yêu cầu đa GPU. Tuy nhiên, việc này chỉ để minh họa cách dữ
liệu được truyền giữa các thiết bị khác nhau.</p>
<!-- ===================== Kết thúc dịch Phần 2 ===================== --><!-- ===================== Bắt đầu dịch Phần 3 ===================== --><!-- ========================================= REVISE PHẦN 1 - KẾT THÚC ===================================--><!-- ========================================= REVISE PHẦN 2 - BẮT ĐẦU ===================================--><!--
## Computing Devices
--><div class="section" id="thiet-bi-tinh-toan">
<h2><span class="section-number">5.6.1. </span>Thiết bị Tính toán<a class="headerlink" href="#thiet-bi-tinh-toan" title="Permalink to this headline">¶</a></h2>
<!--
MXNet can specify devices, such as CPUs and GPUs, for storage and calculation.
By default, MXNet creates data in the main memory and then uses the CPU to calculate it.
In MXNet, the CPU and GPU can be indicated by `cpu()` and `gpu()`.
It should be noted that `cpu()` (or any integer in the parentheses) means all physical CPUs and memory.
This means that MXNet's calculations will try to use all CPU cores.
However, `gpu()` only represents one card and the corresponding memory.
If there are multiple GPUs, we use `gpu(i)` to represent the $i^\mathrm{th}$ GPU ($i$ starts from 0).
Also, `gpu(0)` and `gpu()` are equivalent.
--><p>MXNet có thể chỉ định các thiết bị, chẳng hạn như CPU và GPU, cho việc
lưu trữ và tính toán. Mặc định, MXNet tạo dữ liệu trong bộ nhớ chính và
sau đó sử dụng CPU để tính toán. Trong MXNet, CPU và GPU có thể được chỉ
định bởi <code class="docutils literal notranslate"><span class="pre">cpu</span> <span class="pre">()</span></code> và <code class="docutils literal notranslate"><span class="pre">gpu</span> <span class="pre">()</span></code>. Cần lưu ý rằng <code class="docutils literal notranslate"><span class="pre">cpu()</span></code> (đơn thuần
hoặc thêm bất kỳ số nguyên nào trong ngoặc đơn) có nghĩa là sử dụng tất
cả các CPU và bộ nhớ vật lý. Điều này có nghĩa các tính toán của MXNet
sẽ cố gắng tận dụng tất cả các lõi CPU. Tuy nhiên, <code class="docutils literal notranslate"><span class="pre">gpu()</span></code> đơn thuần
chỉ đại diện cho một card đồ họa và bộ nhớ đồ họa tương ứng. Nếu có
nhiều GPU, chúng tôi sử dụng <code class="docutils literal notranslate"><span class="pre">gpu(i)</span></code> để thể hiện GPU thứ <span class="math notranslate nohighlight">\(i\)</span>
(với <span class="math notranslate nohighlight">\(i\)</span> bắt đầu từ 0). Ngoài ra, <code class="docutils literal notranslate"><span class="pre">gpu(0)</span></code> và <code class="docutils literal notranslate"><span class="pre">gpu()</span></code> tương
đương nhau.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">np</span><span class="p">,</span> <span class="n">npx</span>
<span class="kn">from</span> <span class="nn">mxnet.gluon</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="n">npx</span><span class="o">.</span><span class="n">set_np</span><span class="p">()</span>

<span class="n">npx</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">npx</span><span class="o">.</span><span class="n">gpu</span><span class="p">(),</span> <span class="n">npx</span><span class="o">.</span><span class="n">gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<!--
We can query the number of available GPUs through `num_gpus()`.
--><p>Ta có thể truy vấn số lượng GPU có sẵn thông qua <code class="docutils literal notranslate"><span class="pre">num_gpus()</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">npx</span><span class="o">.</span><span class="n">num_gpus</span><span class="p">()</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">2</span>
</pre></div>
</div>
<!--
Now we define two convenient functions that allow us to run codes even if the requested GPUs do not exist.
--><p>Bây giờ ta định nghĩa hai hàm chức năng thuận tiện cho việc chạy mã kể
cả khi GPU được yêu cầu không tồn tại.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Saved in the d2l package for later use</span>
<span class="k">def</span> <span class="nf">try_gpu</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return gpu(i) if exists, otherwise return cpu().&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">npx</span><span class="o">.</span><span class="n">gpu</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">if</span> <span class="n">npx</span><span class="o">.</span><span class="n">num_gpus</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">npx</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="c1"># Saved in the d2l package for later use</span>
<span class="k">def</span> <span class="nf">try_all_gpus</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return all available GPUs, or [cpu(),] if no GPU exists.&quot;&quot;&quot;</span>
    <span class="n">ctxes</span> <span class="o">=</span> <span class="p">[</span><span class="n">npx</span><span class="o">.</span><span class="n">gpu</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">npx</span><span class="o">.</span><span class="n">num_gpus</span><span class="p">())]</span>
    <span class="k">return</span> <span class="n">ctxes</span> <span class="k">if</span> <span class="n">ctxes</span> <span class="k">else</span> <span class="p">[</span><span class="n">npx</span><span class="o">.</span><span class="n">cpu</span><span class="p">()]</span>

<span class="n">try_gpu</span><span class="p">(),</span> <span class="n">try_gpu</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">try_all_gpus</span><span class="p">()</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="n">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">)])</span>
</pre></div>
</div>
<!--
## `ndarray` and GPUs
--></div>
<div class="section" id="ndarray-va-gpu">
<h2><span class="section-number">5.6.2. </span><code class="docutils literal notranslate"><span class="pre">ndarray</span></code> và GPU<a class="headerlink" href="#ndarray-va-gpu" title="Permalink to this headline">¶</a></h2>
<!--
By default, `ndarray` objects are created on the CPU.
We can use the `ctx` property of `ndarray` to view the device where the `ndarray` is located.
--><p>Mặc định, các đối tượng <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> được tạo trên CPU. Do đó, ta sẽ thấy
định danh <code class="docutils literal notranslate"><span class="pre">&#64;cpu(0)</span></code> mỗi khi ta in một <code class="docutils literal notranslate"><span class="pre">ndarray</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">x</span><span class="o">.</span><span class="n">ctx</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<!--
It is important to note that whenever we want to operate on multiple terms, they need to be in the same context.
For instance, if we sum two ndarrays, we need to make sure that both arguments live on the same device---otherwise MXNet
would not know where to store the result or even how to decide where to perform the computation.
--><p>Điều quan trọng cần lưu ý là bất cứ khi nào ta muốn làm các phép toán
trên nhiều số hạng, chúng cần phải ở trong cùng một bối cảnh. Chẳng hạn,
nếu ta tính tổng hai biến, ta cần đảm bảo rằng cả hai đối số đều nằm
trên cùng một thiết bị — nếu không thì MXNet sẽ không biết nơi lưu trữ
kết quả hoặc thậm chí cách quyết định nơi thực hiện tính toán.</p>
<!-- ===================== Kết thúc dịch Phần 3 ===================== --><!-- ===================== Bắt đầu dịch Phần 4 ===================== --><!--
### Storage on the GPU
--><div class="section" id="luu-tru-tren-gpu">
<h3><span class="section-number">5.6.2.1. </span>Lưu trữ trên GPU<a class="headerlink" href="#luu-tru-tren-gpu" title="Permalink to this headline">¶</a></h3>
<!--
There are several ways to store an `ndarray` on the GPU.
For example, we can specify a storage device with the `ctx` parameter when creating an `ndarray`.
Next, we create the `ndarray` variable `a` on `gpu(0)`.
Notice that when printing `a`, the device information becomes `@gpu(0)`.
The `ndarray` created on a GPU only consumes the memory of this GPU.
We can use the `nvidia-smi` command to view GPU memory usage.
In general, we need to make sure we do not create data that exceeds the GPU memory limit.
--><p>Có một số cách để lưu trữ một <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> trên GPU. Ví dụ: ta có thể chỉ
định một thiết bị lưu trữ với tham số <code class="docutils literal notranslate"><span class="pre">ctx</span></code> khi tạo một<code class="docutils literal notranslate"><span class="pre">ndarray</span></code>.
Tiếp theo, ta tạo biến <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> là <code class="docutils literal notranslate"><span class="pre">a</span></code> trên <code class="docutils literal notranslate"><span class="pre">gpu(0)</span></code>. Lưu ý rằng
khi in <code class="docutils literal notranslate"><span class="pre">a</span></code> ra màn hình, thông tin thiết bị sẽ trở thành <code class="docutils literal notranslate"><span class="pre">&#64;gpu(0)</span></code>.
<code class="docutils literal notranslate"><span class="pre">ndarray</span></code> được tạo trên GPU nào chỉ chiếm bộ nhớ của GPU đó. Ta có thể
sử dụng lệnh <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> để xem việc sử dụng bộ nhớ GPU. Nói chung,
ta cần đảm bảo rằng ta không tạo dữ liệu vượt quá giới hạn bộ nhớ GPU.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">ctx</span><span class="o">=</span><span class="n">try_gpu</span><span class="p">())</span>
<span class="n">x</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span> <span class="n">ctx</span><span class="o">=</span><span class="n">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<!--
Assuming you have at least two GPUs, the following code will create a random array on `gpu(1)`.
--><p>Giả sử bạn có ít nhất hai GPU, đoạn mã sau sẽ tạo ra một mảng ngẫu nhiên
trên <code class="docutils literal notranslate"><span class="pre">gpu(1)</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">ctx</span><span class="o">=</span><span class="n">try_gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span><span class="mf">0.67478997</span><span class="p">,</span> <span class="mf">0.07540122</span><span class="p">,</span> <span class="mf">0.9956977</span> <span class="p">],</span>
       <span class="p">[</span><span class="mf">0.09488854</span><span class="p">,</span> <span class="mf">0.415456</span>  <span class="p">,</span> <span class="mf">0.11231736</span><span class="p">]],</span> <span class="n">ctx</span><span class="o">=</span><span class="n">gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<!-- ========================================= REVISE PHẦN 2 - KẾT THÚC ===================================--><!-- ========================================= REVISE PHẦN 3 - BẮT ĐẦU ===================================--><!--
### Copying
--></div>
<div class="section" id="sao-chep">
<h3><span class="section-number">5.6.2.2. </span>Sao chép<a class="headerlink" href="#sao-chep" title="Permalink to this headline">¶</a></h3>
<!--
If we want to compute $\mathbf{x} + \mathbf{y}$, we need to decide where to perform this operation.
For instance, as shown in :numref:`fig_copyto`, we can transfer $\mathbf{x}$ to `gpu(1)` and perform the operation there.
*Do not* simply add `x + y`, since this will result in an exception.
The runtime engine would not know what to do, it cannot find data on the same device and it fails.
--><p>Nếu ta muốn tính <span class="math notranslate nohighlight">\(\mathbf{x} + \mathbf{y}\)</span> thì ta cần quyết định
nơi thực hiện phép tính này. Chẳng hạn, như trong
<a class="reference internal" href="#fig-copyto"><span class="std std-numref">Fig. 5.6.1</span></a>, ta có thể chuyển <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> sang
<code class="docutils literal notranslate"><span class="pre">gpu(1)</span></code> và thực hiện phép tính ở đó. <em>Đừng</em> chỉ thêm <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code> vì
điều này sẽ dẫn đến một lỗi. Hệ thống thời gian chạy sẽ không biết phải
làm gì và gặp lỗi bởi nó không thể tìm thấy dữ liệu trên cùng một thiết
bị.</p>
<!--
![Copyto copies arrays to the target device](../img/copyto.svg)
--><div class="figure align-default" id="id1">
<span id="fig-copyto"></span><img alt="../_images/copyto.svg" src="../_images/copyto.svg" /><p class="caption"><span class="caption-number">Fig. 5.6.1 </span><span class="caption-text">Lệnh <code class="docutils literal notranslate"><span class="pre">copyto</span></code> sao chép các mảng đến thiết bị mục tiêu</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<!--
`copyto` copies the data to another device such that we can add them.
Since $\mathbf{y}$ lives on the second GPU, we need to move $\mathbf{x}$ there before we can add the two.
--><p>Lệnh <code class="docutils literal notranslate"><span class="pre">copyto</span></code> sao chép dữ liệu sang một thiết bị khác để ta có thể
cộng chúng. Vì <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> tồn tại trên GPU thứ hai, ta cần di
chuyển <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> trước khi ta có thể cộng chúng lại.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copyto</span><span class="p">(</span><span class="n">try_gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span><span class="p">]]</span> <span class="nd">@gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="p">[[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span><span class="p">]]</span> <span class="nd">@gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<!-- ===================== Kết thúc dịch Phần 4 ===================== --><!-- ===================== Bắt đầu dịch Phần 5 ===================== --><!--
Now that the data is on the same GPU (both $\mathbf{z}$ and $\mathbf{y}$ are), we can add them up.
In such cases, MXNet places the result on the same device as its constituents.
In our case, that is `@gpu(1)`.
--><p>Bây giờ dữ liệu đã ở trên cùng một GPU (cả <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> và
<span class="math notranslate nohighlight">\(\mathbf{y}\)</span>), ta có thể cộng lại. Trong những trường hợp như vậy
MXNet lưu kết quả tại cùng thiết bị với các toán hạng. Trong trường hợp
này là <code class="docutils literal notranslate"><span class="pre">&#64;gpu(1)</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">+</span> <span class="n">z</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span><span class="mf">1.6747899</span><span class="p">,</span> <span class="mf">1.0754012</span><span class="p">,</span> <span class="mf">1.9956977</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.0948886</span><span class="p">,</span> <span class="mf">1.415456</span> <span class="p">,</span> <span class="mf">1.1123173</span><span class="p">]],</span> <span class="n">ctx</span><span class="o">=</span><span class="n">gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<!--
Imagine that your variable z already lives on your second GPU (gpu(1)).
What happens if we call z.copyto(gpu(1))?
It will make a copy and allocate new memory, even though that variable already lives on the desired device!
There are times where depending on the environment our code is running in, two variables may already live on the same device.
So we only want to make a copy if the variables currently lives on different contexts.
In these cases, we can call `as_in_ctx()`.
If the variable already live in the specified context then this is a no-op.
Unless you specifically want to make a copy, `as_in_ctx()` is the method of choice.
--><p>Giả sử biến <code class="docutils literal notranslate"><span class="pre">z</span></code> hiện đang được lưu trong GPU thứ hai (gpu(1)). Điều gì
sẽ xảy ra nếu ta gọi <code class="docutils literal notranslate"><span class="pre">z.copyto(gpu(1))</span></code>? Hàm này sẽ tạo một bản sao
của biến và cấp phát vùng nhớ mới cho bản sao, ngay cả khi biến đang có
trong thiết bị. Có những lúc mà tuỳ thuộc vào môi trường thực thi lệnh,
hai biến có thể đã ở trên cùng một thiết bị. Do đó chúng ta muốn chỉ tạo
bản sao khi các biến tồn tại ở các ngữ cảnh khác nhau. Trong các trường
hợp đó, ta có thể gọi <code class="docutils literal notranslate"><span class="pre">as_in_ctx()</span></code>. Nếu biến đó đã tồn tại trong ngữ
cảnh thì hàm này không thực hiện lệnh nào. Trên thực tế, trừ trường hợp
đặc biệt bạn muốn tạo bản sao, hãy sử dụng <code class="docutils literal notranslate"><span class="pre">as_in_ctx()</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">as_in_ctx</span><span class="p">(</span><span class="n">try_gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">z</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span> <span class="n">ctx</span><span class="o">=</span><span class="n">gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<!--
It is important to note that, if the `ctx` of the source variable and the target variable are consistent,
then the `as_in_ctx` function causes the target variable and the source variable to share the memory of the source variable.
--><p>Cần lưu ý rằng, nếu <code class="docutils literal notranslate"><span class="pre">ctx</span></code> của biến nguồn và biến đích là giống nhau,
hàm <code class="docutils literal notranslate"><span class="pre">as_in_ctx</span></code> sẽ khiến biến đích có cùng vùng nhớ với biến nguồn.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">as_in_ctx</span><span class="p">(</span><span class="n">try_gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="ow">is</span> <span class="n">y</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">True</span>
</pre></div>
</div>
<!--
The `copyto` function always creates new memory for the target variable.
--><p>Hàm <code class="docutils literal notranslate"><span class="pre">copyto</span></code> luôn luôn cấp phát vùng nhớ mới cho biến đích.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">copyto</span><span class="p">(</span><span class="n">try_gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="ow">is</span> <span class="n">y</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">False</span>
</pre></div>
</div>
<!-- ===================== Kết thúc dịch Phần 5 ===================== --><!-- ===================== Bắt đầu dịch Phần 6 ===================== --><!--
### Side Notes
--></div>
<div class="section" id="nhung-luu-y-ben-le">
<h3><span class="section-number">5.6.2.3. </span>Những lưu ý bên lề<a class="headerlink" href="#nhung-luu-y-ben-le" title="Permalink to this headline">¶</a></h3>
<!--
People use GPUs to do machine learning because they expect them to be fast.
But transferring variables between contexts is slow.
So we want you to be 100% certain that you want to do something slow before we let you do it.
If MXNet just did the copy automatically without crashing then you might not realize that you had written some slow code.
--><p>Mọi người sử dụng GPU để thực hiện việc tính toán trong học máy vì họ kỳ
vọng chúng sẽ nhanh hơn. Nhưng việc truyền các biến giữa các bối cảnh
lại diễn ra chậm. Do đó, chúng tôi mong bạn chắc chắn 100% rằng bạn muốn
thực hiện một việc nào đó thật chậm trước khi chúng tôi để bạn thực hiện
nó. Nếu MXNet chỉ thực hiện việc sao chép tự động mà không gặp sự cố thì
có thể bạn sẽ không nhận ra được mình đã có những đoạn mã chưa tối ưu
đến nhường nào.</p>
<!--
Also, transferring data between devices (CPU, GPUs, other machines) is something that is *much slower* than computation.
It also makes parallelization a lot more difficult, since we have to wait for data to be sent (or rather to be received) before we can proceed with more operations.
This is why copy operations should be taken with great care.
As a rule of thumb, many small operations are much worse than one big operation.
Moreover, several operations at a time are much better than many single operations interspersed in the code (unless you know what you are doing)
This is the case since such operations can block if one device  has to wait for the other before it can do something else.
It is a bit like ordering your coffee in a queue rather than pre-ordering it by phone and finding out that it is ready when you are.
--><p>Thêm vào đó, việc truyền dữ liệu giữa các thiết bị (CPU, GPU và các máy
khác) <em>chậm hơn nhiều</em> so với việc thực hiện tính toán. Nó cũng làm cho
việc song song hóa trở nên khó hơn nhiều, vì chúng ta phải chờ cho dữ
liệu được gửi đi (hoặc được nhận về) trước khi chúng ta có thể tiến hành
nhiều tác vụ xử lý tính toán hơn. Đây là lý do tại sao các hoạt động sao
chép nên được dành sự lưu tâm lớn. Quy tắc nằm lòng là nhiều xử lý tính
toán nhỏ thì tệ hơn nhiều so với một xử lý tính toán lớn. Hơn nữa, xử lý
nhiều phép tính toán cùng một thời điểm thì tốt hơn nhiều so với nhiều
xử lý tính toán đơn lẻ nằm rải rác trong chương trình (trừ khi là bạn
hiểu rõ mình đang làm gì). Lý do là ở tình huống này những hoạt động như
vậy có thể gây tắc nghẽn nếu một thiết bị phải chờ một thiết bị khác
trước khi nó có thể làm điều gì đó khác. Việc này hơi giống việc bạn
phải xếp hàng mua cà phê thay vì đặt trước qua điện thoại và biết được
khi nào nó đã sẵn sàng để đến lấy.</p>
<!--
Last, when we print `ndarray`s or convert `ndarray`s to the NumPy format, if the data is not in main memory,
MXNet will copy it to the main memory first, resulting in additional transmission overhead.
Even worse, it is now subject to the dreaded Global Interpreter Lock that makes everything wait for Python to complete.
--><p>Sau cùng, khi chúng ta in các <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> hoặc chuyển các <code class="docutils literal notranslate"><span class="pre">ndarray</span></code>
sang định dạng Numpy, nếu dữ liệu không có trong bộ nhớ chính, MXNet sẽ
sao chép nó tới bộ nhớ chính trước tiên, dẫn tới việc tốn thêm thời gian
chờ cho việc truyền dữ liệu. Thậm chí tệ hơn, điều đáng sợ lúc này là nó
phụ thuộc vào Bộ Khóa Phiên dịch Toàn cục (<em>Global Interpreter Lock</em>)
khiến mọi thứ phải chờ Python hoàn tất.</p>
<!-- ===================== Kết thúc dịch Phần 6 ===================== --><!-- ===================== Bắt đầu dịch Phần 7 ===================== --><!-- ========================================= REVISE PHẦN 3 - KẾT THÚC ===================================--><!-- ========================================= REVISE PHẦN 4 - BẮT ĐẦU ===================================--><!--
## Gluon and GPUs
--></div>
</div>
<div class="section" id="gluon-va-gpu">
<h2><span class="section-number">5.6.3. </span>Gluon và GPU<a class="headerlink" href="#gluon-va-gpu" title="Permalink to this headline">¶</a></h2>
<!--
Similarly, Gluon's model can specify devices through the `ctx` parameter during initialization.
The following code initializes the model parameters on the GPU (we will see many more examples of
how to run models on GPUs in the following, simply since they will become somewhat more compute intensive).
--><p>Tương tự, mô hình của Gluon có thể chỉ định thiết bị dựa vào tham số
<code class="docutils literal notranslate"><span class="pre">ctx</span></code> trong quá trình khởi tạo. Đoạn mã dưới đây khởi tạo các tham số
của mô hình trên GPU (sau này chúng ta sẽ thấy nhiều ví dụ về cách chạy
các mô hình trên GPU, đơn giản bởi chúng phần nào sẽ cần khả năng tính
toán mạnh hơn).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">net</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">ctx</span><span class="o">=</span><span class="n">try_gpu</span><span class="p">())</span>
</pre></div>
</div>
<!--
When the input is an `ndarray` on the GPU, Gluon will calculate the result on the same GPU.
--><p>Khi đầu vào là một <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> trên GPU, Gluon sẽ tính toán kết quả trên
cùng GPU đó.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span><span class="mf">0.04995865</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.04995865</span><span class="p">]],</span> <span class="n">ctx</span><span class="o">=</span><span class="n">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<!--
Let's confirm that the model parameters are stored on the same GPU.
--><p>Hãy kiểm chứng lại rằng các tham số của mô hình được lưu trên cùng GPU.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">()</span><span class="o">.</span><span class="n">ctx</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<!--
In short, as long as all data and parameters are on the same device, we can learn models efficiently.
In the following we will see several such examples.
--><p>Tóm lại, khi dữ liệu và các tham số ở trên cùng thiết bị, ta có thể huấn
luyện mô hình một cách hiệu quả. Ta sẽ xem xét một vài ví dụ như thế
trong phần tiếp theo.</p>
<!--
## Summary
--></div>
<div class="section" id="tom-tat">
<h2><span class="section-number">5.6.4. </span>Tóm tắt<a class="headerlink" href="#tom-tat" title="Permalink to this headline">¶</a></h2>
<!--
* MXNet can specify devices for storage and calculation, such as CPU or GPU.
By default, MXNet creates data in the main memory and then uses the CPU for calculations.
* MXNet requires all input data for calculation to be *on the same device*, be it CPU or the same GPU.
* You can lose significant performance by moving data without care.
A typical mistake is as follows: computing the loss for every minibatch on the GPU and reporting it back to the user
on the command line (or logging it in a NumPy array) will trigger a global interpreter lock which stalls all GPUs.
It is much better to allocate memory for logging inside the GPU and only move larger logs.
--><ul class="simple">
<li>MXNet có thể chỉ định các thiết bị thực hiện việc lưu trữ và tính
toán như CPU hay GPU. Mặc định, MXNet tạo dữ liệu trên bộ nhớ chính
và sử dụng CPU để tính toán.</li>
<li>MXNet yêu cầu tất cả dữ liệu đầu vào <em>nằm trên cùng thiết bị</em> trước
khi thực hiện tính toán, tức cùng một CPU hoặc cùng một GPU.</li>
<li>Hiệu năng có thể giảm đáng kể nếu di chuyển dữ liệu một cách không
cẩn thận. Một lỗi thường gặp là: việc tính toán mất mát cho các
minibatch trên GPU rồi in kết quả ra cửa sổ dòng lệnh (hoặc ghi kết
quả vào mảng NumPy) sẽ kích hoạt Bộ Khóa Phiên dịch Toàn cục làm tất
cả GPU dừng hoạt động. Sẽ tốt hơn nếu cấp phát bộ nhớ cho việc ghi
lại quá trình hoạt động (<em>logging</em>) ở GPU và chỉ di chuyển các bản
ghi lớn.</li>
</ul>
<!--
## Exercises
--></div>
<div class="section" id="bai-tap">
<h2><span class="section-number">5.6.5. </span>Bài tập<a class="headerlink" href="#bai-tap" title="Permalink to this headline">¶</a></h2>
<!--
1. Try a larger computation task, such as the multiplication of large matrices, and see the difference in speed between the CPU and GPU.
What about a task with a small amount of calculations?
2. How should we read and write model parameters on the GPU?
3. Measure the time it takes to compute 1000 matrix-matrix multiplications of $100 \times 100$ matrices
and log the matrix norm $\mathrm{tr} M M^\top$ one result at a time vs. keeping a log on the GPU and transferring only the final result.
4. Measure how much time it takes to perform two matrix-matrix multiplications on two GPUs at the same time vs. in sequence
on one GPU (hint: you should see almost linear scaling).
--><ol class="arabic simple">
<li>Thử một tác vụ có khối lượng tính toán lớn, ví dụ như nhân các ma
trận kích thước lớn để thấy sự khác nhau về tốc độ giữa CPU và GPU.
Và với tác vụ có khối lượng tính toán nhỏ thì sao?</li>
<li>Làm thế nào để đọc và ghi các tham số của mô hình trên GPU?</li>
<li>Đo thời gian thực hiện 1000 phép nhân ma trận kích thước
<span class="math notranslate nohighlight">\(100 \times 100\)</span> và ghi lại giá trị chuẩn
<span class="math notranslate nohighlight">\(\mathrm{tr} M M^\top\)</span> của từng kết quả, rồi so sánh với việc
lưu tất cả giá trị chuẩn tại một bản ghi ở GPU và chỉ trả về bản ghi
đó.</li>
<li>Đo thời gian thực hiện hai phép nhân ma trận tại hai GPU cùng lúc so
với việc thực hiện chúng lần lượt trên cùng một GPU (gợi ý: bạn sẽ
thấy tỉ lệ gần như tuyến tính).</li>
</ol>
<!-- ===================== Kết thúc dịch Phần 7 ===================== --><!-- ========================================= REVISE PHẦN 4 - KẾT THÚC ===================================--></div>
<div class="section" id="thao-luan">
<h2><span class="section-number">5.6.6. </span>Thảo luận<a class="headerlink" href="#thao-luan" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="https://discuss.mxnet.io/t/2330">Tiếng Anh</a></li>
<li><a class="reference external" href="https://forum.machinelearningcoban.com/c/d2l">Tiếng Việt</a></li>
</ul>
</div>
<div class="section" id="nhung-nguoi-thuc-hien">
<h2><span class="section-number">5.6.7. </span>Những người thực hiện<a class="headerlink" href="#nhung-nguoi-thuc-hien" title="Permalink to this headline">¶</a></h2>
<p>Bản dịch trong trang này được thực hiện bởi:</p>
<ul class="simple">
<li>Đoàn Võ Duy Thanh</li>
<li>Trần Yến Thy</li>
<li>Lê Khắc Hồng Phúc</li>
<li>Nguyễn Mai Hoàng Long</li>
<li>Nguyễn Văn Cường</li>
<li>Phạm Hồng Vinh</li>
<li>Phạm Minh Đức</li>
<li>Vũ Hữu Tiệp</li>
</ul>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">5.6. GPU</a><ul>
<li><a class="reference internal" href="#thiet-bi-tinh-toan">5.6.1. Thiết bị Tính toán</a></li>
<li><a class="reference internal" href="#ndarray-va-gpu">5.6.2. <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> và GPU</a><ul>
<li><a class="reference internal" href="#luu-tru-tren-gpu">5.6.2.1. Lưu trữ trên GPU</a></li>
<li><a class="reference internal" href="#sao-chep">5.6.2.2. Sao chép</a></li>
<li><a class="reference internal" href="#nhung-luu-y-ben-le">5.6.2.3. Những lưu ý bên lề</a></li>
</ul>
</li>
<li><a class="reference internal" href="#gluon-va-gpu">5.6.3. Gluon và GPU</a></li>
<li><a class="reference internal" href="#tom-tat">5.6.4. Tóm tắt</a></li>
<li><a class="reference internal" href="#bai-tap">5.6.5. Bài tập</a></li>
<li><a class="reference internal" href="#thao-luan">5.6.6. Thảo luận</a></li>
<li><a class="reference internal" href="#nhung-nguoi-thuc-hien">5.6.7. Những người thực hiện</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="read-write_vn.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>5.5. Đọc/Ghi tệp</div>
         </div>
     </a>
     <a id="button-next" href="../chapter_convolutional-neural-networks/index_vn.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>6. Mạng Nơ-ron Tích chập</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>